<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[经济学概念]]></title>
    <url>%2F2019%2F03%2F09%2Feconomics-tips%2F</url>
    <content type="text"><![CDATA[[x] 有人的地方就有交易 [x] 成本是放弃了的最大代价 [x] 稀缺是一个基本事实 [x] 人的需求永无止境 [x] 对人歧视越多，自己代价越大 [x] 沉没成本不是成本 [x] 你的成本由别人决定 [x] 产品的供需决定原材料的成本 [x] 供需关系决定商品价格，商品价格决定资源成本 [x] 乞丐没有白拿施舍 [x] 科斯定律：在交易费用为零或足够低的情况下，不管资源最初的主人是谁，资源都同样会流到价值最高的用途上去。用大白话来说，就是“谁用得好就归谁”。 [x] 待更新]]></content>
      <categories>
        <category>读书</category>
      </categories>
      <tags>
        <tag>经济学</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Apache-HBase-™-中文指南-最新版HBase-3-0-0-ch2-HBase配置详解]]></title>
    <url>%2F2019%2F03%2F04%2FApache-HBase-%E2%84%A2-%E4%B8%AD%E6%96%87%E6%8C%87%E5%8D%97-%E6%9C%80%E6%96%B0%E7%89%88HBase-3-0-0-ch2-HBase%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Apache HBase配置 译者: xixici 在上一章快速开始的内容中，你学习了如何启动独立式、伪分布式以及完全分布式HBase，在本章中，我们将介绍更多关于Apache HBase的配置，以进一步了解Apache HBase。请仔细阅读本章，特别是基本配置条件部分，该部分能够确保您的HBase测试和部署顺利进行，并防止数据丢失。现在，一起进入学习吧！ 3. 配置文件Apache HBase使用与Apache Hadoop相同的配置系统。所有配置文件都位于_conf/_ 目录中，需要保持群集中每个节点的同步。 HBase配置文件说明_backup-masters_ 默认情况下不存在。这是一个纯文本文件，其中列出了主服务器应在其上启动备份主进程的主机，每行一台主机。 _hadoop-metrics2-hbase.properties_ 用于连接HBase Hadoop的Metrics2框架。有关Metrics2的更多信息，请参阅Hadoop Wiki 。默认情况下只包含注释出的示例。 _hbase-env.cmd_ and _hbase-env.sh_ 用于Windows和Linux/Unix环境的脚本，以设置HBase的工作环境，包括Java、Java选项和其他环境变量的位置。该文件包含许多注释示例来提供指导。 _hbase-policy.xml_ RPC服务器使用默认策略配置文件对客户端请求进行授权决策。仅在启用HBase安全模式下使用。 _hbase-site.xml_ 主要的HBase配置文件。该文件指定覆盖HBase的默认配置的配置选项。您可以在_docs/hbase-default.xml_中查看（但不要编辑）默认配置文件。您还可以在HBase Web UI的HBase配置选项卡中查看群集的整个有效配置（默认和覆盖）。 _log4j.properties_ 通过log4j进行HBase日志记录的配置文件。 _regionservers_ 包含应该在HBase集群中运行RegionServer的主机列表的纯文本文件。默认情况下，这个文件包含单个条目localhostt。它应该包含主机名或IP地址列表，每行一个，如果集群中的每个节点将在其localhost接口上运行RegionServer的话，则只应包含localhost 检查XML有效性 在编辑XML时，最好使用支持XML的编辑器，以确保您的语法正确且XML格式良好。您还可以使用该xmllint 程序检查您的XML格式是否正确。默认情况下，xmllint 重新流动并将XML打印到标准输出。要检查格式是否正确，并且只在存在错误时才打印输出，请使用命令xmllint -noout filename.xml。 在集群之间保持同步配置 当在分布式模式下运行时, 在对HBase配置进行编辑后，请确保将conf/目录的内容复制到群集的所有节点。HBase不会为你这么做的。请使用 rsync, scp或其他安全机制将配置文件复制到你的节点。对于大多数配置, 服务器需要重新启动才能成功更改。动态配置是这方面的一个例外，在之后的内容将对此进行说明。 4. HBase基础条件在本节中，我们列出了使用HBase时所需要的服务和一些必需的系统配置。 Java 在下表中你可以看到HBase版本与其对应支持的JDK版本： 社区很乐意帮助你诊断和解决可能遇到的问题.你需要进去社区查找类似问题,可能需要你更改java环境.某些情况下,例如编译/测试单元有效性,具体操作问题)也要注意. 建议使用长期支持JDKs HBase建议用户依赖长期支持 (LTS)版本的JDK,无论是OpenJDK项目或其他.截至2018年3月，这意味着Java 8是唯一适用的版本，而下一个可能的测试版本将是2018 Q3的Java 11。 HBase Version JDK 7 JDK 8 JDK 9 (Non-LTS) JDK 10 (Non-LTS) JDK 11 2.0+ HBASE-20264 HBASE-20264 HBASE-21110 1.2+ HBASE-20264 HBASE-20264 HBASE-21110 HBase不支持 Java 6的构建或编译 你必须在集群的每个节点上设置JAVA_HOME 。_hbase-env.sh_提供了一种方便的机制。 操作系统 ssh （必须的）HBase广泛使用安全Shell（ssh）命令和实用程序在集群节点之间进行通信。集群中的每台服务器都必须运行ssh，以便可以管理Hadoop和HBase后台进程。您必须能够使用共享密钥而不是密码，通过SSH（包括本地节点）从主服务器和任何备份主服务器连接到所有节点。您可以在Linux或Unix系统中的”Procedure: Configure Passwordless SSH Access“（配置无密码SSH访问）中看到这种设置的基本方法。如果群集节点使用OS X，请参阅SSH: Setting up Remote Desktop and Enabling Self-Login DNS HBase使用本地主机名来自行报告其IP地址 NTP 群集节点上的时钟应该同步。少量的变化是可以接受的，但是大量的不同会导致不稳定和意外的行为。如果在群集中看到无法解释的问题，则时间同步是首先要检查的事项之一。建议您在群集上运行网络时间协议（NTP）服务或其他时间同步机制，并且所有节点都查找相同的服务以进行时间同步。请参阅_The Linux Documentation Project (TLDP)_ 中的Basic NTP Configuration以设置NTP。 文件和进程数限制 Apache HBase是一个数据库。它需要能够一次打开大量的文件。许多Linux发行版限制了允许单个用户打开的文件数量1024（或者256，在旧版本的OS X上）。当以运行 HBase 的用户身份登录时，您可以通过在服务器上运行ulimit -n 命令来检查服务器上的限制。限制太低会产生一些 故障 您也可能会注意到以下错误： 122010-04-06 03:04:37,542 INFO org.apache.hadoop.hdfs.DFSClient: Exception increateBlockOutputStream java.io.EOFException2010-04-06 03:04:37,542 INFO org.apache.hadoop.hdfs.DFSClient: Abandoning block blk_-6935524980745310745_1391901 建议将ulimit提高到至少10,000，但更可能是10,240，因为该值通常以1024的倍数表示。每个ColumnFamily至少有一个StoreFile，如果该区域处于加载状态，则可能有多于六个的StoreFile。所需的打开文件的数量取决于ColumnFamilies的数量和区域的数量。以下是计算RegionServer上打开的文件的潜在数量的粗略公式。 计算打开文件的潜在数量： 1(StoreFiles per ColumnFamily) x (regions per RegionServer) 假设一个模式的每个区域有3个ColumnFamilies，每个ColumnFamily平均有3个StoreFiles，每个RegionServer有100个区域，则JVM将打开3 * 3 * 100 = 900文件描述符，不包括打开的JAR文件、配置文件等等。打开一个文件不需要很多资源，而且允许用户打开太多文件的风险很小。 另一个相关设置是允许用户同时运行的进程数量。在Linux和Unix中，使用该ulimit -u 命令设置进程的数量。这不应与nproc命令混淆，该命令控制给定用户可用的CPU数量。在负载下，ulimit -u太低会导致OutOfMemoryError异常。 为运行HBase进程的用户配置文件描述符和进程的最大数量是操作系统配置，而不是HBase配置。确保为实际运行HBase的用户更改设置也很重要。要查看哪个用户启动了HBase，以及该用户的ulimit配置，请查看该实例的HBase日志的第一行。 示例 2. ulimit 在Ubuntu上的设置 要在Ubuntu上配置_limits.conf_设置，请编辑：_/etc/security/limits.conf_，它是一个由四列组成的空格分隔的文件。在以下示例中，第一行将用户名为hadoop的操作系统用户的打开文件数（nofile）的软限制和硬限制设置为32768。第二行将同一用户的进程数设置为32000。 12hadoop - nofile 32768hadoop - nproc 32000 这些设置仅适用于可插入身份验证模块（PAM）环境指示使用它们的情况。要配置PAM以使用这些限制，请确保_/etc/pam.d/common-session_文件包含以下行： 1session required pam_limits.so Linux Shell 所有HBase附带的shell脚本都依赖于GNU Bash shell. Windows 不建议在Windows计算机上运行生产系统。 4.1. Hadoop下表总结了每个HBase版本支持的Hadoop版本。下表总结了每个版本的HBase支持的Hadoop版本。未出现在此表中的旧版本被视为不受支持，可能缺少必要的功能，而新版本未经测试，但可能适用。 基于HBase的版本，您应该选择最合适的Hadoop版本。参考更多关于Hadoop环境配置的内容！ 版本无区别. 请查看 the Hadoop wiki . 建议使用 Hadoop 2.x Hadoop 2.x 速度更快，包括短路读取功能( Leveraging local data)，这将有助于提高您的 HBase 随机读取配置文件；Hadoop 2.x 还包括重要的 bug 修复，可以改善您的整体 HBase 体验；HBase 不支持使用早期版本的 Hadoop 运行；有关特定于不同 HBase 版本的要求，请参见下表 Hadoop 3.x 仍处于早期访问版本中，尚未被 HBase 社区对生产用例进行充分测试。 使用以下的注解来解释下面的这个表格： Hadoop版本支持 T = 支持 F = 不支持 N = 未测试 HBase-1.2.x, HBase-1.3.x HBase-1.4.x HBase-2.0.x HBase-2.1.x Hadoop-2.4.x T F F F Hadoop-2.5.x T F F F Hadoop-2.6.0 F F F F Hadoop-2.6.1+ T F T F Hadoop-2.7.0 F F F F Hadoop-2.7.1+ T T T T Hadoop-2.8.[0-1] F F F F Hadoop-2.8.2 N N N N Hadoop-2.8.3+ N N T T Hadoop-2.9.0 F F F F Hadoop-2.9.1+ N N N N Hadoop-3.0.[0-2] F F F F Hadoop-3.0.3+ F F T T Hadoop-3.1.0 F F F F Hadoop-3.1.1+ F F T T Hadoop Pre-2.6.1 和 JDK 1.8 Kerbero 在 Kerberos 环境中使用 pre-2.6.1 Hadoop 版本和 JDK 1.8 时，HBase 服务器可能因 Kerberos keytab relogin 错误而失败并中止。JDK 1.7 (1.7. 0_80) 的后期版本也有问题HADOOP-10786。在这种情况下考虑升级到Hadoop 2.6.1+。 Hadoop 2.6. 如果您计划在 HDFS 加密区域的顶部运行 HBase，则基于 2.6.x 行的 Hadoop 发行版必须具有 HADOOP-11710 应用。如果不这样做，将导致群集故障和数据丢失。此修补程序存在于Apache Hadoop 2.6.1+版本中。 Hadoop 2.y.0 Hadoop 2.7.0开始两个版本未经测试或不受支持，因为Hadoop PMC明确将该版本标记为不稳定.因此，HBase明确建议用户避免在这些版本之上运行。另外，Hadoop PMC也给出了同样的警告。有关参考，请参见 Apache Hadoop 2.7.0, Apache Hadoop 2.8.0, Apache Hadoop 2.8.1, and Apache Hadoop 2.9.0. Hadoop 3.0.x 包含应用程序时间服务特性的Hadoop集群可能会导致出现意外的HBase类版本.用户要确保YARN-7190 存在于yarn服务中 (目前已修复 2.9.1+ , 3.1.0+). Hadoop 3.1.0 Hadoop PMC声称3.1.0 不稳定且不能用于生产.因此,HBase建议用户避免使用本版本.详情: release announcement for Hadoop 3.1.0. 更换Hadoop 因为hbase依赖于hadoop，并且hadoop jar存在 _lib_目录下。这些的jar仅在独立模式下使用。在分布式模式下，集群上的Hadoop版本与HBase下的版本匹配是_至关重要_的。将hbase lib目录中的hadoop jar替换为集群上运行的版本中的hadoop jar，以避免版本不匹配问题。确保在整个集群中替换hbase下的jar。Hadoop版本不匹配问题有多种表现形式。如果HBase出现挂起，请检查是否不匹配。 4.1.1. dfs.datanode.max.transfer.threadsHDFS DataNode在任何时候都会有一个文件数上限。在进行任何加载之前，请确保您已经配置了Hadoop的_conf/hdfs-site.xml_，并将该dfs.datanode.max.transfer.threads值设置为至少如下的值： 1234&lt;property&gt; &lt;name&gt;dfs.datanode.max.transfer.threads&lt;/name&gt; &lt;value&gt;4096&lt;/value&gt;&lt;/property&gt; 进行上述配置后，务必重新启动HDFS。 没有这个配置就会造成奇怪的故障。其中一种表现是缺失区块。例如： 12310/12/08 20:10:31 INFO hdfs.DFSClient: Could not obtain block blk_XXXXXXXXXXXXXXXXXXXXXX_YYYYYYYY from any node: java.io.IOException: No live nodes contain current block. Will get new block locations from namenode and retry... 查看 casestudies.max.transfer.threads 并注意 dfs.datanode.max.xcievers (e.g. Hadoop HDFS: Deceived by Xciever). 4.2. ZooKeeper 要求ZooKeeper 3.4.x 必需. 5. HBase运行模式：独立式和分布式HBase有两种运行模式：独立式和分布式。HBase以独立模式运行。无论您的模式如何，您都需要通过编辑HBase _conf_目录中的文件来配置HBase 。至少，您必须编辑conf/hbase-env.sh来告诉HBase要使用哪个java。在这个文件中，你设置了HBase环境变量，比如JVM的heapsize和其他选项，日志文件的首选位置等等。设置JAVA_HOME以指向你的java安装的根目录。 5.1. Standalone HBase默认情况下使用的是独立式的HBase。在快速开始一节中，我们已经介绍过独立模式。在独立模式下，HBase不使用HDFS，而是使用本地文件系统，是在同一个JVM中运行所有HBase守护进程和本地ZooKeeper。ZooKeeper绑定到一个众所周知的端口，通过该端口，客户端可以和HBase进行通信。 5.1.1. Standalone HBase over HDFS有时在独立的hbase上有一个有用的变体，它的所有的守护进程都在一个JVM中运行，而不是坚持到本地文件系统，而是坚持到一个HDFS实例。 当您打算使用简单的部署配置文件时，您可能会考虑使用此配置文件，加载很轻松，但是数据必须在节点的出入之间持续存在。向 HDFS 写入数据的地方可以确保后者。 要配置此独立变体，请编_hbase-site.xml_，设置 _hbase.rootdir_以指向HDFS实例中的某个目录，然后将_hbase.cluster.distributed_ 设置为_false_。例如：12345678910&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://namenode.example.org:8020/hbase&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 5.2. 分布式分布式模式可以细分为_分布式_、_伪分布式_（所有守护进程都在单个节点上运行）、_完全分布式_（守护进程分布在集群中的所有节点上）。其中，伪分布式模式与完全分布式的命名来自于Hadoop。 伪分布式模式可以针对本地文件系统运行，也可以针对_Hadoop分布式文件系统（HDFS）_的实例运行。完全分布式模式只能在HDFS上运行。有关如何设置HDFS，请参阅 http://www.alexjf.net/blog/distributed-systems/hadoop-yarn-installation-definitive-guide. 5.2.1. 伪分布式 伪分布式快速开始 快速开始 章节包含相关信息. 伪分布式模式的HBase就是在单个主机上运行的完全分布式模式。使用此HBase配置仅进行测试和原型设计。请勿将此配置用于生产或性能评估。 5.3. 完全分布式默认情况下，HBase以独立模式运行，独立模式和伪分布模式用于小规模测试。对于生产环境，建议使用分布式模式。在分布式模式下，HBase守护进程的多个实例在集群中的多个服务器上运行。 就像在伪分布式模式中一样，完全分布式的配置要求您将hbase.cluster.distributed 属性设置为 true。通常情况下，hbase.rootdir被配置为指向高可用性的HDFS。 此外，集群还配置了以多个群集节点成为RegionServer、ZooKeeper QuorumPeers和备份HMaster服务器。详见: quickstart-fully-distributed. 分布式RegionServers 通常，你的群集将包含多个运行在不同服务器上的RegionServer，以及主要和备份Master和ZooKeeper守护程序。主服务器上的c_conf/regionservers_中包含一个主机列表，其RegionServers与该集群相关。每个主机都在一个单独的行上。当主服务器启动或停止时，此文件中列出的所有主机将启动和停止其RegionServer进程。 ZooKeeper and HBase 有关HBase的ZooKeeper设置说明，请参见 ZooKeeper部分。 示例 3. 分布式HBase集群示例 是一个分布式HBase集群的简单的_conf/hbase-site.xml_ 。用于实际工作的群集将包含更多自定义配置参数。大多数HBase配置指令都具有默认值，除非在_conf/hbase-site.xml_ 中覆盖该值，否则将使用这些默认值。有关更多信息，请参阅“配置文件” 1234567891011121314&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://namenode.example.org:8020/hbase&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;node-a.example.com,node-b.example.com,node-c.example.com&lt;/value&gt; &lt;/property&gt;&lt;/configuration&gt; 这是_conf/regionservers_ 文件的示例，其中包含应在集群中运行RegionServer的节点的列表。这些节点需要安装HBase，他们需要使用与主服务器相同的_conf/_ 目录内容： 123node-a.example.comnode-b.example.comnode-c.example.com 这是_conf/backup-masters_文件的示例，其中包含应运行备份主实例的每个节点的列表。除非主主站变为不可用，否则备份主站实例将处于空闲状态。 12node-b.example.comnode-c.example.com 分布式HBase快速入门 请参阅quickstart-fully-distributed，了解包含多个ZooKeeper、备份HMaster和RegionServer实例的简单三节点群集配置。 过程: HDFS客户端配置 值得注意的是，如果您在Hadoop集群上进行了HDFS客户端配置更改（例如，HDFS客户端的配置指令），而不是服务器端配置，则必须使用以下方法之一来启用HBase以查看和使用这些配置更改： 在_hbase-env.sh_中添加一个指向你HADOOP_CONF_DIR的HBASE_CLASSPATH环境变量 在_${HBASE_HOME}/conf_下添加一个_hdfs-site.xml_（或_hadoop-site.xml_）或更好的符号链接 只有一小部分HDFS客户端配置，请将它们添加到_hbase-site.xml_ 这种HDFS客户端配置的一个例子是dfs.replication。例如，如果希望以5的复制因子运行，则HBase将创建缺省值为3的文件，除非您执行上述操作以使配置可用于HBase。 6. 开始运行保证HDFS第一次运行，你需要通过在HADOOP_HOME目录中运行_bin/start-hdfs.sh_来启动和停止Hadoop HDFS守护进程。你确保它正确启动的方法是通过在 Hadoop 文件系统中测试文件的put和get。HBase通常不使用MapReduce或YARN守护进程，因此它们不需要启动。 如果您正在管理您自己的ZooKeeper，请启动它并确认它正在运行，否则HBase将启动ZooKeeper作为其启动过程的一部分。 你可以从HBASE_HOME目录使用以下命令来启动HBase： 1bin/start-hbase.sh 您现在应该有一个正在运行的HBase实例。HBase日志可以在_log_子目录中找到。检查出来，特别是如果HBase启动困难。 HBase也提供了一个UI列出了重要的属性。默认情况下，它被部署在16010端口的主控主机上（默认情况下HBase RegionServers侦听端口16020，并在端口16030建立一个信息HTTP服务器）。如果主服务器（Master ）在默认端口上指定master.example.org 主机上运行，请将浏览器指向http://master.example.org:16010以查看Web界面。 一旦HBase启动，请参阅下面的shell部分，了解创建表，添加数据，扫描插入内容以及最终禁用和删除表的一些操作命令。 退出HBase shell后停止HBase进入： 12$ ./bin/stop-hbase.shstopping hbase............... 关机可能需要稍等一些时间才能完成。如果您的集群由多台计算机组成，则可能需要更长的时间。如果您正在运行分布式操作，那么在停止Hadoop守护进程之前，一定要等到HBase完全关闭。 7. 默认配置7.1. _hbase-site.xml_ 和 _hbase-default.xml_在Hadoop中将特定于站点的HDFS配置添加到_hdfs-site.xml_文件，那么对于HBase，特定于站点的配置文件为_conf/hbase-site.xml_。有关可配置属性的列表，请参见下面的HBase默认配置或查看_src/main/resources_的HBase源代码中的原始_hbase-default.xml_源文件。 并不是所有的配置选项都会将其发送到_hbase-default.xml_。一些配置只会出现在源代码中；因此识别这些更改的唯一方法是通过代码审查。 目前，这里的更改将需要为HBase重启集群生效。 7.2. HBase 默认配置以下文档是使用默认的HBase配置文件_hbase-default.xml_作为源生成的 hbase.tmp.dir 这是本地文件系统上的临时目录。将此设置更改为指向比“/tmp”更持久的位置，这是java.io.tmpdir的常见解决方案，因为在重新启动计算机时清除了“/tmp”目录。 默认: ${java.io.tmpdir}/hbase-${user.name} hbase.rootdir 这个目录是region servers共享的目录，HBase保持不变。该URL应该是“完全限定的”以包括文件系统的scheme。例如，要指定HDFS实例的”/hbase”目录，namenode运行在namenode.example.org的9000端口，请将此值设置为：hdfs：//namenode.example.org：9000 / hbase。默认情况下，我们会写$ {hbase.tmp.dir}，通常是/tmp - 所以改变这个配置，否则所有的数据在计算机重启时都会丢失。 默认: ${hbase.tmp.dir}/hbase hbase.cluster.distributed 群集所处的模式。对于独立模式，可能的值为false，对于分布式模式，可能的值为true。如果为false，启动将在一个JVM中一起运行所有HBase和ZooKeeper守护程序。 默认: false hbase.zookeeper.quorum 使用逗号分隔的ZooKeeper集合中的服务器列表（这个配置应该被命名为hbase.zookeeper.ensemble）。例如，“host1.mydomain.com，host2.mydomain.com，host3.mydomain.com”。默认情况下，对于本地和伪分布式操作模式，将其设置为localhost。对于完全分布式安装，应将其设置为ZooKeeper集成服务器的完整列表。如果在hbase-env.sh中设置HBASE_MANAGES_ZK，这是hbase将作为群集启动/停止的一部分来启动/停止ZooKeeper的服务器列表。客户端，我们将把这个集合成员的列表，并把它与hbase.zookeeper.property.clientPort配置放在一起。并将其作为connectString参数传递给zookeeper构造函数。 默认: localhost zookeeper.recovery.retry.maxsleeptime 在重试 zookeeper操作之前的最大睡眠时间（以毫秒为单位），这里需要最大时间，以便睡眠时间不会无限增长。 默认: 60000 hbase.local.dir 将本地文件系统上的目录用作本地存储。 默认:${hbase.tmp.dir}/local/ hbase.master.port HBase Master应该绑定的端口。 默认: 16000 hbase.master.info.port HBase Master Web UI的端口。如果您不想运行UI实例，请将其设置为-1。 默认: 16010 hbase.master.info.bindAddress HBase Master Web UI的绑定地址 默认: 0.0.0.0 hbase.master.logcleaner.plugins 由LogsCleaner服务调用的BaseLogCleanerDelegate的逗号分隔列表。这些WAL清理是按顺序调用的。要实现您自己的BaseLogCleanerDelegate，只需将其放入HBase的类路径中，并在此添加完全限定的类名。始终在列表中添加上面的默认日志清理工具。 默认: org.apache.hadoop.hbase.master.cleaner.TimeToLiveLogCleaner,org.apache.hadoop.hbase.master.cleaner.TimeToLiveProcedureWALCleaner hbase.master.logcleaner.ttl WAL在归档（{hbase.rootdir} / oldWALs）目录中保留多久，之后将由主线程清除。该值以毫秒为单位。 默认: 600000 hbase.master.procedurewalcleaner.ttl 过程WAL将在归档目录中保留多久，之后将由主线程清除。该值以毫秒为单位。 默认: 604800000 hbase.master.hfilecleaner.plugins 由HFileCleaner服务调用的BaseHFileCleanerDelegate的逗号分隔列表。这些HFile清理器按顺序调用。要实现您自己的BaseHFileCleanerDelegate，只需将其放入HBase的类路径中，并在此添加完全限定的类名。总是在列表中添加上面的默认日志清除程序，因为它们将被覆盖在hbase-site.xml中。 默认: org.apache.hadoop.hbase.master.cleaner.TimeToLiveHFileCleaner hbase.master.infoserver.redirect Master是否监听Master Web UI端口（hbase.master.info.port）并将请求重定向到由Master和RegionServer共享的Web UI服务器。配置，当主服务区域（而不是默认）时是有意义的。 默认: true hbase.master.fileSplitTimeout 分割一个区域，在放弃尝试之前等待文件分割步骤需要多长时间。默认值：600000。这个设置在hbase-1.x中被称为hbase.regionserver.fileSplitTimeout。Split现在运行主端，因此重命名（如果找到’hbase.master.fileSplitTimeout’设置，将使用它来填充当前’hbase.master.fileSplitTimeout’配置。 默认: 600000 hbase.regionserver.port HBase RegionServer绑定的端口。 默认: 16020 hbase.regionserver.info.port HBase RegionServer Web UI的端口如果您不希望RegionServer UI运行，请将其设置为-1。 默认: 16030 hbase.regionserver.info.bindAddress HBase RegionServer Web UI的地址 默认: 0.0.0.0 hbase.regionserver.info.port.auto Master或RegionServer UI是否应搜索要绑定的端口。如果hbase.regionserver.info.port已被使用，则启用自动端口搜索。用于测试，默认关闭。 默认: false hbase.regionserver.handler.count 在RegionServers上启动RPC Listener实例的计数。Master使用相同的属性来处理主处理程序的数量。太多的处理者可能会适得其反。使其成为CPU数量的倍数。如果主要是只读的，处理程序计数接近CPU计数做得很好。从CPU数量的两倍开始，并从那里调整。 默认: 30 hbase.ipc.server.callqueue.handler.factor 确定呼叫队列数量的因素。值为0表示在所有处理程序之间共享单个队列。值为1意味着每个处理程序都有自己的队列。 默认: 0.1 hbase.ipc.server.callqueue.read.ratio 将调用队列分成读写队列。指定的时间间隔（应该在0.0到1.0之间）将乘以调用队列的数量。值为0表示不分割调用队列，这意味着读取和写入请求将被推送到相同的一组队列中。低于0.5的值意味着将比写入队列更少的读取队列。值为0.5意味着将有相同数量的读写队列。大于0.5的值意味着将有更多的读队列而不是写入队列。值为1.0意味着除了一个之外的所有队列都用于发送读取请求。示例：假设调用队列的总数为10，则read.ratio为0意味着：10个队列将同时包含读/写请求。0.3的读取比例意味着：3个队列将只包含读取请求，7个队列将只包含写入请求。0.5的read.ratio表示：5个队列将只包含读取请求，5个队列将只包含写入请求。0.8的read.ratio意味着：8个队列将只包含读取请求，2个队列将只包含写入请求。1的read.ratio表示：9个队列将只包含读取请求，1个队列将只包含写入请求。 默认: 0 hbase.ipc.server.callqueue.scan.ratio 考虑到读取的调用队列的数量（根据调用队列的总数乘以callqueue.read.ratio计算），scan.ratio属性将把读取的调用队列拆分为小读取和长读取队列。低于0.5的值意味着长读队列比短读队列少。值为0.5意味着将有相同数量的短读取和长读取队列。大于0.5的值意味着将会有比长读取队列更多的长读取队列。值0或1表示使用同一组队列进行获取和扫描。示例：给定读取调用队列的总数为8，scan.ratio为0或1意味着：8个队列将包含长读请求和短读请求。0.3的scan.ratio表示：2个队列只包含长读请求，6个队列只包含短读请求。0.5的scan.ratio表示：4个队列只包含长读请求，4个队列只包含短读请求。0.8的scan.ratio意味着：6个队列只包含长读请求，2个队列只包含短读请求。 默认: 0 hbase.regionserver.msginterval 从RegionServer到Master的消息间隔（以毫秒为单位）。 默认: 3000 hbase.regionserver.logroll.period 无论有多少次编辑，我们将滚动提交日志的时间段。 默认: 3600000 hbase.regionserver.logroll.errors.tolerated 在触发服务器中止之前，我们将允许连续的WAL关闭错误的数量。如果在日志滚动过程中关闭当前WAL书写器失败，则设置为0将导致区域服务器中止。即使是一个很小的值（2或3）也会让区域服务器承担瞬间的HDFS错误。 默认: 2 hbase.regionserver.hlog.reader.impl WAL文件读取器的实现。 默认: org.apache.hadoop.hbase.regionserver.wal.ProtobufLogReader hbase.regionserver.hlog.writer.impl WAL文件编写器的实现。 默认: org.apache.hadoop.hbase.regionserver.wal.ProtobufLogWriter hbase.regionserver.global.memstore.size 在新更新被阻止并刷新之前，区域服务器中所有存储区的最大大小。默认为堆的40％（0.4）。更新被阻止，强制刷新直到区域服务器中的所有内存大小都达到hbase.regionserver.global.memstore.size.lower.limit。此配置中的默认值已被故意留空，以便兑现旧的hbase.regionserver.global.memstore.upperLimit属性（如果存在）。 默认: none hbase.regionserver.global.memstore.size.lower.limit 强制刷新之前，区域服务器中所有存储区的最大大小。默认为hbase.regionserver.global.memstore.size（0.95）的95％。当由于内存限制而导致更新被阻塞时，此值的100％会导致最小可能的刷新。此配置中的默认值已被故意留空，以便兑现旧的hbase.regionserver.global.memstore.lowerLimit属性（如果存在）。 默认: none hbase.systemtables.compacting.memstore.type 确定用于系统表（如META，名称空间表等）的memstore的类型。默认情况下，NONE是类型，因此我们对所有系统表使用默认的memstore。如果我们需要为系统表使用压缩存储器，那么将这个属性设置为：BASIC / EAGER 默认: NONE hbase.regionserver.optionalcacheflushinterval 在自动刷新之前，编辑在内存中的最长时间。默认为1小时。将其设置为0将禁用自动刷新。 默认: 3600000 hbase.regionserver.dns.interface 区域服务器应从中报告其IP地址的网络接口的名称。 默认: default hbase.regionserver.dns.nameserver 域名服务器应使用的名称服务器（DNS）的主机名或IP地址，以确定主机用于通信和显示的主机名。 默认: default hbase.regionserver.region.split.policy 分割策略决定了一个区域应该何时拆分。当前可用的各种其他拆分策略是：BusyRegionSplitPolicy，ConstantSizeRegionSplitPolicy，DisabledRegionSplitPolicy，DelimitedKeyPrefixRegionSplitPolicy，KeyPrefixRegionSplitPolicy和SteppingSplitPolicy。DisabledRegionSplitPolicy会阻止手动区域分割。 默认: org.apache.hadoop.hbase.regionserver.SteppingSplitPolicy hbase.regionserver.regionSplitLimit 限制区域数量，之后不再发生区域分割。这并不是硬性限制区域数量，而是作为区域服务商在一定限度之后停止分裂的指导方针。默认设置为1000。 默认: 1000 zookeeper.session.timeout ZooKeeper会话超时（以毫秒为单位）。它使用两种不同的方式。首先，这个值用于HBase用来连接到集合的ZK客户端。当它启动一个ZK服务器时它也被HBase使用，并且它被作为’maxSessionTimeout’传递。请参http://hadoop.apache.org/zookeeper/docs/current/zookeeperProgrammers.html#ch_zkSessions。例如，如果HBase区域服务器连接到也由HBase管理的ZK集合，那么会话超时将是由此配置指定的。但是，连接到以不同配置管理的集成的区域服务器将受到该集合的maxSessionTimeout的限制。所以，尽管HBase可能会建议使用90秒，但是整体的最大超时时间可能会低于此值，并且会优先考虑。ZK目前的默认值是40秒，比HBase的低。 默认: 90000 zookeeper.znode.parent ZooKeeper中用于HBase的Root ZNode。所有配置了相对路径的HBase的ZooKeeper文件都会在这个节点下。默认情况下，所有的HBase的ZooKeeper文件路径都被配置为一个相对路径，所以它们将全部进入这个目录下，除非被改变。 默认: /hbase zookeeper.znode.acl.parent Root ZNode用于访问控制列表。 默认: acl hbase.zookeeper.dns.interface ZooKeeper服务器应从中报告其IP地址的网络接口的名称。 默认: default hbase.zookeeper.dns.nameserver 名称服务器（DNS）的主机名或IP地址，ZooKeeper服务器应使用该名称服务器来确定主机用于通信和显示的主机名。 默认: default hbase.zookeeper.peerport ZooKeeper同伴使用的端口进行彼此会话。有关更多信息，请参阅 http://hadoop.apache.org/zookeeper/docs/r3.1.1/zookeeperStarted.html#sc_RunningReplicatedZooKeeper 默认: 2888 hbase.zookeeper.leaderport ZooKeeper用于leader选举的端口。有关更多信息，请参阅 http://hadoop.apache.org/zookeeper/docs/r3.1.1/zookeeperStarted.html#sc_RunningReplicatedZooKeeper 默认: 3888 hbase.zookeeper.property.initLimit 来自ZooKeeper的配置zoo.cfg的属性。初始同步阶段可以采用的时钟（ticks）周期数。 默认: 10 hbase.zookeeper.property.syncLimit 来自ZooKeeper的配置zoo.cfg的属性。发送请求和获取确认之间可以传递的时钟（ticks）数量。 默认: 5 hbase.zookeeper.property.dataDir 来自ZooKeeper的配置zoo.cfg的属性。快照存储的目录。 默认: ${hbase.tmp.dir}/zookeeper hbase.zookeeper.property.clientPort 来自ZooKeeper的配置zoo.cfg的属性。客户端将连接的端口。 默认: 2181 hbase.zookeeper.property.maxClientCnxns 来自ZooKeeper的配置zoo.cfg的属性。限制由IP地址标识的单个客户端的并发连接数量（在套接字级别）可能会对ZooKeeper集合的单个成员产生影响。设置为高，以避免独立运行和伪分布式运行的zk连接问题。 默认: 300 hbase.client.write.buffer BufferedMutator写入缓冲区的默认大小（以字节为单位）。一个更大的缓冲区需要更多的内存 - 在客户端和服务器端，因为服务器实例化传递的写入缓冲区来处理它 - 但更大的缓冲区大小减少了RPC的数量。对于估计使用的服务器端内存，计算：hbase.client.write.buffer * hbase.regionserver.handler.count 默认: 2097152 hbase.client.pause 一般客户端pause值。在运行失败的get，region lookup等的重试之前，主要用作等待的值。hbase.client.retries.number 有关如何取消此初始暂停量以及此重试数量说明。 默认: 100 hbase.client.pause.cqtbe 是否为CallQueueTooBigException（cqtbe）使用特殊的客户端pause。如果您观察到来自同一个RegionServer的频繁的CQTBE，并且其中的调用队列保持充满，则将此属性设置为比hbase.client.pause更高的值 默认: none hbase.client.retries.number 最大重试次数。用作所有可重试操作（如获取单元格值，启动行更新等）的最大值。重试间隔是基于hbase.client.pause的粗略函数。首先，我们在这段时间重试，但后来退后，我们很快就达到每十秒钟重试一次。请参阅HConstants＃RETRY_BACKOFF了解备份如何提升。改变这个设置和hbase.client.pause来适应你的工作负载。 默认: 15 hbase.client.max.total.tasks 单个HTable实例发送到集群的最大并发突变任务数。 默认: 100 hbase.client.max.perserver.tasks 单个HTable实例将发送到单个区域服务器的并发突变任务的最大数量。 默认: 2 hbase.client.max.perregion.tasks 客户端将维护到单个Region的最大并发突变任务数。也就是说，如果已经有hbase.client.max.perregion.tasks写入这个区域，那么新的放入将不会被发送到这个区域，直到一些写入完成。 默认: 1 hbase.client.perserver.requests.threshold 所有客户端线程（进程级别）中一个服务器的并发未决请求的最大数量。超过请求将立即抛出ServerTooBusyException，以防止用户的线程被占用和只被一个缓慢的区域服务器阻止。如果使用固定数量的线程以同步方式访问HBase，请将此值设置为与线程数量相关的适当值，这些值将对您有所帮助。详见:https://issues.apache.org/jira/browse/HBASE-16388 默认: 2147483647 hbase.client.scanner.caching 如果从本地，客户端内存中未提供，则在扫描程序上调用next时尝试获取的行数。此配置与hbase.client.scanner.max.result.size一起使用，可以有效地使用网络。缺省值默认为Integer.MAX_VALUE，这样网络将填充由hbase.client.scanner.max.result.size定义的块大小，而不受特定行数的限制，因为行的大小随表格的不同而不同。如果您事先知道扫描中不需要超过一定数量的行，则应通过扫描＃setCaching将此配置设置为该行限制。缓存值越高，扫描器的速度越快，但是会占用更多的内存，而当缓存空置时，下一次调用的时间可能会越来越长。请勿设置此值，以便调用之间的时间大于扫描器超时；即hbase.client.scanner.timeout.period 默认: 2147483647 hbase.client.keyvalue.maxsize 指定KeyValue实例的组合的最大允许大小。这是为保存在存储文件中的单个条目设置上限。由于它们不能被分割，所以有助于避免因为数据太大而导致地区不能被分割。将此设置为最大区域大小的一小部分似乎是明智的。将其设置为零或更少将禁用检查。 默认: 10485760 hbase.server.keyvalue.maxsize 单个单元格的最大允许大小，包括值和所有关键组件。值为0或更小将禁用检查。默认值是10MB。这是保护服务器免受OOM情况的安全设置。 默认: 10485760 hbase.client.scanner.timeout.period 客户端扫描程序的租期以毫秒为单位。 默认: 60000 hbase.client.localityCheck.threadPoolSize 默认: 2 hbase.bulkload.retries.number 最大重试次数，这是在面对分裂操作时尝试原子批量加载的最大迭代次数，0意味着永不放弃。 默认: 10 hbase.master.balancer.maxRitPercent 平衡时转换区域的最大百分比。默认值是1.0。所以没有平衡器节流。如果将此配置设置为0.01，则意味着在平衡时转换中最多有1％的区域。那么当平衡时，集群的可用性至少为99％。 默认: 1.0 hbase.balancer.period 区域平衡器在主站运行的时间段。 默认: 300000 hbase.normalizer.period 区域标准化程序在主程序中运行的时段。 默认: 300000 hbase.normalizer.min.region.count 区域标准化程序最小数量 默认: 3 hbase.regions.slop 如果任何区域服务器具有平均值+（平均*斜率）区域，则重新平衡。StochasticLoadBalancer（默认负载均衡器）中此参数的默认值为0.001，其他负载均衡器（即SimpleLoadBalancer）中的默认值为0.2。 默认: 0.001 hbase.server.thread.wakefrequency 在两次搜索之间休息的时间（以毫秒为单位）。用作日志滚筒等服务线程的睡眠间隔。 默认: 10000 hbase.server.versionfile.writeattempts 在放弃之前重试尝试写入版本文件的次数。每个尝试都由hbase.server.thread.wake频率毫秒分隔。 默认: 3 hbase.hregion.memstore.flush.size 如果memstore的大小超过此字节数，Memstore将被刷新到磁盘。值由每个hbase.server.thread.wakefrequency运行的线程检查。 默认: 134217728 hbase.hregion.percolumnfamilyflush.size.lower.bound.min 如果使用了FlushLargeStoresPolicy，并且有多个列族，那么每当我们达到完全的memstore限制时，我们就会找出所有memstore超过“下限”的列族，只有在保留其他内存的同时刷新它们。默认情况下，“下限”将是“hbase.hregion.memstore.flush.size/column_family_number”，除非该属性的值大于该值。如果没有一个族的memstore大小超过下限，所有的memstore都将被刷新（就像往常一样）。 默认: 16777216 hbase.hregion.preclose.flush.size 如果我们关闭时某个区域的存储空间大于或等于这个大小，则可以运行“预先刷新（pre-flush）”来清除存储区，然后再放置区域关闭标记并使区域脱机。关闭时，在关闭标志下运行刷新以清空内存。在此期间，该地区处于离线状态，我们没有进行任何写入。如果memstore内容很大，则此刷新可能需要很长时间才能完成。这个预刷新是为了清理大部分的memstore，然后把关闭标志放到离线区域，这样在关闭标志下运行的刷新没有什么用处。 默认: 5242880 hbase.hregion.memstore.block.multiplier 如果memstore具有hbase.hregion.memstore.block.multiplier乘以hbase.hregion.memstore.flush.size个字节，则阻止更新。在更新通信高峰期间有用的防止失控的memstore。如果没有上限，memstore就会填满，当刷新生成的flush文件需要很长时间才能压缩或拆分。 默认: 4 hbase.hregion.memstore.mslab.enabled 启用MemStore-Local分配缓冲区，该功能可用于在繁重的写入负载下防止堆碎片。这可以减少在大堆停止全局GC pause的频率。 默认: true hbase.hregion.max.filesize 最大HFile大小。如果一个地区的HFiles的总和已经超过了这个数值，这个地区就会被分成两部分。 默认: 10737418240 hbase.hregion.majorcompaction 主要压缩之间的时间，以毫秒表示。设置为0可禁用基于时间的自动重要压缩。用户请求的和基于大小的主要压缩将仍然运行。这个值乘以hbase.hregion.majorcompaction.jitter，使压缩在一个给定的时间窗口内稍微随机的时间开始。默认值是7天，以毫秒表示。如果主要压缩导致您的环境中断，则可以将它们配置为在部署的非高峰时间运行，或者通过将此参数设置为0来禁用基于时间的主要压缩，并在cron作业或另一个外部机制。 默认: 604800000 hbase.hregion.majorcompaction.jitter 应用于hbase.hregion.majorcompaction的乘数会导致压缩发生在给定的时间量的任何一侧的hbase.hregion.majorcompaction。数字越小，压缩将越接近hbase.hregion.majorcompaction时间间隔。 默认: 0.50 hbase.hstore.compactionThreshold 如果任何一个Store中存在超过此数量的StoreFiles（每个MemStore刷新一个StoreFile），则会执行压缩以将所有StoreFile重写为单个StoreFile。较大的值会延迟压实，但是当压缩发生时，需要较长时间才能完成。 默认: 3 hbase.regionserver.compaction.enabled 开启/关闭 压缩 通过设置true/false.也可以通过 compaction_switch shell命令 默认: true hbase.hstore.flusher.count 刷新线程的数量。用更少的线程，MemStore刷新将排队。随着线程数量的增加，刷新将并行执行，增加了HDFS的负载，并可能导致更多的压缩。 默认: 2 hbase.hstore.blockingStoreFiles 如果任何一个Store中存在超过此数量的StoreFiles（每次刷新MemStore时将写入一个StoreFile），则会阻止该区域的更新，直到压缩完成或超出hbase.hstore.blockingWaitTime。 默认: 16 hbase.hstore.blockingWaitTime 在达到hbase.hstore.blockingStoreFiles定义的StoreFile限制后，区域将阻止更新的时间。经过这段时间后，即使压缩尚未完成，该地区也将停止阻止更新。 默认: 90000 hbase.hstore.compaction.min 压缩可以运行之前，必须有符合进行压缩条件的最小StoreFiles数量。调整hbase.hstore.compaction.min的目标是避免使用太多的小型StoreFiles来压缩。如果将此值设置为2，则每次在Store中有两个StoreFiles时会导致轻微的压缩，这可能不合适。如果将此值设置得太高，则需要相应调整所有其他值。对于大多数情况下，默认值是适当的。在以前的HBase版本中，参数hbase.hstore.compaction.min被命名为hbase.hstore.compactionThreshold。 默认: 3 hbase.hstore.compaction.max 无论符合条件的StoreFiles的数量如何，将为单个次要压缩选择的StoreFiles的最大数量。有效地，hbase.hstore.compaction.max的值控制单个压缩完成所需的时间长度。将其设置得更大意味着更多的StoreFiles包含在压缩中。对于大多数情况下，默认值是适当的。 默认: 10 hbase.hstore.compaction.min.size StoreFile（或使用ExploringCompactionPolicy时选择的StoreFiles）小于此大小将始终有资格进行轻微压缩。这个大小或更大的HFile通过hbase.hstore.compaction.ratio进行计算，以确定它们是否合格。由于此限制表示所有StoreFiles的“自动包含”限制小于此值，因此在需要刷新多个StoreFile（1-2 MB范围内的许多StoreFiles）的写入繁重环境中可能需要降低此值，因为每个StoreFile都将作为目标，对于压缩而言，所得到的StoreFile可能仍然在最小尺寸下，并且需要进一步的压缩。如果此参数降低，比率检查会更快地触发。这解决了在早期版本的HBase中看到的一些问题，但是在大多数情况下不再需要更改此参数。 默认: 134217728 hbase.hstore.compaction.max.size StoreFile（或使用ExploringCompactionPolicy时选择的StoreFiles）大于此大小将被排除在压缩之外。提高hbase.hstore.compaction.max.size的效果较少，较大的StoreFiles不经常压缩。如果你觉得压缩过于频繁而没有太多好处，你可以尝试提高这个价值。默认值：LONG.MAX_VALUE的值，以字节表示。 默认: 9223372036854775807 hbase.hstore.compaction.ratio 对于轻微压缩，此比率用于确定大于hbase.hstore.compaction.min.size的给定StoreFile是否适合压缩。其作用是限制大型StoreFiles的压缩。hbase.hstore.compaction.ratio的值以浮点小数表示。一个很大的比例，如10，将产生一个大型的StoreFile。相反，低值（如0.25）会产生类似于BigTable压缩算法的行为，产生四个StoreFiles。推荐使用1.0到1.4之间的中等数值。在调整此值时，您要平衡写入成本与读取成本。提高价值（如1.4）会有更多的写入成本，因为你会压缩更大的StoreFiles。然而，在读取期间，HBase将需要通过更少的StoreFiles来完成读取。如果您不能利用Bloom过滤器，请考虑使用这种方法。否则，可以将此值降低到1.0以降低写入的背景成本，并使用Bloom过滤器来控制读取期间触摸的StoreFiles的数量。对于大多数情况下，默认值是适当的。 默认: 1.2F hbase.hstore.compaction.ratio.offpeak 允许您设置不同（默认情况下，更积极）的比率，以确定在非高峰时段是否包含较大的StoreFiles。以与hbase.hstore.compaction.ratio相同的方式工作。仅当hbase.offpeak.start.hour和hbase.offpeak.end.hour也被启用时才适用。 默认: 5.0F hbase.hstore.time.to.purge.deletes 使用未来的时间戳延迟清除标记的时间。如果未设置，或设置为0，则将在下一个主要压缩过程中清除所有删除标记（包括具有未来时间戳的标记）。否则，将保留一个删除标记，直到在标记的时间戳之后发生的主要压缩加上此设置的值（以毫秒为单位）。 默认: 0 hbase.offpeak.start.hour 非高峰时段开始，以0到23之间的整数表示，包括0和23之间的整数。设置为-1以禁用非高峰。 默认: -1 hbase.offpeak.end.hour 非高峰时段结束，以0到23之间的整数表示，包括0和23之间的整数。设置为-1以禁用非高峰。 默认: -1 hbase.regionserver.thread.compaction.throttle 有两个不同的线程池用于压缩，一个用于大型压缩，另一个用于小型压缩。这有助于保持精简表（如hbase：meta）的快速压缩。如果压缩度大于此阈值，则会进入大型压缩池。在大多数情况下，默认值是适当的。默认值：2 x hbase.hstore.compaction.max x hbase.hregion.memstore.flush.size（默认为128MB）。值字段假定hbase.hregion.memstore.flush.size的值与默认值相同。 默认: 2684354560 hbase.regionserver.majorcompaction.pagecache.drop 指定是否通过主要压缩删除读取/写入系统页面缓存的页面。将其设置为true有助于防止重大压缩污染页面缓存，这几乎总是要求的，特别是对于具有低/中等内存与存储率的群集。 默认: true hbase.regionserver.minorcompaction.pagecache.drop 指定是否通过较小的压缩删除读取/写入系统页面缓存的页面。将其设置为true有助于防止轻微压缩污染页面缓存，这对于内存与存储比率较低的群集或写入较重的群集是最有利的。当大部分读取位于最近写入的数据上时，您可能希望在中等到低写入工作负载下将其设置为false。 默认: true hbase.hstore.compaction.kv.max 刷新或压缩时要读取并批量写入的KeyValues的最大数量。如果你有较大的KeyValues，并且Out Of Memory Exceptions有问题，请将它设置得更低。 默认: 10 hbase.storescanner.parallel.seek.enable 在StoreScanner中启用StoreFileScanner并行搜索功能，该功能可以在特殊情况下减少响应延迟。 默认: false hbase.storescanner.parallel.seek.threads 如果启用了并行查找功能，则默认线程池大小。 默认: 10 hfile.block.cache.size StoreFile使用的最大堆（-Xmx设置）分配给块缓存的百分比。默认值为0.4意味着分配40％。设置为0禁用，但不建议；您至少需要足够的缓存来保存存储文件索引。 默认: 0.4 hfile.block.index.cacheonwrite 这允许在索引被写入时将非根多级索引块放入块高速缓存中。 默认: false hfile.index.block.max.size 当多级块索引中叶级，中级或根级索引块的大小增长到这个大小时，块将被写出并启动一个新块。 默认: 131072 hbase.bucketcache.ioengine 在哪里存储bucketcache的内容。其中之一：offheap、文件或mmap。如果有文件，则将其设置为file(s)：PATH_TO_FILE。mmap意味着内容将在一个mmaped文件中。使用mmap：PATH_TO_FILE。详见: http://hbase.apache.org/book.html#offheap.blockcache 默认: none hbase.bucketcache.size EITHER表示缓存的总堆内存大小的百分比（如果小于1.0），则表示BucketCache的总容量（兆字节）。默认值：0.0 默认: none hbase.bucketcache.bucket.sizes 用于bucketcache的存储区大小的逗号分隔列表。可以是多种尺寸。列出从最小到最大的块大小。您使用的大小取决于您的数据访问模式。必须是256的倍数，否则当你从缓存中读取时，你会遇到“java.io.IOException：Invalid HFile block magic”。如果您在此处未指定任何值，那么您可以选取代码中设置的默认bucketsizes。 默认: none hfile.format.version 用于新文件的HFile格式版本。版本3添加了对hfiles中标签的支持（请参阅 http://hbase.apache.org/book.html#hbase.tags）。另请参阅配置“hbase.replication.rpc.codec”。 默认: 3 hfile.block.bloom.cacheonwrite 为复合Bloom过滤器的内联块启用写入缓存。 默认: false io.storefile.bloom.block.size 复合Bloom过滤器的单个块（“chunk”）的字节大小。这个大小是近似的，因为Bloom块只能被插入到数据块的边界处，而每个数据块的key的个数也不相同。 默认: 131072 hbase.rs.cacheblocksonwrite 块完成后，是否应将HFile块添加到块缓存中。 默认: false hbase.rpc.timeout 这是为了让RPC层定义一个远程调用超时（毫秒）HBase客户端应用程序超时。它使用ping来检查连接，但最终会抛出TimeoutException。 默认: 60000 hbase.client.operation.timeout 操作超时是一个顶级的限制（毫秒），确保表格中的阻止操作不会被阻止超过这个限制。在每个操作中，如果rpc请求由于超时或其他原因而失败，则将重试直到成功或抛出RetriesExhaustedException。但是，如果总的阻塞时间在重试耗尽之前达到操作超时，则会提前中断并抛出SocketTimeoutException。 默认: 1200000 hbase.cells.scanned.per.heartbeat.check 在heartbeat检查之间扫描的单元格的数量。在扫描处理过程中会发生heartbeat检查，以确定服务器是否应该停止扫描，以便将heartbeat消息发送回客户端。heartbeat消息用于在长时间运行扫描期间保持客户端 - 服务器连接的活动。较小的值意味着heartbeat检查将更频繁地发生，因此将对扫描的执行时间提供更严格的界限。数值越大意味着heartbeat检查发生的频率越低。 默认: 10000 hbase.rpc.shortoperation.timeout 这是“hbase.rpc.timeout”的另一个版本。对于集群内的RPC操作，我们依靠此配置为短操作设置短超时限制。例如，区域服务器试图向活动主服务器报告的短rpc超时可以更快地进行主站故障转移过程。 默认: 10000 hbase.ipc.client.tcpnodelay 在rpc套接字连接上设置没有延迟。详见: http://docs.oracle.com/javase/1.5.0/docs/api/java/net/Socket.html#getTcpNoDelay() 默认: true hbase.regionserver.hostname 这个配置适用于对HBase很熟悉的人：除非你真的知道你在做什么，否则不要设定它的价值。当设置为非空值时，这表示底层服务器的（面向外部）主机名。 详见: https://issues.apache.org/jira/browse/HBASE-12954 默认: none hbase.regionserver.hostname.disable.master.reversedns 这个配置适用于对HBase很熟练的人：除非你真的知道你在做什么，否则不要设定它的价值。当设置为true时，regionserver将使用当前节点主机名作为服务器名称，HMaster将跳过反向DNS查找并使用regionserver发送的主机名。请注意，此配置和hbase.regionserver.hostname是互斥的。详见: https://issues.apache.org/jira/browse/HBASE-18226 默认: false hbase.master.keytab.file 用于登录配置的HMaster服务器主体的kerberos密钥表文件的完整路径。 默认: none hbase.master.kerberos.principal Ex. “hbase/_HOST@EXAMPLE.COM”应该用来运行HMaster进程的Kerberos主体名称。主体名称的格式应为：user/hostname @ DOMAIN。如果使用“_HOST”作为主机名部分，它将被替换为正在运行的实例的实际主机名。 默认: none hbase.regionserver.keytab.file 用于登录配置的HRegionServer服务器主体的kerberos密钥表文件的完整路径。 默认: none hbase.regionserver.kerberos.principal Ex. “hbase/_HOST@EXAMPLE.COM”应该用来运行HRegionServer进程的kerberos主体名称。主体名称的格式应为：user/hostname @ DOMAIN。如果使用“_HOST”作为主机名部分，它将被替换为正在运行的实例的实际主机名。此主体的条目必须存在于hbase.regionserver.keytab.file中指定的文件中 默认: none hadoop.policy.file RPC服务器使用策略配置文件对客户端请求进行授权决策。仅在启用HBase安全性时使用。 默认: hbase-policy.xml hbase.superuser 用户或组列表（以逗号分隔），允许在整个集群中拥有完全权限（不管存储的ACL）。仅在启用HBase安全性时使用。 默认: none hbase.auth.key.update.interval 服务器中认证令牌的主密钥的更新间隔（以毫秒为单位）。仅在启用HBase安全性时使用。 默认: 86400000 hbase.auth.token.max.lifetime 验证令牌过期的最长生存时间（以毫秒为单位）。仅在启用HBase安全性时使用。 默认: 604800000 hbase.ipc.client.fallback-to-simple-auth-allowed 当客户端配置为尝试安全连接，但尝试连接到不安全的服务器时，该服务器可能会指示客户端切换到SASL SIMPLE（不安全）身份验证。此设置控制客户端是否接受来自服务器的此指令。如果为false（默认值），则客户端将不允许回退到SIMPLE身份验证，并会中止连接。 默认: false hbase.ipc.server.fallback-to-simple-auth-allowed 当服务器配置为需要安全连接时，它将拒绝来自使用SASL SIMPLE（不安全）身份验证的客户端的连接尝试。此设置允许安全服务器在客户端请求时接受来自客户端的SASL SIMPLE连接。如果为false（默认值），服务器将不允许回退到SIMPLE身份验证，并将拒绝连接。警告：只有在将客户端转换为安全身份验证时，才应将此设置用作临时措施。必须禁止它才能进行安全操作。 默认: false hbase.display.keys 当它被设置为true时，webUI等将显示所有开始/结束键作为表格细节，区域名称等的一部分。当这被设置为假时，键被隐藏。 默认: true hbase.coprocessor.enabled 启用或禁用协处理器加载。如果’false’（禁用），任何其他协处理器相关的配置将被忽略。 默认: true hbase.coprocessor.user.enabled 启用或禁用用户（又名表）协处理器加载。如果’false’（禁用），则表格描述符中的任何表协处理器属性将被忽略。如果“hbase.coprocessor.enabled”为“false”，则此设置无效。 默认: true hbase.coprocessor.region.classes 在所有表上默认加载的区域观察者或端点协处理器的逗号分隔列表。对于任何覆盖协处理器方法，这些类将按顺序调用。在实现自己的协处理器之后，将其添加到HBase的类路径中，并在此处添加完全限定的类名称。协处理器也可以通过设置HTableDescriptor或者HBase shell来按需加载。 默认: none hbase.coprocessor.master.classes 在活动的HMaster进程中默认加载的org.apache.hadoop.hbase.coprocessor.MasterObserver协处理器的逗号分隔列表。对于任何实施的协处理器方法，列出的类将按顺序调用。在实现你自己的MasterObserver之后，把它放在HBase的类路径中，并在这里添加完全限定的类名称。 默认: none hbase.coprocessor.abortonerror 如果协处理器加载失败，初始化失败或引发意外的Throwable对象，则设置为true将导致托管服务器（主服务器或区域服务器）中止。将其设置为false将允许服务器继续执行，但所涉及的协处理器的系统范围状态将变得不一致，因为它只能在一部分服务器中正确执行，所以这对于仅调试是非常有用的。 默认: true hbase.rest.port HBase REST服务器的端口。 默认: 8080 hbase.rest.readonly 定义REST服务器将启动的模式。可能的值有：false：此时，所有的HTTP方法都是允许的 - GET / PUT / POST / DELETE。true：此时只允许GET方法。 默认: false hbase.rest.threads.max REST服务器线程池的最大线程数。池中的线程被重用来处理REST请求。这将控制同时处理的最大请求数。这可能有助于控制REST服务器使用的内存以避免OOM问题。如果线程池已满，则传入的请求将排队并等待一些空闲的线程。 默认: 100 hbase.rest.threads.min REST服务器线程池的最小线程数。线程池总是至少有这么多的线程，所以REST服务器已经准备好为传入的请求提供服务。 默认: 2 hbase.rest.support.proxyuser 启用运行REST服务器以支持代理用户模式。 默认: false hbase.defaults.for.version.skip 设置为true可以跳过“hbase.defaults.for.version”检查。将其设置为true可以在除maven生成的另一侧之外的上下文中有用；即运行在IDE中。你需要设置这个布尔值为true以避免看到RuntimeException：“hbase-default.xml文件似乎是HBase（\ $ {hbase.version}）的旧版本，这个版本是XXX-SNAPSHOT” 默认: false hbase.table.lock.enable 设置为true以启用锁定zookeeper中的表以进行模式更改操作。从主服务器锁定表可以防止并发的模式修改损坏表状态。 默认: true hbase.table.max.rowsize 单行字节的最大大小（默认值为1 Gb），用于Get-ing或Scan’ning，不设置行内扫描标志。如果行大小超过此限制RowTooBigException被抛出到客户端。 默认: 1073741824 hbase.thrift.minWorkerThreads 线程池的“核心大小”。在每个连接上创建新线程，直到创建了许多线程。 默认: 16 hbase.thrift.maxWorkerThreads 线程池的最大大小。待处理的请求队列溢出时，将创建新线程，直到其号码达到此数字。之后，服务器开始丢弃连接。 默认: 1000 hbase.thrift.maxQueuedRequests 在队列中等待的最大等待节点连接数。如果池中没有空闲线程，则服务器将请求排队。只有当队列溢出时，才会添加新的线程，直到hbase.thrift.maxQueuedRequests线程。 默认: 1000 hbase.regionserver.thrift.framed 在服务器端使用Thrift TFramedTransport。对于thrift服务器，这是推荐的传输方式，需要在客户端进行类似的设置。将其更改为false将选择默认传输，当由于THRIFT-601发出格式错误的请求时，容易受到DoS的影响。 默认: false hbase.regionserver.thrift.framed.max_frame_size_in_mb 使用成帧传输时的默认帧大小，以MB为单位。 默认: 2 hbase.regionserver.thrift.compact 使用Thrift TCompactProtocol二进制序列化协议。 默认: false hbase.rootdir.perms 安全（kerberos）安装程序中根数据子目录的FS Permissions。主服务器启动时，会使用此权限创建rootdir，如果不匹配则设置权限。 默认: 700 hbase.wal.dir.perms 安全（kerberos）安装程序中的根WAL目录的FS Permissions。当主服务器启动时，它将使用此权限创建WAL目录，如果不匹配则设置权限。 默认: 700 hbase.data.umask.enable 如果启用，则启用该文件权限应分配给区域服务器写入的文件 默认: false hbase.data.umask 当hbase.data.umask.enable为true时，应该用来写入数据文件的文件权限 默认: 000 hbase.snapshot.enabled 设置为true以允许taken/restored/cloned。 默认: true hbase.snapshot.restore.take.failsafe.snapshot 设置为true以在还原操作之前得到快照。所得到的快照将在失败的情况下使用，以恢复以前的状态。在还原操作结束时，此快照将被删除 默认: true hbase.snapshot.restore.failsafe.name restore操作所采用的故障安全快照的名称。您可以使用{snapshot.name}，{table.name}和{restore.timestamp}变量根据要恢复的内容创建一个名称。 默认: hbase-failsafe-{snapshot.name}-{restore.timestamp} hbase.snapshot.working.dir 快照过程将发生的位置。已完成快照的位置不会更改，但快照进程发生的临时目录将设置为此位置。为了提高性能，它可以是一个独立的文件系统，而不是根目录。有关详细信息，请参阅HBase-21098 默认: none hbase.server.compactchecker.interval.multiplier 这个数字决定了我们扫描的频率，看是否需要压缩。通常情况下，压缩是在某些事件（如memstore flush）之后完成的，但是如果区域在一段时间内没有收到大量的写入，或者由于不同的压缩策略，则可能需要定期检查。检查之间的时间间隔是hbase.server.compactchecker.interval.multiplier乘以hbase.server.thread.wakefrequency。 默认: 1000 hbase.lease.recovery.timeout 在放弃之前，我们等待dfs lease的总恢复时间。 默认: 900000 hbase.lease.recovery.dfs.timeout dfs恢复lease调用之间的时间间隔。应该大于namenode为datanode的一部分发出块恢复命令所需的时间总和；dfs.heartbeat.interval和主数据节点所花费的时间，在死数据节点上执行数据块恢复到超时；通常是dfs.client.socket-timeout。详见:HBASE-8389 默认: 64000 hbase.column.max.version 新的列族描述符将使用此值作为要保留的默认版本数。 默认: 1 dfs.client.read.shortcircuit 如果设置为true，则此配置参数启用short-circuit本地读取。 默认: false dfs.domain.socket.path 如果将dfs.client.read.shortcircuit设置为true，则这是一个UNIX域套接字的路径，该套接字将用于DataNode与本地HDFS客户端之间的通信。如果该路径中存在字符串“_PORT”，则会被DataNode的TCP端口替换。请注意托管共享域套接字的目录的权限。 默认: none hbase.dfs.client.read.shortcircuit.buffer.size 如果未设置DFSClient配置dfs.client.read.shortcircuit.buffer.size，我们将使用此处配置的内容作为short-circuit读取默认直接字节缓冲区大小。DFSClient本机默认值是1MB；HBase保持HDFS文件的打开状态，所以文件块*1MB的数量很快就开始累积起来，并由于直接内存不足而威胁OOME。所以，我们从默认设置下来。使它大于在HColumnDescriptor中设置的默认hbase块大小，通常是64k。 默认: 131072 hbase.regionserver.checksum.verify 如果设置为true（默认），HBase将验证hfile块的校验和。当HBase写出hfiles时，HBase将校验和写入数据。HDFS（在此写入时）将校验和写入单独的文件，而不是需要额外查找的数据文件。设置这个标志可以节省一些I/O。设置此标志时，HDFS的校验和验证将在hfile流内部禁用。如果hbase-checksum验证失败，我们将切换回使用HDFS校验和（所以不要禁用HDFS校验！除此功能外，还适用于hfiles，而不适用于WAL）。如果这个参数设置为false，那么hbase将不会验证任何校验和，而是取决于HDFS客户端中的校验和验证。 默认: true hbase.hstore.bytes.per.checksum 新创建的校验和块中的字节数，用于hfile块中的HBase级校验和。 默认: 16384 hbase.hstore.checksum.algorithm 用于计算校验和的算法的名称。可能的值是NULL，CRC32，CRC32C。 默认: CRC32C hbase.client.scanner.max.result.size 调用扫描器的下一个方法时返回的最大字节数。请注意，当单个行大于此限制时，行仍然完全返回。默认值是2MB，这对于1ge网络是有好处的。有了更快和/或更高的延迟网络，这个值应该增加。 默认: 2097152 hbase.server.scanner.max.result.size 调用扫描器的下一个方法时返回的最大字节数。请注意，当单个行大于此限制时，行仍然完全返回。默认值是100MB。这是保护服务器免受OOM情况的安全设置。 默认: 104857600 hbase.status.published 该设置激活了主控发布区域服务器的状态。当一台区域服务器死亡并开始恢复时，主服务器会将这些信息推送到客户端应用程序，让他们立即切断连接，而不是等待超时。 默认: false hbase.status.publisher.class 用multicast消息实现状态发布。 默认: org.apache.hadoop.hbase.master.ClusterStatusPublisher$MulticastPublisher hbase.status.listener.class 使用multicast消息实现状态监听器。 默认: org.apache.hadoop.hbase.client.ClusterStatusListener$MulticastListener hbase.status.multicast.address.ip 用于multicase状态发布的multicase地址。 默认: 226.1.1.3 hbase.status.multicast.address.port 用于multicase状态发布的multicase端口。 默认: 16100 hbase.dynamic.jars.dir 自定义过滤器JAR的目录可以由区域服务器动态加载，而无需重新启动。但是，已加载的过滤器/协处理器类将不会被卸载。不适用于协处理器。详见:HBASE-1936 默认: ${hbase.rootdir}/lib hbase.security.authentication 控制是否为HBase启用安全身份验证。可能的值是“simple”（不认证）和“Kerberos”。 默认: simple hbase.rest.filter.classes 用于REST服务的Servlet过滤器。 默认: org.apache.hadoop.hbase.rest.filter.GzipFilter hbase.master.loadbalancer.class 用于在期间发生时执行区域平衡的类。它将DefaultLoadBalancer替换为默认值（因为它被重命名为SimpleLoadBalancer ）。详见: http://hbase.apache.org/devapidocs/org/apache/hadoop/hbase/master/balancer/StochasticLoadBalancer.html 默认: org.apache.hadoop.hbase.master.balancer.StochasticLoadBalancer hbase.master.loadbalance.bytable 平衡器运行时的因子表名称。默认：false。 默认: false hbase.master.normalizer.class 用于执行期间发生时的区域标准化的类。详见: http://hbase.apache.org/devapidocs/org/apache/hadoop/hbase/master/normalizer/SimpleRegionNormalizer.html 默认: org.apache.hadoop.hbase.master.normalizer.SimpleRegionNormalizer hbase.rest.csrf.enabled 设置为true以启用跨站请求伪造的保护。 默认: false hbase.rest-csrf.browser-useragents-regex 通过将hbase.rest.csrf.enabled设置为true来启用为REST服务器，针对跨站点请求伪造（CSRF）的防护时，用于匹配HTTP请求的User-Agent标头的正则表达式的逗号分隔列表。如果传入的用户代理与这些正则表达式中的任何一个相匹配，则认为该请求被浏览器发送，因此CSRF预防被强制执行。如果请求的用户代理与这些正则表达式中的任何一个都不匹配，则该请求被认为是由除浏览器以外的其他东西发送的，例如脚本自动化。在这种情况下，CSRF不是一个潜在的攻击向量，所以预防没有被执行。这有助于实现与尚未更新以发送CSRF预防报头的现有自动化的向后兼容性。 默认: &lt;sup&gt;Mozilla.**,**&lt;/sup&gt;**Opera.** hbase.security.exec.permission.checks 如果启用此设置，并且基于ACL的访问控制处于活动状态（AccessController协处理器作为系统协处理器安装，或作为表协处理器安装在表上），则必须授予所有相关用户EXEC权限（如果需要执行协处理器端点调用。像任何其他权限一样，EXEC权限可以在全局范围内授予用户，也可以授予每个表或命名空间的用户。有关协处理器端点的更多信息，请参阅HBase联机手册的协处理器部分。有关使用AccessController授予或撤消权限的更多信息，请参阅HBase联机手册的安全性部分。 默认: false hbase.procedure.regionserver.classes 在活动HRegionServer进程中默认加载的org.apache.hadoop.hbase.procedure.RegionServerProcedureManager过程管理器的逗号分隔列表。生命周期方法（init / start / stop）将由活动的HRegionServer进程调用，以执行特定的全局barriered过程。在实现你自己的RegionServerProcedureManager之后，把它放在HBase的类路径中，并在这里添加完全限定的类名称。 默认: none hbase.procedure.master.classes 在活动HMaster进程中默认加载的org.apache.hadoop.hbase.procedure.MasterProcedureManager过程管理器的逗号分隔列表。程序通过其签名进行标识，用户可以使用签名和即时名称来触发全局程序的执行。在实现你自己的MasterProcedureManager之后，把它放在HBase的类路径中，并在这里添加完全限定的类名称。 默认: none hbase.coordinated.state.manager.class 协调状态管理员的完全合格的名字。 默认: org.apache.hadoop.hbase.coordination.ZkCoordinatedStateManager hbase.regionserver.storefile.refresh.period 用于刷新辅助区域的存储文件的时间段（以毫秒为单位）。0意味着此功能被禁用。辅助区域在次要区域刷新区域中的文件列表时会看到来自主要文件的新文件（来自刷新和压缩）（没有通知机制）。但是频繁刷新可能会导致额外的Namenode压力。如果文件的刷新时间不能超过HFile TTL（hbase.master.hfilecleaner.ttl），请求将被拒绝。此设置还建议将HFile TTL配置为较大的值。 默认: 0 hbase.region.replica.replication.enabled 是否启用对辅助区域副本的异步WAL复制。如果启用了此功能，则会创建一个名为“region_replica_replication”的复制对等项，它将对日志进行尾随处理，并将突变复制到区域复制大于1的区域复制的区域复制。如果启用一次，禁用此复制也需要禁用复制对等使用shell或Admin java类。复制到辅助区域副本可以在标准群集间复制上工作。 默认: false hbase.http.filter.initializers 一个以逗号分隔的类名列表。列表中的每个类都必须扩展org.apache.hadoop.hbase.http.FilterInitializer。相应的过滤器将被初始化。然后，过滤器将应用于所有面向jsp和servlet网页的用户。列表的排序定义了过滤器的排序。默认的StaticUserWebFilter添加hbase.http.staticuser.user属性定义的用户主体。 默认: org.apache.hadoop.hbase.http.lib.StaticUserWebFilter hbase.security.visibility.mutations.checkauths 如果启用此属性，将检查可见性表达式中的标签是否与发出突变的用户相关联 默认: false hbase.http.max.threads HTTP服务器将在其ThreadPool中创建的最大线程数。 默认: 16 hbase.replication.rpc.codec 启用复制时要使用的编解码器，以便标签也被复制。这与支持标签的HFileV3一起使用。如果标签未被使用或者所使用的hfile版本是HFileV2，则可以使用KeyValueCodec作为复制编解码器。请注意，在没有标签时使用KeyValueCodecWithTags进行复制不会造成任何伤害。 默认: org.apache.hadoop.hbase.codec.KeyValueCodecWithTags hbase.replication.source.maxthreads 任何复制源将用于并行传送编辑到接收器的最大线程数。这也限制了每个复制批次被分解成的块的数量。较大的值可以提高主群集和从群集之间的复制吞吐量。默认值为10，很少需要改变。 默认: 10 hbase.http.staticuser.user 要在呈现内容时在静态网页过滤器上过滤的用户名称。一个示例使用是HDFS Web UI（用于浏览文件的用户）。 默认: dr.stack hbase.regionserver.handler.abort.on.error.percent 区域服务器RPC线程的百分比无法中止RS。-1表示禁用中止；0表示即使单个处理程序已经死亡也会中止；0.x表示只有当这个百分比的处理程序死亡时才中止；1表示只中止所有的处理程序已经死亡。 默认: 0.5 hbase.mob.file.cache.size 要缓存的已打开文件处理程序的数量。更大的值将通过为每个移动文件缓存提供更多的文件处理程序来减少频繁的文件打开和关闭，从而有利于读取。但是，如果设置得太高，则可能导致“打开的文件处理程序太多”。默认值为1000。 默认: 1000 hbase.mob.cache.evict.period mob高速缓存驱逐高速缓存的mob文件之前的时间（秒）。默认值是3600秒。 默认: 3600 hbase.mob.cache.evict.remain.ratio 当缓存的移动文件数量超过hbase.mob.file.cache.size时，触发驱逐后保留的文件的比率（介于0.0和1.0之间）会被触发。默认值是0.5f。 默认: 0.5f hbase.master.mob.ttl.cleaner.period ExpiredMobFileCleanerChore运行的时间段。该单位是秒。默认值是一天。MOB文件名仅使用文件创建时间的日期部分。我们使用这个时间来决定文件的TTL到期时间。所以删除TTL过期的文件可能会被延迟。最大延迟可能是24小时。 默认: 86400 hbase.mob.compaction.mergeable.threshold 如果一个mob文件的大小小于这个值，那么它被认为是一个小文件，需要在mob compaction中合并。默认值是1280MB。 默认: 1342177280 hbase.mob.delfile.max.count mob压缩中允许的最大del文件数。在mob压缩中，当现有的del文件的数量大于这个值时，它们被合并，直到del文件的数量不大于该值。默认值是3。 默认: 3 hbase.mob.compaction.batch.size 在一批mob压缩中所允许的mob文件的最大数量。mob压缩合并小的mob文件到更大的。如果小文件的数量非常大，则可能导致合并中的“打开的文件处理程序太多”。合并必须分成批次。此值限制在一批mob压缩中选择的mob文件的数量。默认值是100。 默认: 100 hbase.mob.compaction.chore.period MobCompactionChore运行的时间。该单位是秒。默认值是一个星期。 默认: 604800 hbase.mob.compactor.class 执行mob compactor，默认一个是PartitionedMobCompactor。 默认: org.apache.hadoop.hbase.mob.compactions.PartitionedMobCompactor hbase.mob.compaction.threads.max MobCompactor中使用的最大线程数。 默认: 1 hbase.snapshot.master.timeout.millis 主快照程序执行的超时。 默认: 300000 hbase.snapshot.region.timeout 区域服务器将线程保持在快照请求池中等待超时。 默认: 300000 hbase.rpc.rows.warning.threshold 批处理操作中的行数，超过该值将记录警告。 默认: 5000 hbase.master.wait.on.service.seconds 默认是5分钟。做30秒的测试。有关上下文，请参见HBASE-19794。 默认: 30 7.3. _hbase-env.sh_hbase-env.sh文件用来设置HBase环境变量。比如包括在启动HBase守护程序（如堆大小和垃圾回收器配置）时传递JVM的选项。您还可以设置HBase配置、日志目录、niceness、ssh选项，定位进程pid文件的位置等的配置。打开_conf/hbase-env.sh_文件并仔细阅读其内容。每个选项都有相当好的记录。如果希望在启动时由HBase守护进程读取，请在此处添加您自己的环境变量。 此处的更改将需要重启HBase才能注意到更改。 7.4. _log4j.properties_编辑此文件以更改HBase文件的滚动速度，并更改HBase记录消息的级别。 此处的更改将需要重新启动集群以注意到更改，尽管可以通过HBase UI为特定的守护程序更改日志级别。 7.5. 客户端配置和依赖关系连接到HBase集群如果您在独立模式下运行HBase，则不必为您的客户端配置任何内容，只要保证它们在同一台计算机上即可。 由于HBase Master可以移动，客户可以通过向ZooKeeper寻找当前的关键位置来进行引导。ZooKeeper是保存所有这些值的地方。因此客户需要ZooKeeper集合的位置才能做其他事情。通常这个集合位置被保存在_hbase-site.xml_中，并由客户端从CLASSPATH中提取。 如果你正在配置一个IDE来运行一个HBase客户端，你应该在你的类路径中包含_conf/_目录，这样可以找到_hbase-site.xml_设置（或者添加_src/test/resources_来获取使用的hbase-site.xml文件通过测试）。 最小的情况是，当连接到集群时，HBase客户机需要依赖关系中的hbase-client模块： 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.hbase&lt;/groupId&gt; &lt;artifactId&gt;hbase-shaded-client&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt;&lt;/dependency&gt; 一个基本的客户端的_hbase-site.xml_的使用示例可能如下所示： 12345678910&lt;?xml version=&quot;1.0&quot;?&gt;&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;example1,example2,example3&lt;/value&gt; &lt;description&gt;The directory shared by region servers. &lt;/description&gt; &lt;/property&gt;&lt;/configuration&gt; 7.5.1. Java客户端配置ava客户端使用的配置保存在HBaseConfiguration实例中。 HBaseConfiguration的工厂方法，HBaseConfiguration.create();;，在调用时会读取客户端上的第一个_hbase-site.xml_的内容（CLASSPATH如果存在的话）（调用也将包含在任何发现的_hbase-default.xml_中；_hbase-default.xml_在_hbase.X.X.X.jar_里面）。也可以直接指定配置，而无需从_hbase-site.xml_中读取数据。例如，要以编程方式设置集群的ZooKeeper集成，请执行以下操作： 12Configuration config = HBaseConfiguration.create();config.set(&quot;hbase.zookeeper.quorum&quot;, &quot;localhost&quot;); // Here we are running zookeeper locally 如果多个ZooKeeper实例组成ZooKeeper集合，则可以在逗号分隔列表中指定它们（就像在_hbase-site.xml_文件中一样）。这个填充的Configuration实例然后可以传递给一个表，依此类推。 7.6. 超时配置HBase提供了各种各样的超时设置来限制各种远程操作的执行时间。 hbase.rpc.timeout hbase.rpc.read.timeout hbase.rpc.write.timeout hbase.client.operation.timeout hbase.client.meta.operation.timeout hbase.client.scanner.timeout.period hbase.rpc.timeout属性限制单个rpc调用在超时之前可以运行的时间。要微调读或写相关的RPC超时，请设置hbase.rpc.read.timeout和hbase.rpc.write.timeout配置属性。如果没有这些属性，将使用hbase.rpc.timeout。 更高级别的超时为hbase.client.operation.timeout，对每个客户端调用都有效。例如，当由于hbase.rpc.timeout而导致rpc调用失败时，将重试该调用，直到达到hbase.client.operation.timeout。可以通过设置hbase.client.meta.operation.timeout配置值来微调系统表的客户端操作超时。如果不设置，则其值将使用hbase.client.operation.timeout。 扫描操作的超时控制方式不同。使用hbase.client.scanner.timeout.period属性设置此超时。 8. HBase配置示例8.1. 基本分布式HBase安装在下文内容中是一个分布式10节点的群集的基本配置示例：其中，节点被命名为example0，example1…一直到example9，在这个例子中；HBase Master和HDFS NameNode正在节点example0上运行；RegionServers在节点example1- example9上运行；一个3节点ZooKeeper集合运行在example1、example2，以及example3的默认端口上；ZooKeeper的数据被保存到：_/export/zookeeper_r。 下面我们显示在HBase conf目录中找到的主要配置文件_hbase-site.xml_, _regionservers_, and _hbase-env.sh_。 8.1.1. _hbase-site.xml_12345678910111213141516171819202122232425262728293031&lt;?xml version=&quot;1.0&quot;?&gt;&lt;?xml-stylesheet type=&quot;text/xsl&quot; href=&quot;configuration.xsl&quot;?&gt;&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;example1,example2,example3&lt;/value&gt; &lt;description&gt;The directory shared by RegionServers. &lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt; &lt;value&gt;/export/zookeeper&lt;/value&gt; &lt;description&gt;Property from ZooKeeper config zoo.cfg. The directory where the snapshot is stored. &lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://example0:8020/hbase&lt;/value&gt; &lt;description&gt;The directory shared by RegionServers. &lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;description&gt;The mode the cluster will be in. Possible values are false: standalone and pseudo-distributed setups with managed ZooKeeper true: fully-distributed with unmanaged ZooKeeper Quorum (see hbase-env.sh) &lt;/description&gt; &lt;/property&gt;&lt;/configuration&gt; 8.1.2. _regionservers_在此文件中列出将运行RegionServers的节点。在我们的例子中，这些节点是example1- example9。 123456789example1example2example3example4example5example6example7example8example9 8.1.3. _hbase-env.sh__hbase-env.sh_文件中的以下行显示了如何设置JAVA_HOME环境变量（HBase需要的）并将堆设置为4 GB（而不是默认值1 GB）。如果您复制并粘贴此示例，请务必调整JAVA_HOME以适合您的环境。 12345# The java implementation to use.export JAVA_HOME=/usr/java/jdk1.8.0/# The maximum amount of heap to use. Default is left to JVM default.export HBASE_HEAPSIZE=4G 使用rsync将_conf_目录的内容复制到群集的所有节点。 9. HBase重要配置下面我们列出一些_重要_的配置。我们已经将这部分分为必需的配置和值得推荐的配置。 9.1. 所需的配置请你参考本教程中HBase基础条件中的操作系统和Hadoop部分的内容！ 9.1.1. 大型群集配置如果您拥有一个包含大量区域的群集，那么在主服务器启动后，Regionserver可能会暂时地进行检查，而所有剩余的RegionServers落后。要签入的第一台服务器将被分配到所有不是最优的区域。为防止出现上述情况，请将其hbase.master.wait.on.regionservers.mintostart属性从其默认值1中调高。详见: HBASE-6389 Modify the conditions to ensure that Master waits for sufficient number of Region Servers before starting region assignments 9.2. 推荐的配置9.2.1. ZooKeeper 配置zookeeper.session.timeout默认的超时时间是三分钟（以毫秒为单位）。这意味着，如果服务器崩溃，则在主服务器在三分钟前发现崩溃并开始恢复。您可能需要将超时调整到一分钟甚至更短的时间，以便主服务器尽快通知故障。在更改此值之前，请确保您的JVM垃圾收集配置处于受控状态，否则，长时间的垃圾回收会超出ZooKeeper会话超时时间，将取出您的RegionServer。（如果一个RegionServer长时间处于GC状态，你可能需要在服务器上启动恢复）。 要更改此配置，请编辑_hbase-site.xml_，将更改的文件复制到群集中并重新启动。 我们将这个值设置得很高，以避免不必要的麻烦。如果出现类似“为什么我在执行一个大规模数据导入的时候Region Server死掉啦”这样的问题，可以解释的原因是：他们的JVM未被解析，并且正在运行长时间的GC操作。 ZooKeeper 数量详见 zookeeper. 9.2.2. HDFS 配置dfs.datanode.failed.volumes.tolerated这是“DataNode 停止提供服务之前允许失败的卷数。默认情况下，任何卷失败都会导致 datanode 关闭”_从HDFS-default.xml_中的描述。您可能希望将其设置为可用磁盘数量的一半左右。 hbase.regionserver.handler.count此设置定义了为应答传入的用户表请求而保持打开的线程数。经验法则是，当每个请求的有效载荷接近MB（大容量、扫描使用大缓存）时保持低数字，并且当有效负载小（获取，小投入，ICV，删除）时保持此数字为高。正在进行的查询的总大小受设置 hbase.ipc.server.max.callqueue.size的限制。 如果这个数字的有效载荷很小，那么将这个数字设置为最大传入客户端数量是安全的，典型的例子是一个服务于网站的集群，因为put通常不被缓冲，大部分操作都是获取的。 保持此设置的高风险的原因是，当前在区域服务器中发生的所有投入的总大小可能对其内存造成太大的压力，甚至会触发OutOfMemoryError。在低内存上运行的RegionServer将触发其JVM的垃圾收集器，以更频繁的方式运行，直到GC暂停变得明显（原因是用于保留所有请求的有效载荷的所有内存不能被丢弃，即便垃圾收集器正在进行尝试）。一段时间之后，整个群集吞吐量都会受到影响，因为每个碰到该RegionServer的请求都将花费更长的时间，这更加剧了问题的严重性。 您可以通过rpc.logging查看某个RegionServer上是否有太多或太多的处理程序，然后跟踪其日志（排队请求消耗内存）。 9.2.3. 大型内存机器的配置HBase提供了一个合理的，保守的配置，可以在几乎所有人们可能想要测试的机器类型上运行。如果你有更大的机器 - HBase有8G或更大的堆 - 你可能会发现下面的配置选项很有帮助。 9.2.4. 压缩您应该考虑启用ColumnFamily压缩。有几个选项可以在大多数情况下都是通过减小StoreFiles的大小来提高性能，从而减少I / O。 详见 compression 9.2.5. 配置WAL文件的大小和数量在发生RS故障的情况下，HBase使用wal恢复尚未刷新到磁盘的memstore数据。这些WAL文件应该配置为略小于HDFS块（默认情况下，HDFS块为64Mb，WAL文件为〜60Mb）。 HBase也对WAL文件的数量有限制，旨在确保在恢复过程中不会有太多的数据需要重放。这个限制需要根据memstore配置进行设置，以便所有必要的数据都可以适用。建议分配足够多的WAL文件来存储至少那么多的数据（当所有的存储都接近完整时）。例如，对于16Gb RS堆，默认的memstore设置（0.4）和默认的WAL文件大小（〜60Mb），16Gb * 0.4 / 60，WAL文件数的起点为〜109。但是，由于所有的memstores不会一直占满，所以可以分配更少的WAL文件。 9.2.6. 管理分割HBase通常会根据您的_hbase-default.xml_ 和 _hbase-site.xml_ 配置文件中的设置来处理您所在区域的分割。重要的设置包括：hbase.regionserver.region.split.policy, hbase.hregion.max.filesize, hbase.regionserver.regionSplitLimit。分割的一个简单的观点是，当一个区域发展到hbase.hregion.max.filesize时，它被分割。对于大多数使用模式，您应该使用自动分割。详见: manual region splitting decisions for more information about manual region splitting. 不要让HBase自动分割你的区域，你可以选择自己管理分割。HBase 0.90.0增加了这个功能。如果你知道你的密钥空间，手动管理分割就行，否则让HBase为你分割。手动分割可以减轻在负载下的区域创建和移动。这也使得区域边界是已知的和不变的（如果你禁用区域分割）。如果使用手动分割，则可以更轻松地进行交错式的基于时间的主要压缩来分散网络IO负载。 禁用自动分割 要禁用自动拆分，可以在集群配置或表配置中设置区域拆分策略： org.apache.hadoop.hbase.regionserver.DisabledRegionSplitPolicy 自动分割建议 如果禁用自动分割来诊断问题或在数据快速增长期间，建议在您的情况变得更加稳定时重新启用它们。 确定预分割区域的最佳数目 预分割区域的最佳数量取决于您的应用程序和环境。一个好的经验法则是从每个服务器的10个预分割区域开始，随着时间的推移数据不断增长。尽量在区域太少的地方犯错，稍后进行滚动分割更好。区域的最佳数量取决于您所在区域中最大的StoreFile。如果数据量增加，最大的StoreFile的大小将随着时间增加。目标是使最大的区域足够大，压实选择算法仅在定时的主要压实期间将其压缩。否则，该集群可能会同时出现大量压实区域的压实风暴。数据增长导致压缩风暴，而不是人工分割决策，这一点很重要。 如果区域被分割成太多的区域，可以通过配置HConstants.MAJOR_COMPACTION_PERIOD来增加主要的压缩间隔。org.apache.hadoop.hbase.util.RegionSplitter`提供所有区域的网络IO安全滚动分割。 9.2.7. 管理压缩默认情况下，主要的压缩计划在7天内运行一次。 如果您需要精确控制主要压缩的运行时间和频率，可以禁用托管的主要压缩。请参阅 hbase.hregion.majorcompaction compaction.parameters 不禁用主要压缩 对于StoreFile清理来说，重要的压缩是绝对必要的。不要完全禁用它们。您可以通过HBase shell或Admin API手动运行主要压缩。 详见: compaction 9.2.8. 预测执行预测执行MapReduce任务是默认开启的，对于HBase集群，通常建议关闭系统级的推测执行，除非您需要在特定情况下可以配置每个作业。将属性 mapreduce.map.speculative 和 mapreduce.reduce.speculative 设置为 false。 9.3. 其他配置9.3.1. 平衡器平衡器（Balancer）是在主服务器上运行的一个周期性操作，用于重新分配集群上的区域。它通过hbase.balancer.period配置，默认为300000（5分钟）。 详见: master.processes.loadbalancer 9.3.2. 禁用Blockcache不要关闭块缓存（你可以通过设置hfile.block.cache.size为零来实现）。这样做没有好处，因为RegionServer将花费所有的时间一次又一次地加载HFile索引。如果你的工作集是这样配置块缓存，那么没有益处，最少应保证hfile指数保存在块缓存内的大小（你可以通过调查RegionServer UI粗略地了解你需要的大小；请参阅占网页顶部附近的索引块大小） 9.3.3. Nagle’s 或小package问题如果在对HBase的操作中出现大约40ms左右的延迟，请尝试Nagles的设置。 例如，请参阅用户邮件列表线程Inconsistent scan performance with caching set to 1 将缓存设置为1的不一致扫描性能以及其中所引用的设置notcpdelay来提高扫描速度的问题。详见文档底部图表HBASE-7008 Set scanner caching to a better default 设置了扫描缓存到一个更好的默认位置，我们的Lars Hofhansl会尝试使用Nagle打开和关闭测量效果的各种数据大小。 9.3.4. 更好的平均恢复时间这部分是关于在服务器出现故障后会使服务器恢复更快的配置。详见:Introduction to HBase Mean Time to Recover (MTTR) HBASE-8354 forces Namenode into loop with lease recovery requests 使用lease恢复请求循环的问题是混乱的，但在低超时以及如何引起更快的恢复，包括引用添加到HDFS的修复程序方面，有很多好的讨论。下面建议的配置是Varun的建议的提炼和测试，确保你在HDFS版本上运行，所以你有他所提到的修补程序，并且他自己添加到HDFS，帮助HBase MTTR（例如HDFS-3703，HDFS-3712和HDFS-4791 -Hadoop 2确保有他们并且后期Hadoop 1有一些）。在RegionServer中设置以下内容： 1234567891011&lt;property&gt; &lt;name&gt;hbase.lease.recovery.dfs.timeout&lt;/name&gt; &lt;value&gt;23000&lt;/value&gt; &lt;description&gt;How much time we allow elapse between calls to recover lease. Should be larger than the dfs timeout.&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.client.socket-timeout&lt;/name&gt; &lt;value&gt;10000&lt;/value&gt; &lt;description&gt;Down the DFS timeout from 60 to 10 seconds.&lt;/description&gt;&lt;/property&gt; 在NameNode/DataNode端，设置以下内容来启用HDFS-3703，HDFS-3912中引入的staleness： 1234567891011121314151617181920212223242526272829303132333435&lt;property&gt; &lt;name&gt;dfs.client.socket-timeout&lt;/name&gt; &lt;value&gt;10000&lt;/value&gt; &lt;description&gt;Down the DFS timeout from 60 to 10 seconds.&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.datanode.socket.write.timeout&lt;/name&gt; &lt;value&gt;10000&lt;/value&gt; &lt;description&gt;Down the DFS timeout from 8 * 60 to 10 seconds.&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;ipc.client.connect.timeout&lt;/name&gt; &lt;value&gt;3000&lt;/value&gt; &lt;description&gt;Down from 60 seconds to 3.&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;ipc.client.connect.max.retries.on.timeouts&lt;/name&gt; &lt;value&gt;2&lt;/value&gt; &lt;description&gt;Down from 45 seconds to 3 (2 == 3 retries).&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.avoid.read.stale.datanode&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;description&gt;Enable stale state in hdfs&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.stale.datanode.interval&lt;/name&gt; &lt;value&gt;20000&lt;/value&gt; &lt;description&gt;Down from default 30 seconds&lt;/description&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;dfs.namenode.avoid.write.stale.datanode&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;description&gt;Enable stale state in hdfs&lt;/description&gt;&lt;/property&gt; 9.3.5. JMXJMX（Java Management Extensions，Java管理扩展）提供了内置的工具，使您能够监视和管理Java VM。要启用远程系统的监视和管理，在启动 Java VM 时，您需要设置系统属性com.sun.management.jmxremote.port（要启用JMX RMI连接的端口号）。详见:official documentation. 从历史上看，除了上面提到的端口之外，JMX还会打开两个附加的随机TCP侦听端口，这可能会导致端口冲突问题。详见: HBASE-10289 作为一种替代方法，您可以使用HBase提供的基于协处理器的JMX实现。启用它，请在hbase-site.xml中添加以下属性：: 1234&lt;property&gt; &lt;name&gt;hbase.coprocessor.regionserver.classes&lt;/name&gt; &lt;value&gt;org.apache.hadoop.hbase.JMXListener&lt;/value&gt;&lt;/property&gt; 不要同时为Java VM 设置 com.sun.management.jmxremote.port 目前它支持Master和RegionServer Java VM。默认情况下，JMX侦听TCP端口10102，您可以使用以下属性进一步配置端口： 12345678&lt;property&gt; &lt;name&gt;regionserver.rmi.registry.port&lt;/name&gt; &lt;value&gt;61130&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;regionserver.rmi.connector.port&lt;/name&gt; &lt;value&gt;61140&lt;/value&gt;&lt;/property&gt; 在大多数情况下，注册表端口可以与连接器端口共享，所以只需要配置regionserver.rmi.registry.port。但是，如果要使用SSL通信，则必须将2个端口配置为不同的值。 默认情况下，密码认证和SSL通信被禁用。要启用密码验证，您需要像下面那样更新_hbase-env.sh_： 123456export HBASE_JMX_BASE=&quot;-Dcom.sun.management.jmxremote.authenticate=true \ -Dcom.sun.management.jmxremote.password.file=your_password_file \ -Dcom.sun.management.jmxremote.access.file=your_access_file&quot;export HBASE_MASTER_OPTS=&quot;$HBASE_MASTER_OPTS $HBASE_JMX_BASE &quot;export HBASE_REGIONSERVER_OPTS=&quot;$HBASE_REGIONSERVER_OPTS $HBASE_JMX_BASE &quot; 请参阅_$JRE_HOME/lib/management_下面的示例password/access文件。 要使用密码验证启用SSL通信，请按照以下步骤操作： 12345678#1\. generate a key pair, stored in myKeyStorekeytool -genkey -alias jconsole -keystore myKeyStore#2\. export it to file jconsole.certkeytool -export -alias jconsole -keystore myKeyStore -file jconsole.cert#3\. copy jconsole.cert to jconsole client machine, import it to jconsoleKeyStorekeytool -import -alias jconsole -keystore jconsoleKeyStore -file jconsole.cert 更新 _hbase-env.sh_ : 123456789export HBASE_JMX_BASE=&quot;-Dcom.sun.management.jmxremote.ssl=true \ -Djavax.net.ssl.keyStore=/home/tianq/myKeyStore \ -Djavax.net.ssl.keyStorePassword=your_password_in_step_1 \ -Dcom.sun.management.jmxremote.authenticate=true \ -Dcom.sun.management.jmxremote.password.file=your_password file \ -Dcom.sun.management.jmxremote.access.file=your_access_file&quot;export HBASE_MASTER_OPTS=&quot;$HBASE_MASTER_OPTS $HBASE_JMX_BASE &quot;export HBASE_REGIONSERVER_OPTS=&quot;$HBASE_REGIONSERVER_OPTS $HBASE_JMX_BASE &quot; 最后，使用密钥存储在客户端上启动 jconsole 1jconsole -J-Djavax.net.ssl.trustStore=/home/tianq/jconsoleKeyStore To 要在主服务器上启用HBase JMX实现，还需要在 _hbase-site.xml_中添加以下属性： 1234&lt;property&gt; &lt;name&gt;hbase.coprocessor.master.classes&lt;/name&gt; &lt;value&gt;org.apache.hadoop.hbase.JMXListener&lt;/value&gt;&lt;/property&gt; 端口配置的相应属性为：master.rmi.registry.port（默认为10101）和master.rmi.connector.port（默认情况下与registry.port相同）。 10. 动态配置你可以在不重新启动服务器的情况下更改配置的子集。在 HBase shell 中，有新的操作符，update_config 以及 update_all_config，它们会提示服务器或所有服务器重新加载配置。 当前正在运行的服务器中，只能更改所有配置的子集。以下是这些支持动态更改的配置： Key hbase.ipc.server.fallback-to-simple-auth-allowed hbase.cleaner.scan.dir.concurrent.size hbase.regionserver.thread.compaction.large hbase.regionserver.thread.compaction.small hbase.regionserver.thread.split hbase.regionserver.throughput.controller hbase.regionserver.thread.hfilecleaner.throttle hbase.regionserver.hfilecleaner.large.queue.size hbase.regionserver.hfilecleaner.small.queue.size hbase.regionserver.hfilecleaner.large.thread.count hbase.regionserver.hfilecleaner.small.thread.count hbase.regionserver.hfilecleaner.thread.timeout.msec hbase.regionserver.hfilecleaner.thread.check.interval.msec hbase.regionserver.flush.throughput.controller hbase.hstore.compaction.max.size hbase.hstore.compaction.max.size.offpeak hbase.hstore.compaction.min.size hbase.hstore.compaction.min hbase.hstore.compaction.max hbase.hstore.compaction.ratio hbase.hstore.compaction.ratio.offpeak hbase.regionserver.thread.compaction.throttle hbase.hregion.majorcompaction hbase.hregion.majorcompaction.jitter hbase.hstore.min.locality.to.skip.major.compact hbase.hstore.compaction.date.tiered.max.storefile.age.millis hbase.hstore.compaction.date.tiered.incoming.window.min hbase.hstore.compaction.date.tiered.window.policy.class hbase.hstore.compaction.date.tiered.single.output.for.minor.compaction hbase.hstore.compaction.date.tiered.window.factory.class hbase.offpeak.start.hour hbase.offpeak.end.hour hbase.oldwals.cleaner.thread.size hbase.oldwals.cleaner.thread.timeout.msec hbase.oldwals.cleaner.thread.check.interval.msec hbase.procedure.worker.keep.alive.time.msec hbase.procedure.worker.add.stuck.percentage hbase.procedure.worker.monitor.interval.msec hbase.procedure.worker.stuck.threshold.msec hbase.regions.slop hbase.regions.overallSlop hbase.balancer.tablesOnMaster hbase.balancer.tablesOnMaster.systemTablesOnly hbase.util.ip.to.rack.determiner hbase.ipc.server.max.callqueue.length hbase.ipc.server.priority.max.callqueue.length hbase.ipc.server.callqueue.type hbase.ipc.server.callqueue.codel.target.delay hbase.ipc.server.callqueue.codel.interval hbase.ipc.server.callqueue.codel.lifo.threshold hbase.master.balancer.stochastic.maxSteps hbase.master.balancer.stochastic.stepsPerRegion hbase.master.balancer.stochastic.maxRunningTime hbase.master.balancer.stochastic.runMaxSteps hbase.master.balancer.stochastic.numRegionLoadsToRemember hbase.master.loadbalance.bytable hbase.master.balancer.stochastic.minCostNeedBalance hbase.master.balancer.stochastic.localityCost hbase.master.balancer.stochastic.rackLocalityCost hbase.master.balancer.stochastic.readRequestCost hbase.master.balancer.stochastic.writeRequestCost hbase.master.balancer.stochastic.memstoreSizeCost hbase.master.balancer.stochastic.storefileSizeCost hbase.master.balancer.stochastic.regionReplicaHostCostKey hbase.master.balancer.stochastic.regionReplicaRackCostKey hbase.master.balancer.stochastic.regionCountCost hbase.master.balancer.stochastic.primaryRegionCountCost hbase.master.balancer.stochastic.moveCost hbase.master.balancer.stochastic.maxMovePercent hbase.master.balancer.stochastic.tableSkewCost]]></content>
      <categories>
        <category>翻译</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Apache-HBase-™-中文指南-最新版HBase-3-0-0-ch3-HBase配置详解]]></title>
    <url>%2F2019%2F03%2F04%2FApache-HBase-%E2%84%A2-%E4%B8%AD%E6%96%87%E6%8C%87%E5%8D%97-%E6%9C%80%E6%96%B0%E7%89%88HBase-3-0-0-ch3-HBase%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3%20-%20%E5%89%AF%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[Apache HBase配置 译者: xixici 当你想要升级时，你不能跳过主要版本。当你从版本0.98.x到 2.x时，你必须首先升级到1.2.x再从1.2.x升级到 2.x。 回顾 Apache HBase 配置章节，还有 Hadoop，并熟悉 支持和测试. 11. HBase版本号和兼容性11.1. 期望语义版本控制从版本1.0.0开始，HBase采用 Semantic Versioning作为版本控制。 对于给定的版本号 MAJOR.MINOR.PATCH，增加如下内容： MINOR 版本，当您以向后兼容的方式添加功能时PATCH 版本，当您进行向后兼容的错误修复时预发布和构建元数据的其他标签可作为MAJOR.MINOR.PATCH格式的扩展。 MAJOR 版本，当你进行不兼容的 API 更改时 MINOR 版本，当您以向后兼容的方式添加功能时 PATCH 版本，当您进行向后兼容的错误修复时 预发布和构建元数据的其他标签可作为MAJOR.MINOR.PATCH格式的扩展。 兼容性维度 除了通常的 API 版本考虑之外，HBase 还有其他需要考虑的兼容性维度。 Client-Server 线协议兼容性： 允许不同步更新客户端和服务器。 我们只能允许先升级服务器。也就是说，服务器将向后兼容旧客户端，这样新的 API 就可以使用。 示例：用户应该能够使用旧客户端连接到升级的群集。 Server-Server 协议兼容性： 不同版本的服务器可以共存于同一个群集中。 服务器之间的有线协议是兼容的。 分布式任务的工作人员（如复制和日志拆分）可以共存于同一个群集中。 相关协议（如使用ZK进行协调）也不会改变。 示例：用户可以执行滚动升级。 文件格式兼容性： 支持文件格式向前和向后兼容 示例：文件、ZK 编码、目录布局自动升级为 HBase 升级的一部分。用户可以降级到旧版本，并且一切都将继续工作。 客户端 API 兼容性： 允许更改或删除现有的客户端 API。 在我们更改/删除主要版本之前，API 需要被弃用。 修补程序（patch）版本中提供的 API 将在所有后续修补程序版本中提供。但是，可能会添加新的 API，这些 API 在以前的修补程序版本中将不可用。 修补程序版本中引入的新 API 只能以源代码兼容的方式添加：即实现公共 API 的代码将继续编译[1]:。示例：使用新废用的 API 的用户不需要使用 HBase API 调用修改应用程序代码，直到下一个主要版本。 示例：在下一个主要版本之前，使用新弃用的API的用户不需要修改应用程序的HBase API调用代码。 客户端二进制兼容性： 写入给定修补程序版本中提供的 API 的客户端代码可以运行不变（不需要重新编译），以抵补新的 jar 后续补丁版本。 写入给定修补程序版本中提供的 API 的客户端代码可能无法针对早期修补程序版本中的旧 jar 运行。示例：旧编译的客户端代码将在 jar 中保持不变。 示例：旧编译的客户端代码将在 jar 中保持不变。 如果客户端实现 HBase 接口，则可能需要重新编译升级到较新的次要（minor）版本。 服务器端有限的 API 兼容性（取自 Hadoop）： 内部API被标记为“稳定（Stable）”，“正在发展（Evolving）”或“不稳定（Unstable）”。 这意味着协处理器和插件（可插入类，包括复制）的二进制兼容性，只要这些只使用标记的接口/类。 例如：旧编译的协处理器，过滤器或插件代码将在新 jar 中保持不变。 相关性兼容性： HBase 的升级除Apache Hadoop外，不需要依赖项目的兼容升级，包括运行 Java 时。 HBase 的升级不需要依赖项目的兼容升级，包括Java 。 示例：将HBase升级到支持_依赖兼容性_的版本不需要升级Apache ZooKeeper服务。 示例：示例：如果当前版本的HBase支持在JDK 8上运行，则升级到支持_依赖兼容性_的版本也将在JDK 8上运行。 Hadoop 版本 之前，我们尝试维护基础Hadoop服务的依赖兼容性，但在过去几年中，这已经证明是站不住脚的。 虽然HBase项目试图维持对旧版本Hadoop的支持，但我们删除了次要版本的“受支持”指示符。 此外，Hadoop项目有自己的一组兼容性指南，这意味着在某些情况下，会破坏指南，也就是必须更新到较新的受支持的次要版本。 操作兼容性： 度量标准的更改 服务的行为变化 通过 /jmx/ 端点公开的 JMX API 概要 修补程序（patch）升级是一种直接替代方案。任何不是 Java 二进制和源代码兼容的更改都将不被允许[2]。在修补程序版本中降级版本可能不兼容。 次要（minor）升级不需要修改应用程序/客户端代码。理想情况下，这将是一个直接替换，但如果使用新的 jar，则客户端代码，协处理器，过滤器等可能必须重新编译。 主要（major）升级允许 HBase 做出重大改变。 Major Minor Patch 客户端 - 服务器线路兼容性 N Y Y 服务器 - 服务器兼容性 N Y Y 文件格式兼容性 N [4] Y Y 客户端API兼容性 N Y Y 客户端二进制兼容性 N N Y 服务器端有限的API兼容性 稳定性（Stable） N Y Y 发展性（Evolving） N N Y 不稳定性（Unstable） N N N 相关性兼容性 N Y Y 操作兼容性 N N Y 11.1.1. HBase APIHBase 有很多 API 要点，但对于上面的兼容性矩阵，我们区分了Client API（客户端 API），Limited Private API（有限的私有 API）和 Private API（私有 API）。HBase 使用 Apache Yetus Audience Annotations 来定义稳定性 InterfaceAudience (javadocs): 捕捉预期的受众，可能的值包括： Public：对于最终用户和外部项目是安全的； LimitedPrivate：用于我们期望可插入的内部组件，如协处理器； Private：严格用于 HBase 自身内部定义为 IA 的类中，Private 可以用作声明 IA.LimitedPrivate 接口的参数或返回值。将IA.Private对象视为不透明；不要尝试直接访问其方法或字段。 InterfaceStability (javadocs): 描述允许接口更改的类型。可能的值包括： Stable：接口是固定的，预计不会改变； Evolving：界面可能会在未来的minor 版本中改变； Unstable：界面可能随时更改 请记住 HBase 项目中 InterfaceAudience 注释和 InterfaceStability 注释之间的以下相互作用： IA.Public 类本质上是稳定的，并坚持我们有关升级类型（主要，次要或修补程序）的稳定性保证。 IA.LimitedPrivate 类应始终使用给定的 InterfaceStability 值的其中一个进行注释。如果他们不是，你应该假定他们是 IS.Unstable。 IA.Private 类应该被认为是隐含不稳定的，不能保证发布之间的稳定性。 HBase Client API HBase 客户端 API 由所有标记有 InterfaceAudience.Public 接口的类或方法组成。hbase-client 和依赖模块中的所有主类都有InterfaceAudience.Public，InterfaceAudience.LimitedPrivate或InterfaceAudience.Private标记。并非所有其他模块（hbase-server等）中的类都有标记。如果一个类没有使用上述中的一个注释，则它被认为是一个InterfaceAudience.Private类。 HBase LimitedPrivate API LimitedPrivate 注释为接口附带了一组目标使用者。这些使用者是协处理器，phoenix，复制端点实现等。此时，HBase 只能保证修补程序版本之间的这些接口的源和二进制兼容性。 HBase Private API 所有使用InterfaceAudience.Private注释的类或没有注释的所有类仅在HBase内部使用。接口和方法签名可以随时改变。如果您依赖于标记为Private的特定界面，则应打开jira以建议将界面更改为Public或LimitedPrivate，或者为此目的公开的接口。 二进制兼容性： 当我们说两个 HBase 版本是兼容的时，我们的意思是这些版本是线（wire）和二进制兼容的。兼容的HBase版本意味着客户可以与兼容但不同版本的服务器通话。这也意味着你可以换出一个版本的 jar，并用另一个兼容版本的 jar 替换它们，所有的 jar 都可以工作。除非另有说明，否则 HBase 主要的版本都是二进制兼容的。您可以安全地在二进制兼容版本之间进行滚动升级。例如从1.2.4到 1.2.6.详见:[Does compatibility between versions also mean binary compatibility?] 在HBase论坛的讨论。 11.2. 滚动升级滚动升级是您一次更新服务器群集中的服务器的过程。如果它们是二进制或线路兼容的，则可以跨 HBase版本进行滚动升级。详见：Rolling Upgrade Between Versions that are Binary/Wire Compatible 粗略地说，滚动升级是正常地停止每台服务器，更新软件，然后重新启动。您可以为集群中的每个服务器执行此操作。通常先升级 Master，然后再升级 RegionServers。 查看 Rolling Restart 例如，下面的 HBase 是 symlinked 实际的 HBase 安装。在升级之前，在群集上运行滚动重启之前，我们将 symlink 更改为指向新的 HBase 软件版本，然后运行： 1$ HADOOP_HOME=~/hadoop-2.6.0-CRC-SNAPSHOT ~/hbase/bin/rolling-restart.sh --config ~/conf_hbase 滚动重新启动脚本将首先正常停止并重新启动主服务器，然后依次重新启动每个 RegionServer。由于 symlink 被更改，所以重新启动时，服务器将使用新的HBase 版本。随着滚动升级的进行，检查日志中是否有错误。 在兼容二进制/Wire的版本之间进行滚动升级： 除非另有说明，否则 HBase 指向的版本是二进制兼容的。您可以在 HBase 主要版本之间进行滚动升级。例如，您可以通过在集群中进行滚动升级，使用0.94.6二进制文件替换0.94.5二进制文件，从而从 0.94.5 转到 0.94.6。 在次要（minor）版本中，我们调用的版本是有线/协议兼容的，在这种情况下，也可以执行滚动升级。 12. 版本恢复当你在试着升级 HBase 的时候，你可能会遇到升级失败的问题，并且想要将其恢复成之前的版本。本节就介绍如何执行_回滚_以将 HBase 恢复为到较早的版本。请注意，这应该只在主要版本和一些次要版本之间需要。您应该始终能够在相同次要版本的 HBase Patch 版本之间进行_降级_。这些说明可能要求您在开始升级过程之前注意相关的事项，因此请务必事先阅读本节。 12.1. 警告回滚与降级 本节介绍如何对 HBase 次要版本和主要版本之间的升级执行回滚。在本文档中，回滚指的是采取升级后的集群并将其恢复到旧版本的过程，同时_丢失升级后发生的所有更改_。相比之下，群集降级会将升级后的群集恢复到旧版本，同时保留升级后写入的任何数据。我们目前仅提供回滚 HBase 集群的说明。此外，只有在执行升级之前遵循这些说明，回滚才有效。 当这些指令谈论回滚与降级的先决条件群集服务（即HDFS）时，您应该将服务版本与退化的降级案例视为相同。 复制 除非您正在执行全部服务回滚，否则 HBase 群集将会丢失任何配置的对等 HBase 复制。如果您的集群配置为 HBase 复制，那么在按照这些说明Managing and Configuring Cluster Replication进行操作之前，您应该记录所有复制节点。执行回滚之后，您应该将每个记录的对等点添加回群集。另外要注意，自升级后写入群集的数据可能已经或可能未被复制到任何对等方。 数据位置 除非您正在执行全部服务回滚，否则通过回滚过程可能会破坏Region Server的所有局部位置。在群集有时间通过紧凑排列恢复数据位置之前，您应该期望性能的降级。或者，您可以强制压缩来加速此过程，但要以生成群集负载为代价。 可配置的位置 以下说明假设 HBase 数据目录和 HBase znode 的默认位置。这两个位置都是可配置的，您应该在继续操作之前验证群集中使用的值。如果您有不同的值，只需将默认值替换为在配置中找到的 HBase 数据目录，它是通过密钥 “HBase” (rootdir) 配置的，并且具有默认的 “/HBase”。* HBase znode通过密钥’zookeeper.znode.parent’进行配置，默认值为’/ hbase’。 12.2. 所有服务回滚如果您要执行 HDFS 和 ZooKeeper 服务的回滚，那么 HBase 的数据将在此过程中回滚。 要求 能够回滚 HDFS 和 ZooKeeper 升级前 在升级前不需要额外的步骤。作为一项额外的预防措施，您可能希望使用 distcp 将 HBase 数据备份到要升级的群集之外。为此，请本节内容中的按照“HDFS降级后回滚”的“升级前”部分中的步骤操作，但它是复制到另一个 HDFS 实例，而不是在同一实例中。 执行回滚 停止 HBase 执行 HDFS 和 ZooKeeper 的回滚（HBase 应该保持停止状态） 将安装的 HBase 版本更改为以前的版本 启动 HBase 验证 HBase 内容 - 使用 HBase shell 列出表格并扫描一些已知值。 12.3. HDFS 回滚和 ZooKeeper 降级后回滚如果您将回滚 HDFS，但通过 ZooKeeper 降级，那么 HBase 将处于不一致的状态。在完成此过程之前，您必须确保集群未启动。 要求 能够回滚 HDFS 能够降级 ZooKeeper 升级前 在升级前不需要额外的步骤。作为一种额外的预防措施，您可能希望使用 distcp 将 HBase 数据备份到要升级的群集之外。为此，请本节内容中的按照“HDFS降级后回滚”的“升级前”部分中的步骤操作，但它将复制到另一个HDFS实例，而不是在同一实例中。 执行回滚 停止 HBase 执行 HDFS 回滚和 ZooKeeper 降级（HBase 应该保持停止状态） 将安装的 HBase 版本更改为以前的版本 清除与 HBase 相关的 ZooKeeper 信息。警告：此步骤将永久销毁所有复制对等点。 清理 ZooKeeper 中的 HBase 信息 123456[hpnewton@gateway_node.example.com ~]$ zookeeper-client -server zookeeper1.example.com:2181,zookeeper2.example.com:2181,zookeeper3.example.com:2181Welcome to ZooKeeper!JLine support is disabledrmr /hbasequitQuitting... 启动 HBase 验证 HBase 内容 - 使用 HBase shell 列出表格并扫描一些已知值。 12.4. HDFS 降级后回滚如果您要执行 HDFS 降级，则无论ZooKeeper是否通过回滚、降级或重新安装，您都需要遵循这些指示信息。 要求 可以降级 HDFS 升级前群集必须能够运行 MapReduce 作业 HDFS 超级用户访问 在 HDFS 中至少有两个 HBase 数据目录的副本空间可以降级 HDFS 升级前 在开始升级过程之前，您必须对 HBase 的支持数据进行完整备份。以下说明介绍了在当前HDFS实例中备份数据的过程。或者，您可以使用 distcp 命令将数据复制到另一个 HDFS 群集。 停止 HBase 群集 将 HBase 数据目录复制到备份位置, 方法distcp command是使用 distcp 命令作为 HDFS 超级用户 (下面显示在启用安全的群集上) 使用distcp备份HBase数据目录： 12[hpnewton@gateway_node.example.com ~]$ kinit -k -t hdfs.keytab hdfs@EXAMPLE.COM[hpnewton@gateway_node.example.com ~]$ hadoop distcp /hbase /hbase-pre-upgrade-backup Distcp 将启动一个 mapreduce 作业来处理以分布式方式复制文件。检查 distcp 命令的输出，以确保此作业成功完成。 执行回滚 停止 HBase 执行 HDFS 的降级和 ZooKeeper 的降级/回滚（HBase 应该保持停止状态） 将安装的 HBase 版本更改为以前的版本 将 HBase 数据目录从升级前恢复为 HDFS 超级用户 (如下所示在启用安全的群集上)。如果您将数据备份到另一个 HDFS 群集而不是本地，则需要使用distcp 命令将其复制回当前的 HDFS 群集。恢复 HBase 数据目录： 123[hpnewton@gateway_node.example.com ~]$ kinit -k -t hdfs.keytab hdfs@EXAMPLE.COM[hpnewton@gateway_node.example.com ~]$ hdfs dfs -mv /hbase /hbase-upgrade-rollback[hpnewton@gateway_node.example.com ~]$ hdfs dfs -mv /hbase-pre-upgrade-backup /hbase 清除与 HBase 相关的 ZooKeeper 信息。警告：此步骤将永久销毁所有复制对等点。 清理 ZooKeeper 中的 HBase 信息： 123456[hpnewton@gateway_node.example.com ~]$ zookeeper-client -server zookeeper1.example.com:2181,zookeeper2.example.com:2181,zookeeper3.example.com:2181Welcome to ZooKeeper!JLine support is disabledrmr /hbasequitQuitting... 启动 HBase 验证 HBase 内容 - 使用 HBase shell 列出表格并扫描一些已知值。 13. HBase升级路径13.1. 从 1.x 升级到 2.x在本节中，先前稳定的HBase版本相比所发生的重大变化，一定要仔细阅读，然后再进行升级。以免发生意外。 13.1.1. 变化通告首先，我们将介绍升级到HBase 2.0+时可能遇到的部署/操作更改。之后，我们将告知下游应用程序的更改。请注意，协处理器包含在操作部分中。另外请注意，本节并不旨在传达您可能感兴趣的新功能的信息。有关更改的完整摘要，请参阅您计划升级到的版本的源发布工件中的changes.txt文件。 更新到HBase 2.0+的基本最低先决条件 如之前章节所述 Basic Prerequisites, HBase 2.0+ 需要依赖Java 8 和 Hadoop 2.6. HBase社区建议在升级您的HBase版本之前，确保您已经完成了任何必要的先决条件升级。 HBCK 一定要匹配HBase版本 一定不要在HBase 2.0+ 集群上使用 HBase 1.x 版本的 HBCK。 HBCK是严格绑定 HBase版本的。 对hbase 2.0+集群使用早期版本的hbck工具将以不可恢复的方式破坏性地改变集群。 从HBase 2.0开始， HBCK (也叫做_HBCK1_ 或 _hbck1_)是一个只读工具，可以报告某些非公共系统内部的状态。您不应该依赖这些内部构件的格式和内容来保持HBase版本之间的一致性。 替代品详见： HBase HBCK2 和 Apache HBase Operational Management. 配置设置不再位于HBase 2.0+ 下列配置设置不再适用或不可用。有关详细信息，请参阅详细的发行说明。 hbase.config.read.zookeeper.config (查看 ZooKeeper configs no longer read from zoo.cfg ) hbase.zookeeper.useMulti (HBase现在使用ZK’s multi functionality) hbase.rpc.client.threads.max hbase.rpc.client.nativetransport hbase.fs.tmp.dir hbase.bucketcache.combinedcache.enabled hbase.bucketcache.ioengine 不再支持 ‘heap’ 值. hbase.bulkload.staging.dir hbase.balancer.tablesOnMaster 严格地说，它并没有被删除，但它的意义已经发生了根本性的改变，用户不应该设置它。详见： “Master hosting regions” feature broken and unsupported hbase.master.distributed.log.replay 详见： “Distributed Log Replay” feature broken and removed hbase.regionserver.disallow.writes.when.recovering 详见： “Distributed Log Replay” feature broken and removed hbase.regionserver.wal.logreplay.batch.size 详见： “Distributed Log Replay” feature broken and removed hbase.master.catalog.timeout hbase.regionserver.catalog.timeout hbase.metrics.exposeOperationTimes hbase.metrics.showTableName hbase.online.schema.update.enable (HBase 不再支持) hbase.thrift.htablepool.size.max 在HBase 2.0+重命名的配置属性 已重命名以下属性。在运行时设置旧属性将失败。 旧名称 新名称 hbase.rpc.server.nativetransport hbase.netty.nativetransport hbase.netty.rpc.server.worker.count hbase.netty.worker.count hbase.hfile.compactions.discharger.interval hbase.hfile.compaction.discharger.interval hbase.hregion.percolumnfamilyflush.size.lower.bound hbase.hregion.percolumnfamilyflush.size.lower.bound.min 在HBase 2.0+中具有不同默认值的配置 以下配置设置更改了它们的默认值。在适用的情况下，将给出hbase 1.2行为的设置值。 hbase.security.authorization 默认 false. 之前版本的default是true hbase.client.retries.number 现在默认10. 之前默认 35.建议下游用户使用 Timeout settings 所述的客户端超时。 hbase.client.serverside.retries.multiplier 现在默认3. 之前默认 10.建议下游用户使用 Timeout settings 所述的客户端超时。 hbase.master.fileSplitTimeout 默认10分钟，之前是30秒 hbase.regionserver.logroll.multiplier默认 0.5\之前 0.95. 此更改与下面的块大小加倍有关。结合起来，这两个配置更改应该使WAL的大小与HBase-1.x中的大小大致相同，但是小块的发生率应该更低，因为在达到块大小阈值之前，我们无法滚动WAL。详见： HBASE-19148 hbase.regionserver.hlog.blocksize 默认为wal dir的hdfs默认块大小的2倍。以前它等于wal dir的hdfs默认块大小。 hbase.client.start.log.errors.counter 更改为5,以前是9 hbase.ipc.server.callqueue.type 改为“FIFO”。在HBase版本1.0-1.2中，这是“最后期限”。在之前和之后的1.x版本中，它已经默认为“FIFO”。 hbase.hregion.memstore.chunkpool.maxsize 默认为1.0, 之前是0.0. 实际上，这意味着以前当memstore onheap时，我们不会使用区块池，现在我们将使用。有关mslab区块池的更多信息，请参阅Long GC pauses hbase.master.cleaner.interval 默认为10分钟, 之前是1分钟. hbase.master.procedure.threads 现在将默认为可用CPU数量的1/4，但不少于16个线程。以前，线程数等于CPU数。 hbase.hstore.blockingStoreFiles 现在是16。以前是10。 hbase.http.max.threads 现在是16。以前是10。 hbase.client.max.perserver.tasks 现在是2。以前是5 hbase.normalizer.period 现在是5分钟。以前是30分钟. hbase.regionserver.region.split.policy 现在是步进式分割策略。以前，它增加边界区域策略。 replication.source.ratio 现在是0.5。以前是0.1. “主托管区域”功能已损坏且不受支持 hbase 1.y中的“master充当区域服务器”功能和相关后续工作在hbase 2.y中不起作用，不应在生产设置中使用，因为master初始化时出现死锁。建议下游用户将相关的配置设置视为实验性的，并将该功能视为不适合生产设置。 相关变更的简要概述： 默认情况下，Master不再承载区域 hbase.balancer.tablesonmaster是一个布尔值，默认为false（如果它包含hbase 1.x表列表，则默认为false） hbase.balancer.tablesonmaster.systemtablesonly是保持用户表远离master的布尔值。缺省假 那些希望复制旧服务器列表配置的人应该部署一个独立的区域服务器进程，然后依赖于区域服务器组。 “分布式日志回放”功能已中断并已删除 分布式日志重播功能已损坏，已从hbase 2.y+中删除。因此，所有相关的配置、度量、RPC字段和日志记录都已被删除。请注意，在运行到hbase 1.0时发现此功能不可靠，默认为未使用，当我们开始忽略打开该功能的配置时 (HBASE-14465)，它在hbase 1.2.0中被有效删除。如果您当前正在使用该功能，请确保执行干净的关机，确保完成所有DLR工作，并在升级之前禁用该功能。 _prefix-tree_ 编码移除 前缀树编码已从hbase 2.0.0中删除(HBASE-19179)。在HBase-1.2.7、HBase-1.4.0和HBase-1.3.2中已弃用。 此功能被删除，因为它未被积极维护。如果有兴趣恢复这种可以在慢写代价高昂的情况下改善随机读取延迟的功能，可以在_dev at hbase dot apache dot org_上写下hbase开发者列表。 升级到HBase 2.0+之前，需要从所有表中删除前缀树编码。要首先执行此操作，您需要将编码从前缀树更改为HBase 2.0中支持的其他内容。之后，您必须主要压缩以前使用前缀树编码的表。要检查哪些列族使用的数据块编码不兼容，可以使用Pre-Upgrade Validator 指标变化 以下指标已更改名称： 以前以”AssignmentManger” [sic]名称发布的度量现在”AssignmentManager”名称发布。 以下指标改变了其含义： 基于每个区域服务器发布的度量“blockcacheevictioncount”不再包括由于其来自的hfiles无效（例如通过压缩）而从缓存中删除的块。 度量’totalRequestCount’每个请求增加一次；以前它是由请求中携带的Actions数量增加的；例如，如果一个请求是由四个get和两个puts组成的multi，那么我们将“totalrequestcount”增加六次；现在，不管怎样，我们都将增加一次。希望在HBase-2.0.0中看到该指标的较低值。 ‘readRequestCount’现在对返回非空行的读取进行计数，在较旧的HBase中，无论结果是否为，我们都会增加“readrequestcount”。如果请求不存在的行，此更改将使读取请求图的配置文件变平。YCSB读取繁重的工作负载可以根据数据库的加载方式来实现这一点。 已删除以下指标： 与分布式日志重播功能相关的度量不再存在。以前在区域服务器上下文中的名称“replay”下找到了它们。有关详细信息，请参阅 “Distributed Log Replay” feature broken and removed 添加了以下指标： ‘totalRowActionRequestCount’是汇总读和写的区域行操作的计数。 更改日志 HBase-2.0.0 现在使用 slf4j 作日志组件.之前是 log4j (1.2). 对于大多数情况，转换应该是无缝的；slf4j能够很好地解释_log4j.properties_日志配置文件，这样您就不会注意到日志系统的排放量有任何差异。 也就是说, _log4j.properties_ 需要刷新下. 详见例子: HBASE-20351在每次shell命令调用时，一个过时的日志配置文件都显示为netty配置，并在debug级别转储为前导码。 zookeeper配置不再从zoo.cfg中读取 HBase不再选择读取与ZooKeeper相关的配置设置的“zoo.cfg”文件。如果您以前依赖“hbase.config.read.zookeeper.config”配置来实现此功能，则应在向每个属性名添加前缀“hbase.zookeeper.property.”的同时，将任何需要的设置迁移到hbase-site.xml文件。 权限更改 以下与权限相关的更改要么更改了语义，要么更改了默认值： 授予用户的权限现在与该用户的现有权限合并，而不是重写它们。详见: the release note on HBASE-17472 区域服务器组命令（在1.4.0中添加）现在需要管理员权限。 大多数管理API不适用于来自HBase 2.0之前的客户机的HBase 2.0+群集。 从HBase 2.0之前的客户机使用时，许多管理命令都不起作用。这包括一个hbase shell，该shell具有来自hbase 2.0之前版本的库jar。在您还可以更新到所需的客户端版本之前，您需要计划管理API和命令的使用中断。 当从HBase 2.0之前的客户机执行时，以下客户机操作不适用于HBase 2.0+群集： list_procedures split merge_region list_quotas enable_table_replication disable_table_replication Snapshot related commands 1.0已弃用的管理员命令删除。 在适用的情况下，列出了替换命令。 ‘hlog’命令已被删除。 下游用户应该依赖’wal’命令。 区域服务器内存消耗更改。 从HBase 1.4之前的版本升级的用户应阅读本节中的说明 Region Server memory consumption changes.. 此外，HBase 2.0改变了如何跟踪memstore内存以进行刷新决策。 以前，数据大小和存储开销都用于计算冲洗threashold的利用率。 现在，只使用数据大小来做出每个区域的决策。 在全球范围内，添加存储开销用于做出有关强制刷新的决策。 用于拆分和合并的Web UI对行前缀进行操作 以前，Web UI包含表状态页面上的功能，以根据编码的区域名称进行合并或拆分。 在HBase 2.0中，此功能通过采用行前缀来工作。 从HBase 1.4之前对Replication用户进行特殊升级 用户在1.4.0版本之前运行HBase版本并使用复制时，请务必阅读本节中的说明Replication peer’s TableCFs config. HBase shell 变化 HBase shell命令依赖于捆绑的JRuby实例。捆绑的JRuby已从1.6.8版更新到9.1.10.0版。它表示从Ruby 1.8到Ruby 2.3.3的更改，它为用户脚本引入了不兼容的语言更改。 HBase shell命令现在忽略早期HBase 1.4版本中存在的’—return-values’标志。相反，shell总是表现得像传递了那个标志。如果您希望避免在控制台中打印表达式结果，则应更改IRB配置，如_irbrc_）部分所述。 HBase 2.0+中的协处理器API已更改 所有协处理器API都经过重构，以提高针对未来HBase版本的二进制API兼容性的可支持性。如果您或您所依赖的应用程序具有自定义HBase协处理器，您应阅读 the release notes for HBASE-18169 ，了解您将需要的更改的详细信息在升级到HBase 2.0+之前制作。 例如，如果你在HBase 1.2中有一个BaseRegionObserver，那么至少你需要更新它以实现RegionObserver和RegionCoprocessor并添加方法 123456... @Override public Optional&lt;RegionObserver&gt; getRegionObserver() &#123; return Optional.of(this); &#125;... HBase 2.0+无法再写入HFile v2文件。 HBase简化了我们内部的HFile处理。因此，我们再也无法在版本3 \的默认版本之前编写HFile版本。升级用户应确保在升级之前hbase-site.xml中的hfile.format.version未设置为2。如果不这样做将导致Region Server失败。 HBase仍然可以读取以旧版本2格式编写的HFile。 HBase 2.0+无法再读取基于序列文件的WAL文件。 HBase无法再读取以Apache Hadoop序列文件格式编写的已弃用的WAL文件。应将hbase.regionserver.hlog.reader.impl和hbase.regionserver.hlog.reader.impl配置条目设置为使用基于Protobuf的WAL读取器/写入器类。此实现是HBase 0.96以来的默认实现，因此传统WAL文件不应成为大多数下游用户关注的问题。 干净的群集关闭应确保没有WAL文件。如果您不确定给定的WAL文件格式，可以使用hbase wal命令在HBase集群脱机时解析文件。在HBase 2.0+中，此命令将无法读取基于WAL的序列文件。有关该工具的更多信息，请参阅WALPrettyPrinter）。 过滤器的行为更改 过滤器ReturnCode NEXT_ROW已重新定义为跳过当前系列中的下一行，而不是跳到所有系列中的下一行。它更合理，因为ReturnCode是商店级别的概念，而不是区域级别。 下游HBase 2.0+用户应该使用着色客户端 强烈建议下游用户依赖Maven坐标org.apache.hbase：hbase-shaded-client来运行它们。此工件包含与HBase集群通信所需的所有实现详细信息，同时最大限度地减少暴露的第三方依赖项的数量。 请注意，此工件公开org.apache.hadoop包空间中的某些类（例如o.a.h.configuration.Configuration），以便我们可以保持与我们的公共API的源兼容性。包含这些类，以便可以将它们更改为使用与HBase客户端代码的其余部分相同的重定位第三方依赖项。如果您还需要**在代码中使用Hadoop，则应确保所有与Hadoop相关的jar都位于类路径中的HBase客户端jar之前。 运行时类路径的重大更改 HBase的许多内部依赖项已从运行时类路径中更新或删除。 不遵循Downstream HBase 2.0+ users should use the shaded client的指导的下游客户端用户将必须检查Maven为影响而引入的依赖关系集。 LimitedPrivate Coprocessor API的下游用户需要检查运行时环境是否有影响。 有关我们对协调兼容运行时版本一直存在问题的第三方库的新处理的详细信息，请参阅参考指南部分The hbase-thirdparty dependency and shading/relocation）。 对客户端API的源和二进制兼容性进行多次重大更改 HBase的Java客户端API有许多更改可以破坏源和二进制兼容性的详细信息，请参阅要升级到的版本的兼容性检查报告。 跟踪实施变化 HBase跟踪功能的支持实现已从Apache HTrace 3更新为HTrace 4，其中包括几个重大更改。 虽然HTrace 3和4可以在同一运行时共存，但它们不会相互集成，从而导致不相交的跟踪信息。 此升级期间HBase的内部更改足以进行编译，但尚未确认跟踪功能中没有回归。 请考虑此功能在不久的将来会过期。 如果您以前依赖与HBase操作集成的客户端跟踪，则建议您将使用情况升级到HTrace 4。 HFile不再向前兼容 由2.0.0, 2.0.1, 2.1.0生成的HFile与 1.4.6-, 1.3.2.1-, 1.2.6.1-和其他非活动版本不向前兼容。 为什么HFile失去兼容性是新版本(2.0.0, 2.0.1, 2.1.0)中的hbase使用protobuf序列化/反序列化TimeRangeTracker（TRT），而旧版本使用DataInput / DataOutput。为解决这个问题,详见: 2.x中 HBASE-21012 , 1.x中 HBASE-21013 . 还有 HBASE-21008.性能 在读取和写入路径发生重大变化的情况下，升级到hbase-2.0.0时，您可能会看到性能配置文件发生变化。 在发布时，写入可能会更慢，读取相同或更好，取决于上下文。准备好花时间重新调整(详见: Apache HBase Performance Tuning). 性能也是一个正在积极审查的领域，因此期待在即将发布的版本中进行改进 (详见: HBASE-20188 TESTING Performance). 集成测试和Kerberos 集成测试（IntegrationTests *）过去依赖于Kerberos凭证缓存来对安全集群进行身份验证。 当凭证缓存中的票证过期时，这会导致由于身份验证失败导致测试失败。 从hbase-2.0.0（和hbase-1.3.0 +）开始，集成测试客户端将使用配置属性hbase.client.keytab.file和hbase.client.kerberos.principal。 它们是必需的。 客户端将从配置的keytab文件执行登录，并在后台自动刷新凭据以获取进程生命周期(详见: HBASE-16231). 13.1.2. 将协处理器升级到 2.0协处理器在2.0中发生了很大变化，从类层次结构中的顶级设计更改到更改/删除的方法，接口等。 (详见 jira: HBASE-18169 Coprocessor fix and cleanup before 2.0.0 release). 这种种广泛变化的原因是: 传递接口而不是实现; e.g. TableDescriptor 而不是 HTableDescriptor and Region 而不是 HRegion (HBASE-18241 更改client.Table 和 client.Admin 并非使用 HTableDescriptor). 设计重构让实现者需要填写更少的样板，因此我们可以进行更多的编译时检查 (HBASE-17732) 从协处理器API清除协议缓冲区 (HBASE-18859, HBASE-16769, etc) 减少我们向Coprocessors公开的内容，删除过于私密而无法公开的内部的钩子(例如: HBASE-18453 CompactionRequest不应该暴露给用户; HBASE-18298 RegionServerServices 对CP公开的接口清理;) 要在2.0中使用协处理器，应该针对新 API重建它们，否则它们将无法加载，HBase进程将会死亡。 升级协处理器的建议更改顺序： 直接实现观察者接口，而不是扩展Base * Observer类。 更改 Foo extends BaseXXXObserver 到 Foo implements XXXObserver. (HBASE-17312). 适应从继承到组合的设计变更 (HBASE-17732) 像 此例. getTable()已从中删除，协处理器应自行管理Table实例。 这里hbase-example模块中可以找到使用新API编写协处理器的一些示例 最后，如果api被更改/删除，会以无法修复的方式打破你，并且如果有充分的理由将其添加回去，请将其通知我们(dev@hbase.apache.org). 13.1.3. 从 1.x 到 2.x的滚动升级滚动升级目前是一项实验性功能。 他们的测试有限。 在我们有限的经历中，有可能发现一些极端情况，所以如果你走这条路，你应该小心。 下一节Upgrade process from 1.x to 2.x中描述的停止/升级/启动是最安全的方式 以下是1.4集群滚动升级的提前要求 前提 升级到最新的1.4.x版本。 Pre 1.4版本也可以使用但未经过测试，因此请在升级到2.x之前升级到1.4.3+，除非您是专家并且熟悉区域分配和崩溃处理。 有关如何升级到1.4.x的信息，请参见Upgrading from pre-1.4 to 1.4+ 部分。 确保启用了无zk赋值，即将hbase.assignment.usezk设置为false。 这是最重要的事情。 它允许1.x主服务器为2.x区域服务器分配/取消分配区域。 有关如何从基于zk的分配迁移到zk less赋值，请参阅 HBASE-11059的发行说明部分。 我们测试了从1.4.3到2.1.0的滚动升级，但如果要升级到2.0.x，它也应该可以工作。 说明 卸载 region服务升级到 2.1.0. 从 HBASE-17931 看出，其他系统表的元区域和区域将立即移动到该区域服务器。 如果没有，请手动将它们移动到新的区域服务器。 这非常重要，因为 元区域的模式是硬编码的，如果元在旧的区域服务器上，则新的区域服务器不能访问它，因为它没有一些族，例如，表状态。 较低版本的客户端可以与具有更高版本的服务器通信，但反之亦然。 如果元区域位于旧区域服务器上，则新区域服务器将使用具有较高版本的客户端与具有较低版本的服务器通信，这可能引入奇怪的问题。 滚动升级所有其他区域服务器。 升级 masters. 在滚动升级期间，区域服务器崩溃是可以的。 1.x主服务器可以为1.x和2.x区域服务器分配区域，HBASE-19166修复了问题，以便 1.x区域服务器还可以读取2.x区域服务器写入的WAL并将其拆分。 在滚动升级之前，请仔细阅读Changes of Note!部分。 确保不使用2.0中删除的功能，例如前缀树编码，旧的hfile格式等。它们都可能无法升级并使群集处于中间状态并且难以恢复。 如果您成功运行此处方，请通知开发者列表，并附上您的经验说明和/或更新上述内容以及您可能采取的任何偏差，以便其他人走这条路线可以从您的努力中受益。 13.1.4. 从1.x升级到2.x的升级过程要升级现有的HBase 1.x群集，您应该： 现有1.x群集关闭 更新协处理器 首先升级主角色 升级RegionServers （最终）升级客户端 13.2. Upgrading from pre-1.4 to 1.4+13.2.1. Region Server memory consumption changes.从HBase 1.4之前的版本升级的用户应该知道，对于最大为32G的堆大小（使用CompressedOops），memstore对象（KeyValue，对象和数组头大小等）的堆使用估计已经更准确，从而导致 他们在实践中下降了10-50％。 由于“更胖”的冲洗，这也导致更少的冲洗和压缩。因人而异。 因此，刷新之前memstore的实际堆使用量可能会增加最多100％。 如果已根据观察到的使用情况调整了区域服务器的已配置内存限制，则此更改可能会导致更糟糕的GC行为或甚至OutOfMemory错误。 将环境属性（不是hbase-site.xml）“hbase.memorylayout.use.unsafe”设置为false以禁用。 13.2.2. Replication peer’s TableCFs 设置在1.4之前，表名不能包含复制对等体的TableCFs配置的名称空间。 通过将TableCF添加到存储在Zookeeper上的ReplicationPeerConfig来修复它。 因此，当升级到1.4时，您必须首先更新Zookeeper上的原始ReplicationPeerConfig数据。 当您的群集具有具有TableCFs配置的复制对等方时，有四个步骤可以升级。 禁用 replication peer. 如果master有权写入复制对等znode，则直接滚动更新master。 如果没有，请使用TableCFsUpdater工具更新复制对等方的配置。 1$ bin/hbase org.apache.hadoop.hbase.replication.master.TableCFsUpdater update 滚动升级regionservers. 开启replication peer. 注意: 无法使用旧客户端（1.4之前）更改复制对等方的配置。 由于客户端将直接向Zookeeper写入配置，因此旧客户端将错过TableCFs配置。 并且旧客户端将TableCFs配置写入旧的tablecfs znode，它不适用于新版本的regionserver。 13.2.3. 原始数据扫描忽略TTL现在，执行原始扫描将返回根据TTL设置已过期的结果。 13.3. 从1.3之前升级到1.3+如果在Kerberos下运行集成测试，请参阅Integration Tests and Kerberos. 13.4. 升级到 1.x有关升级过程的详细信息，请参阅专门针对要升级到的HBase版本发布的文档。]]></content>
      <categories>
        <category>翻译</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Apache HBase ™ 中文指南(最新版HBase 3.0.0)-ch1快速开始]]></title>
    <url>%2F2019%2F02%2F28%2FApache-HBase-%E2%84%A2-%E4%B8%AD%E6%96%87%E6%8C%87%E5%8D%97-%E6%9C%80%E6%96%B0%E7%89%88HBase-3-0-0-ch1%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B%2F</url>
    <content type="text"><![CDATA[入门 译者: xixici 1. 介绍快速开始 会介绍如何运行一个单机版的Standalone模式HBase. 2. 快速开始 - Standalone HBase本章节介绍了在单机安装HBase的方法。会引导你通过hbase shell创建一个表，插入一行，然后执行put和scan指令，开启和关闭这张表，开启和停止HBase。只要10分钟就可以完成以下的操作。 除了下载HBase外，此过程不到10分钟就能完成。 2.1. JDK 版本要求HBase要求安装JDK。有关支持JDK版本的信息，请参阅Java。 2.2. HBase开始过程：下载、配置和启动 Standalone HBase 选择一个[Apache下载镜像]（https://www.apache.org/dyn/closer.lua/hbase/）。 建议点击顶部链接，进入_HBase Releases_ 点击_stable_的文件夹，然后下载将以_tar.gz_结尾的二进制文件到本地。暂时不要下载以_src.tar.gz_结尾的文件。 解压缩，然后进入到那个要解压的目录. 12$ tar xzvf hbase-3.0.0-SNAPSHOT-bin.tar.gz$ cd hbase-3.0.0-SNAPSHOT/ 在启动HBase之前，您需要设置JAVA_HOME环境变量。您可以通过操作系统的常用设置来设置变量，HBase也提供了一个中心机制_conf/hbase-env.sh_。编辑此文件，取消注释以JAVA_HOME开头的行，并将其设置为适合您的操作系统的路径。应将JAVA_HOME变量设置为包含可执行文件_bin/java_的目录。如今，大多数Linux操作系统都提供了一种机制，例如RHEL或CentOS上的/usr/bin/alternatives，可以方便切换环境。在这种情况下，您可以将JAVA_HOME设置为包含_bin/java_的符号链接的目录，通常为_/usr_。 1JAVA_HOME=/usr 编辑HBase主配置文件_conf/hbase-site.xml_.此时，您需要在本地文件系统上指定HBase和ZooKeeper数据存储目录，并知晓一些风险。默认情况下，HBase会在/tmp下创建一个新目录，但是许多服务为在重新启动时会删除_/tmp_的内容，因此您需要将数据存储在其他位置。以下配置文件处在_hbase_,名为testuser的用户的主目录中。首次安装HBase为空，可以将&lt;property&gt;标记粘贴在&lt;configuration&gt;内。 示例 1. _hbase-site.xml_ Standalone HBase配置 12345678910111213141516171819202122232425&lt;configuration&gt; &lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;file:///home/testuser/hbase&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt; &lt;value&gt;/home/testuser/zookeeper&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hbase.unsafe.stream.capability.enforce&lt;/name&gt; &lt;value&gt;false&lt;/value&gt; &lt;description&gt; Controls whether HBase will check for stream capabilities (hflush/hsync). Disable this if you intend to run on LocalFileSystem, denoted by a rootdir with the &apos;file://&apos; scheme, but be mindful of the NOTE below. WARNING: Setting this to false blinds you to potential data loss and inconsistent system state in the event of process and/or node failures. If HBase is complaining of an inability to use hsync or hflush it&apos;s most likely not a false positive. &lt;/description&gt; &lt;/property&gt;&lt;/configuration&gt; 您不需要创建HBase数据目录。 HBase会自动创建。如果您想要自定义创建目录，HBase将尝试进行迁移 。 上例中的_hbase.rootdir_指向_local filesystem_中的目录。 ‘file：//‘前缀是表示本地文件系。您应该将配置示例中的警告牢记在心。在Standalone模式下，HBase利用Apache Hadoopd的本地文件存储。但是这种方式并不能保证HBase运行的持久性。这只是适用于于本地开发和测试用例，可以很好的控制集群故障的成本。它不适合生产部署，否则你会丢失数据。 为在HDFS上部署HBase, 可以将 _hbase.rootdir_ 指向如: _hdfs://namenode.example.org:8020/hbase_. 有关此变量的更多用法，可查看章节基于HDFS部署Standalone HBase. 脚本_bin/start-hbase.sh_为启动HBase提供了方便的途径。执行命令，在标准输出的日志里可以看到HBase启动成功的消息。你可以使用 jps 命令来确认你有一个正在运行的进行 HMaster。在 HBase 的Standalone模式中，所有的服务都运行在同一JVM中，如 HMaster，单例的 HRegionServer 和 ZooKeeper 的守护进程。可以前往Web UI_http://localhost:16010_查看HBase. Java必须安装且可用. 如果你收到错误提示，Java未安装，可能java位于非标准位置，你可以编辑_conf/hbase-env.sh_ ,修改 JAVA_HOME 路径，并确保包含 _bin/java_. 过程: 首次使用HBase 连接HBase 在HBase安装目录_bin/_ 目录下使用hbase shell命令连接正在运行的HBase实例。 在下面这个例子中，当你启动HBase Shell 并忽略一些用法和版本信息后，HBase Shell 是以字符&gt; 结尾。 12$ ./bin/hbase shellhbase(main):001:0&gt; 预览 HBase Shell 的帮助文本 输入help并回车, 可以看到HBase Shell的基本信息和一些示例命令.请注意，表名，行，列都必须用引号字符括起来。 创建表 使用 create创建一个表，你必须执行一个表名和列族名。 1234hbase(main):001:0&gt; create &apos;test&apos;, &apos;cf&apos;0 row(s) in 0.4170 seconds=&gt; Hbase::Table - test 表信息 使用 list 查看存在表 123456hbase(main):002:0&gt; list &apos;test&apos;TABLEtest1 row(s) in 0.0180 seconds=&gt; [&quot;test&quot;] 使用 describe 查看表细节及配置 12345678910hbase(main):003:0&gt; describe &apos;test&apos;Table test is ENABLEDtestCOLUMN FAMILIES DESCRIPTION&#123;NAME =&gt; &apos;cf&apos;, VERSIONS =&gt; &apos;1&apos;, EVICT_BLOCKS_ON_CLOSE =&gt; &apos;false&apos;, NEW_VERSION_BEHAVIOR =&gt; &apos;false&apos;, KEEP_DELETED_CELLS =&gt; &apos;FALSE&apos;, CACHE_DATA_ON_WRITE =&gt;&apos;false&apos;, DATA_BLOCK_ENCODING =&gt; &apos;NONE&apos;, TTL =&gt; &apos;FOREVER&apos;, MIN_VERSIONS =&gt; &apos;0&apos;, REPLICATION_SCOPE =&gt; &apos;0&apos;, BLOOMFILTER =&gt; &apos;ROW&apos;, CACHE_INDEX_ON_WRITE =&gt; &apos;false&apos;, IN_MEMORY =&gt; &apos;false&apos;, CACHE_BLOOMS_ON_WRITE =&gt; &apos;false&apos;, PREFETCH_BLOCKS_ON_OPEN =&gt; &apos;false&apos;, COMPRESSION =&gt; &apos;NONE&apos;, BLOCKCACHE =&gt; &apos;true&apos;, BLOCKSIZE =&gt; &apos;65536&apos;&#125;1 row(s)Took 0.9998 seconds 插入数据 使用 put 插入数据 12345678hbase(main):003:0&gt; put &apos;test&apos;, &apos;row1&apos;, &apos;cf:a&apos;, &apos;value1&apos;0 row(s) in 0.0850 secondshbase(main):004:0&gt; put &apos;test&apos;, &apos;row2&apos;, &apos;cf:b&apos;, &apos;value2&apos;0 row(s) in 0.0110 secondshbase(main):005:0&gt; put &apos;test&apos;, &apos;row3&apos;, &apos;cf:c&apos;, &apos;value3&apos;0 row(s) in 0.0100 seconds 在这里，我们往test表中依次插入了三条数据。首先插入了一条rowkey为row1、列为cf:a、值为value1的数据。HBase中的列是包含列族前缀的，在这个例子中，冒号前的为列 cf，冒号后的为列限定符 a 。 扫描全部数据 从HBase获取数据的途径之一就是 scan 。使用 scan 命令扫描表数据。你可以对扫描做限制，不过现在，获取全部的数据。 123456hbase(main):006:0&gt; scan &apos;test&apos;ROW COLUMN+CELL row1 column=cf:a, timestamp=1421762485768, value=value1 row2 column=cf:b, timestamp=1421762491785, value=value2 row3 column=cf:c, timestamp=1421762496210, value=value33 row(s) in 0.0230 seconds 获取一条数据 使用 get 命令一次获取一条数据。 1234hbase(main):007:0&gt; get &apos;test&apos;, &apos;row1&apos;COLUMN CELL cf:a timestamp=1421762485768, value=value11 row(s) in 0.0350 seconds 禁用表 如果你想删除一个表或者改变表的设置，以及一些其他的场景，首先你需要使用 disable 命令禁用表。你可以使用 enable 命令“反禁用”即启用表。 12345hbase(main):008:0&gt; disable &apos;test&apos;0 row(s) in 1.1820 secondshbase(main):009:0&gt; enable &apos;test&apos;0 row(s) in 0.1770 seconds Disable the table again if you tested the enable command above: 12hbase(main):010:0&gt; disable &apos;test&apos;0 row(s) in 1.1820 seconds 删除表 使用 drop 命令删除一个表。 12hbase(main):011:0&gt; drop &apos;test&apos;0 row(s) in 0.1370 seconds 退出HBase Shell. 使用quit命令退出命令行并从集群断开连接。HBase 仍然在后台运行。 过程: 停止HBase 脚本 _bin/start-hbase.sh_ 这个脚本提供了便利的启动所有 HBase 服务，同样地， _bin/stop-hbase.sh_ 脚本用来停止所有HBase服务。 123$ ./bin/stop-hbase.shstopping hbase....................$ 在使用这个命令后，它可能需要过几分钟才能停掉服务进程。可以使用 jps 确认 HMaster 和 HRegionServer 进程是否关闭。 上面已经向您展示了如何启动和停止HBase的Standalone实例。在下一节中，我们将简要介绍HBase其他部署模式。 2.3. 伪分布式HBase在快速开始小节部署了Standalone模式的HBase后，您可以重新配置以伪分布式运行。伪分布模式意味着HBase仍然在单个主机上完全运行，但是每个HBase守护进程（HMaster，HRegionServer和ZooKeeper）作为一个单独的进程运行：在独立模式下，所有守护进程都运行在一个jvm进程/实例中。 默认情况下, 除非你按 快速开始更改hbase.rootdir 的配置，否则你的数据仍会存储在 _/tmp/_中。假设HDFS系统可用，我们将数据存储在HDFS上。 当然，您可以跳过HDFS配置，继续使用本地文件系统。 Hadoop配置 此过程假定已在本地系统或远程系统上配置Hadoop和HDFS，并且保证正在运行且可用，版本为Hadoop 2。Hadoop文档向导 配置单节点集群. 停止HBase 假设你刚刚完成 快速开始 , Hbase正在运行, 那么请停止他.这个过程将创建一个全新的目录，HBase将存储它的数据，所以你之前创建的任何数据库都将丢失。 配置HBase 编辑 _hbase-site.xml_ . 首先，添加以下指示HBase以分布式模式运行的属性，每个守护进程有一个JVM实例 1234&lt;property&gt; &lt;name&gt;hbase.cluster.distributed&lt;/name&gt; &lt;value&gt;true&lt;/value&gt;&lt;/property&gt; 接下来，将 hbase.rootdir 从本地文件系统更改为您的 HDFS 实例的地址，使用 hdfs:////的 URI 语法。在这个例子中，HDFS在端口8020\的本地主机上运行。并确保 hbase.unsafe.stream.capability.enforce删除或为true. 1234&lt;property&gt; &lt;name&gt;hbase.rootdir&lt;/name&gt; &lt;value&gt;hdfs://localhost:8020/hbase&lt;/value&gt;&lt;/property&gt; 您不需要在HDFS中创建目录。HBase会为你做这个。如果你要更改目录，HBase会试图迁移。 启动HBase 使用_bin/start-hbase.sh_ 启动HBase. 如果您的系统配置正确，该jps命令应显示HMaster和HRegionServer进程正在运行。 检查HDFS中的HBase目录 如果一切正常，HBase在HDFS中创建它的目录。在上面的配置中，它存储在HDFS上的_/hbase/_中。您可以使用 hadoop 的 _bin/_目录中的hadoop fs 命令来列出此目录。 123456789$ ./bin/hadoop fs -ls /hbaseFound 7 itemsdrwxr-xr-x - hbase users 0 2014-06-25 18:58 /hbase/.tmpdrwxr-xr-x - hbase users 0 2014-06-25 21:49 /hbase/WALsdrwxr-xr-x - hbase users 0 2014-06-25 18:48 /hbase/corruptdrwxr-xr-x - hbase users 0 2014-06-25 18:58 /hbase/data-rw-r--r-- 3 hbase users 42 2014-06-25 18:41 /hbase/hbase.id-rw-r--r-- 3 hbase users 7 2014-06-25 18:41 /hbase/hbase.versiondrwxr-xr-x - hbase users 0 2014-06-25 21:49 /hbase/oldWALs 创建一个表并使用数据填充它 您可以使用HBase Shell创建一个表，使用数据填充它，使用与shell练习中相同的步骤。 启动和停止备份HBase主（HMaster）服务器 在同一个硬件上运行多个HMaster实例在生产环境中是没有意义的，就像运行伪分布式集群对于生产没有意义一样。此步骤仅供测试和学习之用。 HMaster服务器控制HBase集群。你可以启动最多9个备份HMaster服务器，这个服务器总共有10个HMaster计算主服务器。使用local-master-backup.sh启动备份HMaster。对于要启动的每个备份主节点，请添加一个表示该主节点的端口偏移量的参数。每个HMaster使用三个端口（默认情况下为16010,16020和16030）。端口偏移量2添加到这些端口，那么备份HMaster将使用端口16012,16022和16032。以下命令启动服务器端口为：16012/16022/16032，16013/16023/16033和16015/16025/16035 1$ ./bin/local-master-backup.sh start 2 3 5 要在不杀死整个群集的情况下杀死备份主机，则需要查找其进程ID（PID）。PID存储在一个名为_/tmp/hbase-USER-X-master.pid_的文件中。该文件的唯一内容是PID。您可以使用该kill -9命令来杀死该PID。以下命令将终止具有端口偏移1的主服务器，但保持群集正在运行： 1$ cat /tmp/hbase-testuser-1-master.pid |xargs kill -9 启动和停止其他RegionServers HRegionServer按照HMaster的配置管理StoreFiles中的数据。通常，一个HRegionServer在集群中的每个节点上运行。在同一个系统上运行多个HRegionServers对于伪分布式模式下的测试非常有用。该local-regionservers.sh命令允许您运行多个RegionServer。它以类似的local-master-backup.sh命令的方式工作，因为您提供的每个参数都代表实例的端口偏移量。每个RegionServer需要两个端口，默认端口是16020和16030。但是，由于HMaster使用默认端口，所以其他RegionServers的基本端口不是默认端口，而HMaster自从HBase版本1.1.0以来也是RegionServer。基本端口是16200和16300。您可以在服务器上运行另外99个不是HMaster或备份HMaster的RegionServer。以下命令将启动另外四个RegionServers，它们在从16202/16302（基本端口16200/16300加2）开始的顺序端口上运行 HBase从版本1.1.0开始, HMaster不使用 region server端口, 而为RegionServers预留了10个端口 (16020 to 16029 and 16030 to 16039). 为支持添加RegionServers, 在启动local-regionservers.sh之前,需设置HBASE_RS_BASE_PORT 和 HBASE_RS_INFO_BASE_PORT.例如, 使用基本端口16200和16300。也可以使用另外99个端口。 以下命令将启动另外四个RegionServers，它们在从16202/16302（基本端口16200/16300加2）开始的顺序端口上运行。 1$ .bin/local-regionservers.sh start 2 3 4 5 要手动停止RegionServer，请使用带有stop参数和服务器偏移量的local-regionservers.sh命令停止。 1$ .bin/local-regionservers.sh stop 3 停止HBase 您可以使用 _bin/stop-hbase.sh_命令以与快速开始过程相同的方式停止HBase 。 2.4. 完全分布式HBase实际上，您需要一个完全分布式的配置来全面测试HBase，并将其用于实际场景中。在分布式配置中，集群包含多个节点，每个节点运行一个或多个HBase守护进程。这些包括主要和备份主实例，多个ZooKeeper节点和多个RegionServer节点。 此高级快速入门将两个以上的节点添加到您的群集。架构如下： Node Name Master ZooKeeper RegionServer node-a.example.com yes yes no node-b.example.com backup yes yes node-c.example.com no yes yes 这个快速入门假定每个节点都是虚拟机，并且它们都在同一个网络上。它基于之前的快速入门、本地和伪分布式HBase，假设您在该过程中配置的系统是现在node-a。继续之前，在node-a停止HBase 。 请确保所有节点都具有完全的通信访问权限，并且没有任何防火墙规则可以阻止。如果您看到任何错误，如no route to host，请检查您的防火墙设置。 过程: 配置无密码SSH访问 node-a需要能够登录node-b和node-c（包含自己）才能启动守护进程。实现这一点的最简单的方法是在所有主机上使用相同的用户名，并配置node-a到其他的无密码的SSH登录 在node-a，生成一个密钥对 以运行HBase的用户身份登录时，使用以下命令生成SSH密钥对： 1$ ssh-keygen -t rsa 如果命令成功，密钥对的位置将打印到标准输出。公钥的默认名称是 _id_rsa.pub_. 创建并共享密钥的目录 在node-b和上node-c，以HBase用户身份登录，并在用户主目录中创建一个_.ssh/_目录（如果尚不存在）。如果它已经存在，请注意它可能已经包含其他值。 将公钥复制到其他节点 通过使用scp或其他一些安全的手段，安全地将公钥从node-a复制到每个节点。在其他每个节点上，创建一个名为_.ssh/authorized_keys_的新文件（如果该文件尚不存在），并将_id_rsa.pub_ 文件的内容附加到该文件的末尾。请注意，你也需要为node-a本身执行此项。 1$ cat id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys 测试无密码登录 确保过程正确,可以以相同用户名从node-a 无密码登录其他节点. 由于 node-b 是备份主节点, 重复上述步骤,将node-a替换为node-b.确保不会覆盖现有的 _.ssh/authorized_keys_ 文件, 可以使用&gt;&gt;运算符而不是&gt;运算符将新密钥添加到文件末尾。 过程: 准备 node-a node-a 是主节点和ZooKeeper进程节点,而不是RegionServers服务. 首先停止node-aRegionServers服务 编辑 _conf/regionservers_ 移除包含 localhost的列. 添加 node-b 和 node-c的主机名和IP. 即使你非要在 node-a上运行regionserver, 你应该配置主机名. 演示中为 node-a.example.com.确保您能够将配置分发到集群的每个节点上并无任何主机名冲突。保存文件。 配置HBase,将 node-b作为备份主节点 在 _conf/_ 目录创建 _backup-masters_添加新的一行主机名为 node-b. 演示中主机名为 node-b.example.com. 配置ZooKeeper 实际上，你应该仔细考虑你的ZooKeeper配置。您可以在zookeeper部分找到更多关于配置ZooKeeper的信息。这个配置将指示HBase在集群的每个节点上启动和管理一个ZooKeeper实例。在node-a上，编辑_conf/hbase-site.xml_并添加下列属性 12345678&lt;property&gt; &lt;name&gt;hbase.zookeeper.quorum&lt;/name&gt; &lt;value&gt;node-a.example.com,node-b.example.com,node-c.example.com&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;hbase.zookeeper.property.dataDir&lt;/name&gt; &lt;value&gt;/usr/local/zookeeper&lt;/value&gt;&lt;/property&gt; 在您的配置中，您已经将node-a作为localhost引用，将引用改为指向其他节点用来引用 node-a的主机名。在这些例子中，主机名是node-a.example.com 过程: 准备 node-b 和 node-c node-b 将运行一个备份主服务器和一个ZooKeeper实例。 下载并解压HBase 将HBase下载并解压到node-b，就像您为独立和伪分布式快速入门所操作的一样。 将配置文件从node-a复制到node-b和node-c 的群集的每个节点都需要具有相同的配置信息。将_conf/_ 目录下的内容复制到node-b和node-c上的_conf/_ 目录中。 过程: 启动并测试群集 确保HBase没有在任何节点上运行 如果您在之前的测试中忘记停止HBase，您将会遇到错误。通过使用该jps命令检查HBase是否在任何节点上运行。寻HMaster, HRegionServer和 HQuorumPeer的进程。如果他们存在，杀掉他们 启动集群 在node-a，发出start-hbase.sh命令。您的输出将类似于下面的输出。 12345678$ bin/start-hbase.shnode-c.example.com: starting zookeeper, logging to /home/hbuser/hbase-0.98.3-hadoop2/bin/../logs/hbase-hbuser-zookeeper-node-c.example.com.outnode-a.example.com: starting zookeeper, logging to /home/hbuser/hbase-0.98.3-hadoop2/bin/../logs/hbase-hbuser-zookeeper-node-a.example.com.outnode-b.example.com: starting zookeeper, logging to /home/hbuser/hbase-0.98.3-hadoop2/bin/../logs/hbase-hbuser-zookeeper-node-b.example.com.outstarting master, logging to /home/hbuser/hbase-0.98.3-hadoop2/bin/../logs/hbase-hbuser-master-node-a.example.com.outnode-c.example.com: starting regionserver, logging to /home/hbuser/hbase-0.98.3-hadoop2/bin/../logs/hbase-hbuser-regionserver-node-c.example.com.outnode-b.example.com: starting regionserver, logging to /home/hbuser/hbase-0.98.3-hadoop2/bin/../logs/hbase-hbuser-regionserver-node-b.example.com.outnode-b.example.com: starting master, logging to /home/hbuser/hbase-0.98.3-hadoop2/bin/../logs/hbase-hbuser-master-nodeb.example.com.out ZooKeeper首先启动，然后是master，然后是RegionServers，最后是backup masters。 验证进程是否正在运行 在集群的每个节点上，运行该jps命令并验证每台服务器上是否运行了正确的进程。如果用于其他用途，您可能会看到在您的服务器上运行的其他Java进程。 node-a jps 输出 1234$ jps20355 Jps20071 HQuorumPeer20137 HMaster node-b jps 输出 12345$ jps15930 HRegionServer16194 Jps15838 HQuorumPeer16010 HMaster node-c jps 输出 1234$ jps13901 Jps13639 HQuorumPeer13737 HRegionServer ZooKeeper 进程名称 进程HQuorumPeer是一个由HBase控制和启动的ZooKeeper实例.如果以这种方式使用ZooKeeper，则每个群集节点仅限于一个实例，并且仅适用于测试。如果ZooKeeper在HBase之外运行，则调用该进程QuorumPeer。更多请查看章节 zookeeper . Web UI. Web UI 接口更改 在HBase 0.98.x以上, HBase Web UI的端口从主节点的60010和RegionServer的60030变化为16010 和 16030 如果一切设置正确，您应该能够使用Web浏览器连接到Master[http://node-a.example.com:16010/](http://node-a.example.com:16010/)或Secondary Master的UI [http://node-b.example.com:16010/](http://node-b.example.com:16010/) 。如果您可以通过localhost而不是从另一台主机连接，请检查您的防火墙规则。您可以在端口16030的IP地址中查看每个RegionServers的Web UI，也可以通过单击Master的Web UI中的链接来查看。 测试节点或服务消失时会发生什么 在配置了三节点集群后，集群并不会很有弹性。您仍然可以通过关闭进程并查看日志来测试主Master或RegionServer的行为。 2.5. 接下来下一章节 configuration, 提供有关不同的HBase运行模式、运行HBase的系统要求以及分布式HBase群集的关键配置的详细信息。]]></content>
      <categories>
        <category>翻译</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Apache HBase ™ 中文指南(最新版HBase 3.0.0)-ch0前言]]></title>
    <url>%2F2019%2F02%2F28%2FApache-HBase-%E2%84%A2-%E4%B8%AD%E6%96%87%E6%8C%87%E5%8D%97-%E6%9C%80%E6%96%B0%E7%89%88HBase-3-0-0-ch0%E5%89%8D%E8%A8%80%2F</url>
    <content type="text"><![CDATA[前言 译者: xixici 此处为HBase版本的官方参考指南。 从这里，你不仅能找到发布的HBase版本的最终文档，而且包括相关Javadoc和JIRA信息。 关于指南本指南仍在编辑当中。本指南的源码可以在文件夹_src/main/asciidoc当中找到。本指南最终使用 AsciiDoc 构建，成为’站点’的一部分. 运行 1mvn site 来生成此文档。并且欢迎对此进行修改和改进。点击此链接 提供bug反馈. 文档贡献有关AsciiDoc的概述以及文档参与的建议，请参阅本文档后面的相关部分。 如果这是你第一次涉足分布式计算领域…… 若这是你第一次踏入分布式计算的精彩世界，你会感到这是一个有趣的年代。分布式计算是很难的，做一个分布式系统需要很多软硬件和网络的技能。 你的集群可以会因为各式各样的错误发生故障。比如HBase本身的Bug,错误的配置(包括操作系统)，硬件的故障(网卡和磁盘甚至内存)（Issue里有两个最近的硬件问题示例，表现为“HBase很慢”） 如果你一直在写单机程序的话，你需要重新开始学习。这是一个很好的起点分布式计算的谬论. 所以，欢迎你。这是一个有趣的地方。HBase社区。 报告bugs请使用 [JIRA]（https://issues.apache.org/jira/browse/hbase） 报告与安全无关的错误。 为了保护现有HBase安装免受新漏洞的影响，请勿使用JIRA报告与安全相关的错误。 相反，请将您的报告发送到邮件列表[private@hbase.apache.org]（mailto：private@hbase.apache.org），该列表允许任何人发送邮件，但限制谁可以阅读邮件。 该列表中的某个人将与您联系以跟进您的报告。 支持和测试以下短语/支持/，/不支持/，/测试/，和/未测试/经常出现在本指南中。 为方便起见，这里先简要解释了这些短语在HBase背景下的含义 许多Hadoop供应商都提供Apache HBase的商业版本的技术支持。 但这不是在Apache HBase项目中/ 支持 /的意义。 Apache HBase团队对您的HBase集群，配置或数据不承担任何责任。 支持在Apache HBase中，/ 支持 /意味着HBase被设计为以所描述的方式工作，并且应该将与定义的行为或功能的偏差报告为错误。 不支持在Apache HBase中，/不支持/意味着用例或使用模式不会重视，应该被视为反模式。如果您认为应该针对给定功能或使用模式重新考虑，请提交JIRA或通过邮件讨论。 已测试在Apache HBase中，/ 已测试 /意味着单元或集成测试涵盖了一个功能，并且已经证明可以按预期工作。 未测试在Apache HBase中，/未测试/表示功能或使用模式可能或可能不以给定方式工作，并且可能会也可能不会损坏您的数据或导致操作问题。这是未知的，没有任何保证。如果您可以提供指定为/未经测试/的功能以特定方式工作的证据，请提交测试和指标，以便其他用户可以确定使用有关功能或使用模式。]]></content>
      <categories>
        <category>翻译</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[初次运行 Git 前的配置]]></title>
    <url>%2F2019%2F02%2F25%2Ffirst-with-git%2F</url>
    <content type="text"><![CDATA[一般在新的系统上，我们都需要先配置下自己的 Git 工作环境。配置工作只需一次，以后升级时还会沿用现在的配置。当然，如果需要，你随时可以用相同的命令修改已有的配置。 git config 的工具（译注：实际是 git-config 命令，只不过可以通过 git 加一个名字来呼叫此命令。），专门用来配置或读取相应的工作环境变量。而正是由这些环境变量，决定了 Git 在各个环节的具体工作方式和行为。这些变量可以存放在以下三个不同的地方： 目录/etc/gitconfig文件：系统中对所有用户都普遍适用的配置。若使用 git config 时用 —system 选项，读写的就是这个文件。 ~/.gitconfig文件：用户目录下的配置文件只适用于该用户。若使用 git config 时用 —global 选项，读写的就是这个文件。 当前项目的 Git目录中的配置文件（也就是工作目录中的 .git/config 文件）：这里的配置仅仅针对当前项目有效。每一个级别的配置都会覆盖上层的相同配置，所以 .git/config 里的配置会覆盖 /etc/gitconfig 中的同名变量。 在 Windows 系统上，Git 会找寻用户主目录下的 .gitconfig 文件。主目录即 $HOME 变量指定的目录，一般都是 C:\Documents and Settings$USER。此外，Git 还会尝试找寻 /etc/gitconfig 文件，只不过看当初 Git 装在什么目录，就以此作为根目录来定位。 用户信息第一个要配置的是你个人的用户名称和电子邮件地址。这两条配置很重要，每次 Git 提交时都会引用这两条信息，说明是谁提交了更新，所以会随更新内容一起被永久纳入历史记录： 12$ git config --global user.name &quot;John Doe&quot;$ git config --global user.email johndoe@example.com 如果用了 —global 选项，那么更改的配置文件就是位于你用户主目录下的那个，以后你所有的项目都会默认使用这里配置的用户信息。如果要在某个特定的项目中使用其他名字或者电邮，只要去掉 —global 选项重新配置即可，新的设定保存在当前项目的 .git/config 文件里。 查看配置信息要检查已有的配置信息，可以使用 git config —list 命令：12345678$ git config --listuser.name=Scott Chaconuser.email=schacon@gmail.comcolor.status=autocolor.branch=autocolor.interactive=autocolor.diff=auto... 有时候会看到重复的变量名，那就说明它们来自不同的配置文件（比如 /etc/gitconfig 和 ~/.gitconfig），不过最终 Git 实际采用的是最后一个。 也可以直接查阅某个环境变量的设定，只要把特定的名字跟在后面即可，像这样：12$ git config user.nameScott Chacon 文本编辑器接下来要设置的是默认使用的文本编辑器。Git 需要你输入一些额外消息的时候，会自动调用一个外部文本编辑器给你用。默认会使用操作系统指定的默认编辑器，一般可能会是 Vi 或者 Vim。如果你有其他偏好，比如 Emacs 的话，可以重新设置： git config --global core.editor emacs```12345差异分析工具还有一个比较常用的是，在解决合并冲突时使用哪种差异分析工具。比如要改用 vimdiff 的话：```$ git config --global merge.tool vimdiff Git 可以理解 kdiff3，tkdiff，meld，xxdiff，emerge，vimdiff，gvimdiff，ecmerge，和 opendiff 等合并工具的输出信息。当然，你也可以指定使用自己开发的工具，具体怎么做可以参阅第七章。 参考https://git-scm.com/book/zh/v1/%E8%B5%B7%E6%AD%A5-%E5%88%9D%E6%AC%A1%E8%BF%90%E8%A1%8C-Git-%E5%89%8D%E7%9A%84%E9%85%8D%E7%BD%AE]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[配置 SSH 公钥访问 Github 和 Coding 仓库]]></title>
    <url>%2F2019%2F02%2F22%2Fssh-connect-coding-and-github%2F</url>
    <content type="text"><![CDATA[生成公钥打开命令行终端输入ssh-keygen -t rsa -C &lt;your_email@example.com&gt;( 你的邮箱)，连续点击 Enter 键即可。 12345sh-keygen -t rsa -C &lt;your_email@example.com&gt;# Creates a new ssh key, using the provided email as a label# Generating public/private rsa key pair.Enter file in which to save the key (/Users/you/.ssh/id_rsa): [Press enter] // 推荐使用默认地址Enter passphrase (empty for no passphrase): //此处点击 Enter 键即可，也可以填写密码，填写密码后每次使用 SSH 方式推送代码时都会要求输入密码，由于这个 Key 也不是用于军事目的，所以也无需设置密码。 成功之后显示如下信息： 1234Your identification has been saved in /Users/you/.ssh/id_rsa.# Your public key has been saved in /Users/you/.ssh/id_rsa.pub.# The key fingerprint is:# 01:0f:f4:3b:ca:85:d6:17:a1:7d:f0:68:9d:f0:a2:db your_email@example.com Coding.net添加公钥Coding 提供账户 SSH 公钥和项目 SSH 公钥设置。本质上账户公钥和部署公钥是一样的，只是关联的方式不同。同一个 SSH 公钥文件，如果和 Coding 账户关联，便称为账户 SSH 公钥，配置后拥有账户下所有项目的读写权限；如果和具体的某一个项目关联，则称为部署公钥，配置后默认拥有该项目的只读权限。 添加账户公钥 在终端输入open ~/.ssh，用文本编辑器打开「id_rsa.pub」文件（此处是生成公钥的默认名称，如果生成公钥时采用了其他名称，打开相对应的文件即可），复制全部内容 登录 Coding.net，进入「账户 -&gt; SSH 公钥」页面，点击「新增公钥」 将第一步中复制的内容填写到「公钥内容」一栏，公钥名称可随意填写 设定公钥有效期，可选择具体日期或设置永久有效 添加部署公钥 在终端输入open ~/.ssh，用文本编辑器打开「id_deploy.pub」文件（此处部署公钥名称为「id_deploy.pub」，用户在生成部署公钥的时候完全可以自定义名称），复制全部内容 登录 Coding.net，进入目标项目，点击「设置 -&gt; 部署公钥 -&gt; 新建部署公钥」 将第一步中复制的内容填写到「公钥内容」一栏，公钥名称自定义 点击「添加」，然后输入账户密码即可成功添加部署公钥 Github.com添加公钥类似上面 最终测试-重要添加完成之后, 切记要测试连接如下: 123ssh -T git@git.coding.net ssh -T git@github.com 参考 https://help.github.com/en/articles/adding-a-new-ssh-key-to-your-github-account https://coding.net/help/doc/git/ssh-key.html]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[机器学习相关评估指标，分类，回归，聚类]]></title>
    <url>%2F2019%2F02%2F18%2Fevaluating-indicator%2F</url>
    <content type="text"><![CDATA[分类算法混淆矩阵 实际表现 1 P 0 N 预测表现 1 P TP FP 0 N FN TN P（Positive）： 代表分类1 N（Negative）： 代表分类0 T（True）： 代表预测正确 F（False）： 代表预测错误 于是乎: TP： 预测为1，预测正确，实际1 FP： 预测为1，预测错误，实际0 FN： 预测为0，预测错确，实际1 TN： 预测为0，预测正确，实际0 准确率准确率的定义是预测正确的结果占总样本的百分比 . 准确率=(TP+TN)/(TP+TN+FP+FN) 样本不平衡的情况下，并不能作为很好的指标来衡量结果。 精准率精准率（Precision）又叫查准率，它是针对预测结果而言的，它的含义是在所有被预测为正的样本中实际为正的样本的概率，意思就是在预测为正样本的结果中，我们有多少把握可以预测正确，其公式如下： 精准率=TP/(TP+FP) 精准率与准确率区别精准率代表对正样本结果中的预测准确程度，而准确率则代表整体的预测准确程度，既包括正样本，也包括负样本。 召回率召回率（Recall）又叫查全率，它是针对原样本而言的，它的含义是在实际为正的样本中被预测为正样本的概率，其公式如下： 精准率=TP/(TP+FN) F1分数通常，如果想要找到二者之间的一个平衡点，我们就需要一个新的指标：F1分数。F1分数同时考虑了查准率和查全率，让二者同时达到最高，取一个平衡。 F1分数 = 2*查准率*查全率 / (查准率 + 查全率) P-R曲线（查准率-查全率）横坐标为查全率（召回率（Recall）），纵坐标为查准率（精准率（Precision） ） 真正率&amp;假正率灵敏度（Sensitivity） = TP/(TP+FN) 特异度（Specificity） = TN/(FP+TN) 真正率（TPR） = 灵敏度 = TP/(TP+FN) 假正率（FPR） = 1- 特异度 = FP/(FP+TN) ROC（接受者操作特征曲线）横坐标为假正率（FPR），纵坐标为真正率（TPR） AUC（曲线下的面积）AUC的一般判断标准 0.5 - 0.7： 效果较低，但用于预测股票已经很不错了 0.7 - 0.85： 效果一般 0.85 - 0.95： 效果很好 0.95 - 1： 效果非常好，但一般不太可能 回归算法f表示预测值，y表示实际值 MAE(Mean Absolute Error) 平均绝对误差平均绝对误差MAE（Mean Absolute Error）又被称为 l1 范数损失 MAE = \frac{ 1}{ n}\sum\limits_{ i = 1}^n { \left| { { f_i} - { y_i}} \right|}MAE不足MAE虽能较好衡量回归模型的好坏，但是绝对值的存在导致函数不光滑，在某些点上不能求导，可以考虑将绝对值改为残差的平方，这就是均方误差。 MSE(Mean Square Error) 平均平方差/均方误差均方误差MSE(Mean Squared Error)又被称为 l2 范数损失 MSE = \frac{ 1}{ n}\sum\limits_{ i = 1}^n { { { \left( { { f_i} - { y_i}} \right)}^2}}MSE不足MSE和方差的性质比较类似，与我们的目标变量的量纲不一致，为了保证量纲一致性，我们需要对MSE进行开方得到RMSE。 RMSE(Root Mean Square Error) 均方根误差RMSE = \sqrt { MSE} = \sqrt { \frac{ 1}{ n}\sum\limits_{ i = 1}^n { { { \left( { { f_i} - { y_i}} \right)}^2}} }RMSE不足上面的几种衡量标准的取值大小与具体的应用场景有关系，很难定义统一的规则来衡量模型的好坏。比如说利用机器学习算法预测上海的房价RMSE在2000元，我们是可以接受的，但是当四五线城市的房价RMSE为2000元，我们还可以接受吗？下面介绍的决定系数就是一个无量纲化的指标。 R2（R-Square）决定系数Coefficient of determination$ \bar y $ 表示观测数据的平均值 残差平方和S{ S_{ res}} = \sum\limits_{ i = 1}^n { { { \left( { { f_i} - { y_i}} \right)}^2}}总平方和 S{ S_{ tot}} = \sum\limits_{ i = 1}^n { { { \left( { { y_i} - \bar y} \right)}^2}}R方 { r^2} = 1 - \frac{ { S{ S_{ res}}}}{ { S{ S_{ tot}}}} = 1 - \frac{ { \sum\limits_{ i = 1}^n { { { \left( { { f_i} - { y_i}} \right)}^2}} }}{ { \sum\limits_{ i = 1}^n { { { \left( { { y_i} - \bar y} \right)}^2}} }}分母理解为原始数据的离散程度，分子为预测数据和原始数据的误差，二者相除可以消除原始数据离散程度的影响 Adjusted R-Square (校正决定系数） r_{ adj}^2 = 1 - \frac{ { \left( { 1 - { r^2}} \right)\left( { n - 1} \right)}}{ { n - p - 1}}n为样本数量，p为特征数量消除了样本数量和特征数量的影响 聚类算法轮廓系数（Silhouette Coefficient）对于其中的一个点 i 来说： a(i) = average(i向量到所有它属于的簇中其它点的距离)b(i) = min (i向量到各个非本身所在簇的所有点的平均距离)那么 i 向量轮廓系数就为： s\left( i \right) = \frac { { b\left( i \right) - a\left( i \right)}} { { \max \left\ { { a\left( i \right) ,b\left( i \right)} \right\}}} = \left\ { { \begin { array} { * { 20} { c}} { 1 - \frac { { a\left( i \right)}} { { b\left( i \right)}}}& { ,a\left( i \right) < b\left( i \right)} & \\ 0& { ,a\left( i \right) = b\left( i \right)} & \\ { \frac { { b\left( i \right)}} { { a\left( i \right)}} - 1}& { ,a\left( i \right) > b\left( i \right)} & \end { array}} \right.]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>deeplearning</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[idea-start]]></title>
    <url>%2F2019%2F02%2F15%2Fidea-start%2F</url>
    <content type="text"><![CDATA[IntelliJ IDEA主题设置 主题我现用主题: http://www.riaway.com/themeshow.php?tid=13$cid=1理论上JetBrain家族的所有产品都能使用,IDEA, Pycharm, webstorm等等,方法是File-&gt;Import setting, 选择你下载的Jar就可以 字体调整字体,File -&gt; setting -&gt; editor -&gt;color scheme -&gt; color scheme font我调整的是DejaVu Sans Mono , Size :15 我所使用的快捷键 CTRL+D 复制当前行 CTRL+X 剪切当前行 CTRL+Y 删除当前行 SHIFT+ENTER 向下插入新行 CTRL+ENTER 向上插入新行 CTRL+W 快速选中代码 反向CTRL+SHIFT+W Ctrl+Alt+O 格式化import列表 Ctrl+Alt+L 格式化代码 Ctrl+F 搜索 F3 下一个 shift+F3 上一个]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>idea</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[scala自我书写]]></title>
    <url>%2F2019%2F02%2F15%2Fscala-start%2F</url>
    <content type="text"><![CDATA[Scala基础Scala变量首先,Scala有两种变量 变量: 其值可以改变, 关键词 var 常量: 其值不能改变, 关键词 val 123456789101112131415161718object HelloWorld &#123; def main(args: Array[String]): Unit =&#123; //4种声明变量的方式 //可变变量var 不可变变量val //声明变量类型 //val or var 变量名 : 变量类型 = 变量初始值 var myVar : String = &quot;myVar&quot;; val myVal : Int = 1; //不声明变量类型 类型推断 var myVar1 = 20; val myVal1 = &quot;sdfsd&quot;; //多个赋值 val myVal22, myVal33 = 100; val(myVal2: Int, myVal3: String) = Pair(40,&quot;myVal3&quot;); println(myVar); println(myVal);println(myVar1);println(myVal1); println(myVal2);println(myVal3); &#125;&#125; Scala访问修饰符类似Java, Scala修饰符有:private , public, protected, 默认未声明时为public, 同时Scala较Java更为严格 私有(private)成员用private关键字修饰，带有此标记的成员仅在包含了成员定义的类或对象内部可见，同样的规则还适用内部类。(Java允许外部类访问内部类的私有成员) 保护(Protected)成员只允许保护成员在定义了该成员的的类的子类中被访问。(Java同一packge都可以访问) 公共(Public)成员任何地方均可以访问 Scala运算符算术运算符同Java, 5类12345+ //加 +- //减 -* //乘 */ //除 /% //取余 % 关系运算符同Java, 6类123456== //等于!= //不等于&gt; //大于&lt; //小于&gt;= //大于等于&lt;= //小于等于 逻辑运算符同Java, 3类123&amp;&amp; //逻辑与|| //逻辑或! //逻辑非 位运算符位运算针对二进制进行操作,有7类1234567&amp; //按位与| //按位或^ //按位异或~ //按位取反&lt;&lt; //按位左移运算符&gt;&gt; //按位右移运算符&gt;&gt;&gt; //无符号右移 赋值运算符1234567891011= //简单赋值+= //相加后赋值-= //相减后赋值*= //相乘后赋值/= //相除后赋值%= //求余后赋值&lt;&lt;= //按位左移后再赋值&gt;&gt;= //按位右移后再赋值&amp;= //按位与后赋值^= //按位异或后赋值|= //按位或后赋值 Scala控制语句If1234if(布尔表达式)&#123; // 如果布尔表达式为 true 则执行该语句块&#125; If…Else12345if(布尔表达式)&#123; // 如果布尔表达式为 true 则执行该语句块&#125;else&#123; // 如果布尔表达式为 false 则执行该语句块&#125; if…else if…else123456789if(布尔表达式 1)&#123; // 如果布尔表达式 1 为 true 则执行该语句块&#125;else if(布尔表达式 2)&#123; // 如果布尔表达式 2 为 true 则执行该语句块&#125;else if(布尔表达式 3)&#123; // 如果布尔表达式 3 为 true 则执行该语句块&#125;else &#123; // 如果以上条件都为 false 执行该语句块&#125; While运行一系列语句，如果条件为true，会重复运行，直到条件变为false。1234while(condition)&#123; statement(s);&#125; do while条件表达式出现在循环的尾部，所以循环中的 statement(s) 会在条件被测试之前至少执行一次。123do &#123; statement(s);&#125; while( condition ); for123for( var x &lt;- Range )&#123; statement(s);&#125; range是个范围,左箭头←这个家伙是生成器（generator）,可以理解成后面的范围中生成单值. for也能用来进行多范围遍历,例如1234for( a &lt;- 1 to 3; b &lt;- 1 to 3)&#123; println( &quot;Value of a: &quot; + a ); println( &quot;Value of b: &quot; + b );&#125; 这样将遍历出所有情况,即所有可能性. until 与 toto为包含上限的闭区间，如：1 to 3,Range为1,2,3;until不包含上限，如：1 until 3, Range为1,2 for也能用来遍历集合123for( var x &lt;- List )&#123; statement(s);&#125; for的过滤,在for语句中加if条件1234567var a = 0;val numList = List(1,2,3,4,5,6,7,8,9,10);for( a &lt;- numList if a != 3; if a &lt; 8 )&#123; println( &quot;Value of a: &quot; + a );&#125; for的存储与返回12345678910var a = 0;val numList = List(1,2,3,4,5,6,7,8,9,10);// for loop execution with a yieldvar retVal = for&#123; a &lt;- numList if a != 3; if a &lt; 8 &#125;yield a //yield给a// Now print returned values using another loop.for( a &lt;- retVal)&#123; println( &quot;Value of a: &quot; + a );&#125; Scala数组定长数组变长数组Scala函数按名称调用函数命名参数的函数可变参数的函数递归函数默认参数值函数高阶函数嵌套函数匿名函数部分应用函数柯里化函数spark2-submit —driver-memory 5G —executor-memory 5G —conf spark.kryoserializer.buffer.max=2047m —jars SparkOnHBase-assembly-0.1-SNAPSHOT-deps.jar —master yarn —class “SparkOnHBase” sparkonhbase_2.11-0.1-SNAPSHOT.jar yarn application -list 查询所有的任务；然后使用yarn application -kill yarn application -kill application_1512629122215_0235]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>scala</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mongo自我书写]]></title>
    <url>%2F2019%2F02%2F15%2Fmongo-start%2F</url>
    <content type="text"><![CDATA[MongoDB简介MongoDB 是由C++语言编写的，是一个基于分布式文件存储的开源数据库系统。在高负载的情况下，添加更多的节点，可以保证服务器性能。MongoDB 旨在为WEB应用提供可扩展的高性能数据存储解决方案。MongoDB 将数据存储为一个文档，数据结构由键值(key=&gt;value)对组成。MongoDB 文档类似于 JSON 对象。字段值可以包含其他文档，数组及文档数组。 MongoDB概念与关系型数据库的区别在于 表 -&gt; 集合 行 -&gt; 文档 列 -&gt; 域同时不支持连接查询 SQL术语/概念 | MongoDB术语/概念 | 解释/说明database | database | 数据库table | collection | 数据库表/集合row | document | 数据记录行/文档column | field | 数据字段/域index | index | 索引table joins | 表连接,MongoDB不支持primary key | primary key | 主键,MongoDB自动将_id字段设置为主键 MongoDB增删改查MongoDB插入文档MongoDB 使用 insert() 或 save() 方法向集合中插入文档，语法如下： db.COLLECTION_NAME.insert(document) MongoDB更新文档update() 方法用于更新已存在的文档。语法格式如下：123456789db.collection.update( &lt;query&gt;, &lt;update&gt;, &#123; upsert: &lt;boolean&gt;, multi: &lt;boolean&gt;, writeConcern: &lt;document&gt; &#125;) 参数说明：query : update的查询条件，类似sql update查询内where后面的。 update : update的对象和一些更新的操作符（如$,$inc…）等，也可以理解为sql update查询内set后面的 upsert : 可选，这个参数的意思是，如果不存在update的记录，是否插入objNew,true为插入，默认是false，不插入。 multi : 可选，mongodb 默认是false,只更新找到的第一条记录，如果这个参数为true,就把按条件查出来多条记录全部更新。 writeConcern :可选，抛出异常的级别。 MongoDB 删除文档remove() 方法的基本语法格式如下所示：123456789101112db.collection.remove( &lt;query&gt;, &lt;justOne&gt;)如果你的 MongoDB 是 2.6 版本以后的，语法格式如下：db.collection.remove( &lt;query&gt;, &#123; justOne: &lt;boolean&gt;, writeConcern: &lt;document&gt; &#125;) 参数说明：query :（可选）删除的文档的条件。justOne : （可选）如果设为 true 或 1，则只删除一个文档。 writeConcern :（可选）抛出异常的级别。 MongoDB查询文档MongoDB 查询数据的语法格式如下： db.collection.find(query, projection)query ：可选，使用查询操作符指定查询条件projection ：可选，使用投影操作符指定返回的键。查询时返回文档中所有键值， 只需省略该参数即可（默认省略）。如果你需要以易读的方式来读取数据，可以使用 pretty() 方法，语法格式如下： db.col.find().pretty()pretty() 方法以格式化的方式来显示所有文档。 MongoDB操作符MongoDB中条件操作符有：12345678910111213$gt -------- greater than &gt;$gte --------- gt equal &gt;=$lt -------- less than &lt;$lte --------- lt equal &lt;=$ne ----------- not equal !=$eq -------- equal =$type $type操作符是基于BSON类型来检索集合中匹配的数据类型，并返回结果。MongoDB 中可以使用的类型如下表所示：1234567891011121314151617181920类型 数字 备注Double 1 String 2 Object 3 Array 4 Binary data 5 Undefined 6 已废弃。Object id 7 Boolean 8 Date 9 Null 10 Regular Expression 11 JavaScript 13 Symbol 14 JavaScript (with scope) 15 32-bit integer 16 Timestamp 17 64-bit integer 18 Min key 255 Query with -1.Max key 127 MongoDB基本方法MongoDB Limit() 方法如果你需要在MongoDB中读取指定数量的数据记录，可以使用MongoDB的Limit方法，limit()方法接受一个数字参数，该参数指定从MongoDB中读取的记录条数。语法limit()方法基本语法如下所示： db.COLLECTION_NAME.find().limit(NUMBER) MongoDB Skip() 方法我们除了可以使用limit()方法来读取指定数量的数据外，还可以使用skip()方法来跳过指定数量的数据，skip方法同样接受一个数字参数作为跳过的记录条数。语法skip() 方法脚本语法格式如下： db.COLLECTION_NAME.find().limit(NUMBER).skip(NUMBER)想要读取从 10 条记录后 100 条记录，相当于 sql 中limit (10,100)。 db.COLLECTION_NAME.find().skip(10).limit(100) MongoDB sort()方法在MongoDB中使用使用sort()方法对数据进行排序，sort()方法可以通过参数指定排序的字段，并使用 1 和 -1 来指定排序的方式，其中 1 为升序排列，而-1是用于降序排列。语法sort()方法基本语法如下所示： db.COLLECTION_NAME.find().sort({KEY:1}) ensureIndex() 方法MongoDB使用 ensureIndex() 方法来创建索引。语法ensureIndex()方法基本语法格式如下所示： db.COLLECTION_NAME.ensureIndex({KEY:1})语法中 Key 值为你要创建的索引字段，1为指定按升序创建索引，如果你想按降序来创建索引指定为-1即可。 aggregate() 方法MongoDB中聚合的方法使用aggregate()。语法aggregate() 方法的基本语法格式如下所示： &gt;db.COLLECTION_NAME.aggregate(AGGREGATE_OPERATION)表达式 | 描述 | 实例$sum | 计算总和。 | db.mycol.aggregate([{$group : {_id : “$by_user”, num_tutorial : {$sum : “$likes”}}}])$avg | 计算平均值 | db.mycol.aggregate([{$group : {_id : “$by_user”, num_tutorial : {$avg : “$likes”}}}])$min | 获取集合中所有文档对应值得最小值。 | db.mycol.aggregate([{$group : {_id : “$by_user”, num_tutorial : {$min : “$likes”}}}])$max | 获取集合中所有文档对应值得最大值。 | db.mycol.aggregate([{$group : {_id : “$by_user”, num_tutorial : {$max : “$likes”}}}])$push | 在结果文档中插入值到一个数组中。 | db.mycol.aggregate([{$group : {_id : “$by_user”, url : {$push: “$url”}}}])$addToSet | 在结果文档中插入值到一个数组中，但不创建副本。 | db.mycol.aggregate([{$group : {_id : “$by_user”, url : {$addToSet : “$url”}}}])$first | 根据资源文档的排序获取第一个文档数据。 | db.mycol.aggregate([{$group : {_id : “$by_user”, first_url : {$first : “$url”}}}]) $last | 根据资源文档的排序获取最后一个文档数据 | db.mycol.aggregate([{$group : {_id : “$by_user”, last_url : {$last : “$url”}}}])1db.getCollection(&apos;testCollection&apos;).aggregate([&#123;$group : &#123;label : &quot;$label&quot;, num_tutorial : &#123;$sum : 1&#125;&#125;&#125;]) 对label聚合,查询各个label条数 mongo导入CSV文件mongoimport -h 172.20.3.10:27017 —db fourClassify —collection allTrainCollection —type csv —headerline —file D:/all_train_data.csv mongo导出CSV文件mongoexport -h 172.20.3.10:27017 —db fourClassify —collection testCollection —type=csv —fieldFile D:/fieldFile.txt —out D:/1.csv]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>mongo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[查找算法-JAVA版本]]></title>
    <url>%2F2017%2F09%2F11%2Fsearch%2F</url>
    <content type="text"><![CDATA[这篇文章占坑，要梳理一下查找算法。 123456789101112131415161718192021222324252627282930313233343536373839package Offer;import java.util.Arrays;public class search &#123; public static void main(String[] args) &#123; int[] numbers = &#123; 10, 50, 20, 30, 100, 900, 400, 400 &#125;; System.out.println(SequelSearch(numbers, 100)); System.out.println(BinarySearch(numbers, 100)); &#125; // 顺序查找 public static int SequelSearch(int[] numbers, int a) &#123; for (int i = 0; i &lt; numbers.length; i++) &#123; if (numbers[i] == a) &#123; return i; &#125; &#125; return -1; &#125; // 二分查找 // 针对已排序从小到大. public static int BinarySearch(int[] numbers, int a) &#123; int low = 0, high = numbers.length - 1; while (low &lt;= high) &#123; int mid = (low + high) / 2; if (numbers[mid] &lt; a) &#123; low = mid + 1; &#125; else if (numbers[mid] &gt; a) &#123; high = mid - 1; &#125; else return mid; &#125; return -1; &#125;&#125;]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>search</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[排序算法-JAVA版本]]></title>
    <url>%2F2017%2F08%2F21%2Fsort%2F</url>
    <content type="text"><![CDATA[这篇文章占坑，要梳理一下排序算法。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161package Offer;import java.util.Arrays;public class Sorting &#123; public static void main(String[] args) &#123; int[] numbers = &#123;10, 50, 20, 30, 100, 900, 400, 400&#125;; System.out.println(&quot;冒泡排序:&quot; + Arrays.toString(bubbleSort(numbers))); System.out.println(&quot;选择排序:&quot; + Arrays.toString(selectSort(numbers))); System.out.println(&quot;插入排序:&quot; + Arrays.toString(insertSort(numbers))); System.out.println(&quot;希尔排序:&quot; + Arrays.toString(shellSort(numbers))); System.out.println(&quot;归并排序:&quot; + Arrays.toString(mergeSort(numbers,0,numbers.length-1))); System.out.println(&quot;快速排序:&quot; + Arrays.toString(quickSort(numbers,0,numbers.length-1))); &#125; // 冒泡排序 // 遍历比较全体元素,如果相邻两个元素顺序不一致,则交换. public static int[] bubbleSort(int[] numbers) &#123; int temp = 0; int size = numbers.length; for (int i = 0; i &lt; size - 1; i++) &#123; for (int j = 0; j &lt; size - 1 - i; j++) &#123; if (numbers[j] &gt; numbers[j + 1]) // 交换两数位置 &#123; temp = numbers[j]; numbers[j] = numbers[j + 1]; numbers[j + 1] = temp; &#125; &#125; &#125; return numbers; &#125; //选择排序 //寻找未排序最小元素与自身交换位置 public static int[] selectSort(int[] numbers) &#123; int temp = 0; int size = numbers.length; for(int i = 0; i &lt; size ; i++) &#123; int k = i ; // 选取最小元素 for(int j = i + 1; j &lt; size ; j++)&#123; if (numbers[j] &lt; numbers[k]) &#123; k = j; &#125; &#125; // 交换位置z，自身最小无须交换 if(i != k) &#123; temp = numbers[i]; numbers[i] = numbers[k]; numbers[k] = temp; &#125; &#125; return numbers; &#125; //插入排序 //将未排序元素向前扫描，插入在小于后面且大于前面的位置 public static int[] insertSort(int[] numbers) &#123; int temp = 0; int size = numbers.length; int j = 0; for(int i = 0; i &lt; size ; i++) &#123; temp = numbers[i]; //后移较大元素 for(j = i; j &gt; 0 &amp;&amp; temp &lt; numbers[j-1]; j--) &#123; numbers[j] = numbers[j-1]; &#125; numbers[j] = temp; &#125; return numbers; &#125; //希尔排序 插入排序的变形 public static int[] shellSort(int[] arr)&#123; int gap = 1, i, j, len = arr.length; int temp; while (gap &lt; len / 3) gap = gap * 3 + 1; // &lt;O(n^(3/2)) by Knuth,1973&gt;: 1, 4, 13, 40, 121, ... for (; gap &gt; 0; gap /= 3) &#123; for (i = gap; i &lt; len; i++) &#123; temp = arr[i]; for (j = i - gap; j &gt;= 0 &amp;&amp; arr[j] &gt; temp; j -= gap) arr[j + gap] = arr[j]; arr[j + gap] = temp; &#125; &#125; return arr; &#125; //归并排序 public static int[] mergeSort(int[] nums, int low, int high) &#123; int mid = (low + high) / 2; if (low &lt; high) &#123; // 左边 mergeSort(nums, low, mid); // 右边 mergeSort(nums, mid + 1, high); // 左右归并 merge(nums, low, mid, high); &#125; return nums; &#125; public static void merge(int[] nums, int low, int mid, int high) &#123; int[] temp = new int[high - low + 1]; int i = low;// 左指针 int j = mid + 1;// 右指针 int k = 0; // 把较小的数先移到新数组中 while (i &lt;= mid &amp;&amp; j &lt;= high) &#123; if (nums[i] &lt; nums[j]) &#123; temp[k++] = nums[i++]; &#125; else &#123; temp[k++] = nums[j++]; &#125; &#125; // 把左边剩余的数移入数组 while (i &lt;= mid) &#123; temp[k++] = nums[i++]; &#125; // 把右边边剩余的数移入数组 while (j &lt;= high) &#123; temp[k++] = nums[j++]; &#125; // 把新数组中的数覆盖nums数组 for (int k2 = 0; k2 &lt; temp.length; k2++) &#123; nums[k2 + low] = temp[k2]; &#125; &#125; //快速排序 private static int getMiddle(int[] list, int low, int high) &#123; int tmp = list[low]; //数组的第一个作为中轴 while (low &lt; high) &#123; while (low &lt; high &amp;&amp; list[high] &gt;= tmp) &#123; high--; &#125; list[low] = list[high]; //比中轴小的记录移到低端 while (low &lt; high &amp;&amp; list[low] &lt;= tmp) &#123; low++; &#125; list[high] = list[low]; //比中轴大的记录移到高端 &#125; list[low] = tmp; //中轴记录到尾 return low; //返回中轴的位置 &#125; private static int[] quickSort(int[] list, int low, int high) &#123; if (low &lt; high) &#123; int middle = getMiddle(list, low, high); //将list数组进行一分为二 quickSort(list, low, middle - 1); //对低字表进行递归排序 quickSort(list, middle + 1, high); //对高字表进行递归排序 &#125; return list; &#125; &#125;]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[http 状态码]]></title>
    <url>%2F2017%2F08%2F20%2Fhttp-status-code%2F</url>
    <content type="text"><![CDATA[HTTP状态码（HTTP Status Code）,是指当访问一个网页时，浏览器向服务器发出请求后，显示网页前，网页所在服务器会返回一个包含HTTP状态码的信息头，来响应浏览器的请求。 下面表格，清楚的分类了状态码： HTTP状态码分类 状态码 含义 备注 1** 信息，收到请求 2** 成功，操作被成功接收并处理 3** 重定向，需进一步操作 4** 客户端错误，语法错误或无法完成请求 5** 服务端错误，服务器处理过程发生错误 常见状态码： 状态码 含义 备注 200 OK 请求成功 301 Move Permanently 资源已被永久转移到其他URL 304 Not Modified 所请求资源未修改 305 Use Proxy 使用代理，所请求资源必须通过代理访问 400 BadRequest 客户端语法错误 401 unauthorized 身份认证 403 Forbidden 服务端拒绝 404 NotFound 未找到 500 Internal Server Error 服务器内部错误]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux基础笔记]]></title>
    <url>%2F2017%2F08%2F18%2Flinux%2F</url>
    <content type="text"><![CDATA[这篇文章为需要的人准备着，后期会不断添加内容。权当手册使用。 维基定义Linux（/ˈlɪnəks/ lin-əks）是一种自由和开放源代码的类UNIX操作系统。目前运用最广泛，使用人数最多的操作系统。 Linux 发行版分类Linux的发行版本可以大体分为两类，一类是商业公司维护的发行版本，一类是社区组织维护的发行版本，前者以著名的Redhat（RHEL）为代表，后者以Debian为代表。 Redhat 系列 RHEL(Redhat Enterprise Linux，也就是所谓的Redhat Advance Server收费版本) FedoraCore(由原来的Redhat桌面版本发展而来，免费版本) CentOS(RHEL的社区克隆版本，免费)。Debian 系列 Debian Ubuntu Linux 系统常用目录的含义123456789101112131415161718/bin：bin是Binary的缩写, 这个目录存放着最经常使用的命令。/boot：这里存放的是启动Linux时使用的一些核心文件，包括一些连接文件以及镜像文件。/dev ：dev是Device(设备)的缩写, 该目录下存放的是Linux的外部设备，在Linux中访问设备的方式和访问文件的方式是相同的。/etc：这个目录用来存放所有的系统管理所需要的配置文件和子目录。/home：用户的主目录，在Linux中，每个用户都有一个自己的目录，一般该目录名是以用户的账号命名的。/lib：这个目录里存放着系统最基本的动态连接共享库，其作用类似于Windows里的DLL文件。几乎所有的应用程序都需要用到这些共享库。/lost+found：这个目录一般情况下是空的，当系统非法关机后，这里就存放了一些文件。/media：linux系统会自动识别一些设备，例如U盘、光驱等等，当识别后，linux会把识别的设备挂载到这个目录下。/mnt：系统提供该目录是为了让用户临时挂载别的文件系统的，我们可以将光驱挂载在/mnt/上，然后进入该目录就可以查看光驱里的内容了。/opt： 这是给主机额外安装软件所摆放的目录。比如你安装一个ORACLE数据库则就可以放到这个目录下。默认是空的。/root：该目录为系统管理员，也称作超级权限者的用户主目录。/sbin：s就是Super User的意思，这里存放的是系统管理员使用的系统管理程序。/tmp：这个目录是用来存放一些临时文件的。/usr： 这是一个非常重要的目录，用户的很多应用程序和文件都放在这个目录下，类似与windows下的program files目录。/usr/bin：系统用户使用的应用程序。/usr/sbin：超级用户使用的比较高级的管理程序和系统守护程序。/usr/src：内核源代码默认的放置目录。/var：这个目录中存放着在不断扩充着的东西，我们习惯将那些经常被修改的目录放在这个目录下。包括各种日志文件。 Linux 文件属性及权限每个文件的属性都是由10个字符来确定。0：文件类型 当为[ d ]则是目录 当为[ - ]则是文件； 若是[ l ]则表示为链接文档(link file)； 若是[ b ]则表示为装置文件里面的可供储存的接口设备(可随机存取装置)； 若是[ c ]则表示为装置文件里面的串行端口设备，例如键盘、鼠标(一次性读取装置)。1-3：文件所有者权限4-6：所有者同组权限7-9：其他用户权限其中不同用户的权限有3个字母构成：[ r ]代表可读(read)、[ w ]代表可写(write)、[ x ]代表可执行(execute)。 要注意的是，这三个权限的位置不会改变，如果没有权限，就会出现减号[ - ]而已。 Linux 常用命令man: 帮助 目录相关命令1234567ls: 列出目录cd：切换目录pwd：显示目前的目录mkdir：创建一个新的目录rmdir：删除一个空的目录cp: 复制文件或目录rm: 移除文件或目录 文件处理相关1234567cat 由第一行开始显示文件内容tac 从最后一行开始显示，可以看出 tac 是 cat 的倒著写！nl 显示的时候，顺道输出行号！more 一页一页的显示文件内容less 与 more 类似，但是比 more 更好的是，他可以往前翻页！head 只看头几行tail 只看尾巴几行 硬件配置相关12345fdisk -l 查看硬盘及分区情况df 查看分区空间使用情况free 查看内存信息cat /proc/meminfo 内存信息more /proc/cpuinfo 查询CPU基本信息 网络配置相关12345ifconfig 查看已启用的网络接口信息netstat 显示网络状态top 实时监控CPU、内存、进程等使用情况ps 查看所有进程kill 关闭进程 参考- Linux命令查询]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[回归 Despacito]]></title>
    <url>%2F2017%2F08%2F17%2Freback%2F</url>
    <content type="text"><![CDATA[DespacitoCome on over in my direction快点与我同行吧So thankful for that, it’s such a blessin’, yeah你能来到我的身边，那是上天的眷顾Turn every situation into Heaven, yeah你将一切厄运化为乌有Oh, you are哦，你是My sunrise on the darkest day我在黑暗黎明里的一丝曙光Got me feelin’ some kind of way你总会让我产生一种美好的感觉Make me wanna savor every moment slowly, slowly让我想细细咀嚼生命中的每分每秒You fit me, tailor-made love, how you put it on你就像是我量身定做的灰姑娘，没人知道怎么为你穿上玻璃鞋Got the only key, know how to turn it on而我是唯一知道如何做的王子The way you nibble on my ear, the only words I wanna hear你在我耳边的轻轻细语，那是我的天籁之音Baby take it slow so we can last long宝贝，所有的爱情都需要温存，只有这样它才会长久Oh, tú, tú eres el imn y yo soy el metal你 你是磁石而我是金属Me voy acercando y voy armando el plan我一步步接近 盘算着如何出招Sólo con pensarlo se acelera el pulso光是想想 我的脉搏就狂跳Oh, yeah哦，是的Ya, ya me está gustando más de lo normal现在 现在这感觉非比寻常Todos mis sentidos van pidiendo más我的所有感官都饥渴万分Esto hay que tomarlo sin ningún apuro但这事儿着急不得Despacito慢慢地来Quiero respirar tu cuello despacito想要在你脖颈间慢慢地喘息Deja que te diga cosas al oído在你的耳边说尽甜言蜜语好Para que te acuerdes si no estás conmigo让你在以后都能想起此时此刻Despacito慢慢地来Quiero desnudarte a besos despacito想要用吻慢慢褪去你的衣衫Firmo en las paredes de tu laberinto在你迷宫的墙上留下我的名字Y hacer de tu cuerpo todo un manuscrito把你的身体变成我的手稿(Sube, sube, sube, sube, sube)亲爱的，亲爱的，亲爱的，亲爱的，亲爱的Quiero ver bailar tu pelo想要看你发丝飞扬Quiero ser tu ritmo想要成为你舞动的旋律Que le enseñes a mi boca想要你告诉我的嘴唇Tus lugares favoritos何处是你想要亲吻的地方(Favorito, favorito, baby)（最想要的 宝贝）Déjame sobrepasar tus zonas de peligro让我越过你的危险地带Hasta provocar tus gritos直到令你尖叫Y que olvides tu apellido直到你忘记了自己的名字Si te pido un beso, ven, dámelo若我向你索吻 那你就来轻吻我吧Yo sé que estás pensándolo我知道你想这么做Llevo tiempo intentándolo我已经为你努力了那么久宝贝Mami, esto es dando y dándolo你就给我吧 给我一个你的吻Sabes que tu corazón conmigo te hace bang-bang知道你与我在一起时 你的心跳 砰砰Sabes que esa beba está buscando de mi bang-bang你知道你所需按照的那种 我能给的 砰砰Ven, prueba de mi boca para ver cómo te sabe来尝尝我的唇是什么味道Quiero, quiero, quiero ver cuánto amor a ti te cabe我想要 想要看看你能承受多深的爱Yo no tengo prisa, yo me quiero dar el viaje我不着急 我喜欢游玩的感觉Empecemos lento, después salvaje开始时风平浪静 之后则电闪雷鸣Pasito a pasito, suave suavecito一点一点 温柔再温柔Nos vamos pegando, poquito a poquito我们越贴越近 一点一点Cuando tú me besas con esa destreza你亲吻的时候是如此娴熟Veo que eres malicia con delicadeza我才发现你是一个娇媚的小坏蛋Pasito a pasito, suave suavecito一点一点 温柔再温柔Nos vamos pegando, poquito a poquito我们越贴越近 一点一点Y es que esa belleza es un rompecabezas你的美 如同打乱的拼图一样 令人着迷Pero pa’ montarlo aquí tengo la pieza但我会拼好的 因为缺失的那一块在我的手中¡Oye!嘿！Despacito慢慢地来Quiero respirar tu cuello despacito想要在你脖颈间慢慢地喘息Deja que te diga cosas al oído在你的耳边说尽甜言蜜语Para que te acuerdes si no estás conmigo好让你在以后都能想起此时此刻Despacito慢慢地来Quiero desnudarte a besos despacito想要用吻慢慢褪去你的衣衫Firmo en las paredes de tu laberinto在你迷宫的墙上留下我的名字Y hacer de tu cuerpo todo un manuscrito把你的身体变成我的手稿(Sube, sube, sube, sube, sube)亲爱的，亲爱的，亲爱的，亲爱的，亲爱的Quiero ver bailar tu pelo想要看你发丝飞扬Quiero ser tu ritmo想要成为你舞动的旋律Que le enseñes a mi boca想要你告诉我的嘴唇Tus lugares favoritos何处是你想要亲吻的地方(Favorito, favorito, baby)（最想要的 宝贝Déjame sobrepasar tus zonas de peligro让我越过你的危险地带Hasta provocar tus gritos直到令你尖叫Y que olvides tu apellido知道你忘记了自己的名字Despacito慢慢地来This is how we do it down in Puerto Rico这就是波多黎各的做法I just wanna hear you screaming, “¡Ay, Bendito!”我只想听到你尖叫，“嗨，本迪托！”I can move foreverm se quede contigo我可以永远移动¡Bailalo!bailalo！（加利西亚语）Pasito a pasito, suave suavecito一点一点 温柔再温柔Nos vamos pegando, poquito a poquito我们越贴越近 一点一点Que le enseñes a mi boca告诉他们 我的嘴Tus lugares favoritos是你最喜欢的地方(Favorito, favorito, baby)（最想要的 宝贝）Pasito a pasito, suave suavecito一点一点 温柔再温柔Nos vamos pegando, poquito a poquito我们越贴越近 一点一点Hasta provocar tus gritos (Fonsi)直到令你尖叫(Fonsi)Y que olvides tu apellido (D.Y.)直到你忘记了自己的名字（D.Y.）Despacito慢慢地来]]></content>
      <categories>
        <category>心情随笔</category>
      </categories>
      <tags>
        <tag>心情</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu开启root账户登录后的两条笔记]]></title>
    <url>%2F2016%2F08%2F13%2Froot-ubuntu%2F</url>
    <content type="text"><![CDATA[做Hadoop集群时,以root账户登录获取到最高权限.可以避免很多不必要的麻烦.但有两点需要略作修改的bug之处.笔者Ubuntu 14.04 LTS ROOT账户登录时界面报错登录系统时出现12Error found when loading /root/.profilestdin: is not a tty 此时需要更改1/root/.profile 编辑并修改一样代码如下:12gedit /root/.profile # 打开tty -s &amp;&amp; mesg n # 修改mesg n 的所在行代码 然后重启系统即可. ROOT账户启动Chromium浏览器报错以ROOT用户启动Chromium时,会报错不能以根用户身份运行google chrome 浏览器此时,我最初的解决办法就是以隐身方式打开浏览器.后来找到下面的解决办法,将chromium用户数据文件夹.进入下面路径1/usr/share/applications/ 在chromium快捷图标上右键，点击属性，在命令属性后添加1-user-data-dir 即可.]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu下Matplotlib的安装与SDN仿真]]></title>
    <url>%2F2016%2F08%2F10%2Fmatplotlib-ubuntu%2F</url>
    <content type="text"><![CDATA[帮同学做SDN(Software Defined Network)软件定义网络方向的代码仿真,环境的安装与调试如下. 安装pip支持下载get-pip 安装包1wget https://bootstrap.pypa.io/get-pip.py --no-check-certificate 安装pip 支持1sudo python get-pip.py 安装Matplotlib库 安装scipy组件 1sudo apt-get install python-scipy 安装numpy组件 1sudo apt-get install python-numpy 安装 matplotlib 1sudo apt-get install python-matplotlib 利用pip安装neworkx1sudo pip install networkx 安装R语言1sudo apt-get install r-base 运行程序1./DO_EVERYTHING.sh 代码报错,并未看到PLOT…郁闷… 代码地址sdnctrlsim-Github 后续报错问题最终解决.生成的PLOT,路径没找对.]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Matplotlib SDN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spark集群搭建教程 in Ubuntu 14.04]]></title>
    <url>%2F2016%2F07%2F18%2Fspark-cookbook%2F</url>
    <content type="text"><![CDATA[基本环境总览-及下载链接VMware 12.1.1Ubuntu 14.04JAVA 1.8.0Hadoop 2.7.2Spark 1.6.2SCALA 2.10.6ideaIC-2016.2scala-intellij-bin-2016.2.1文末有网盘提供本文环境下载 VMtools安装 VMware菜单-虚拟机-安装VMtools 解压tar.gz teminal中执行./vmware-install.pl 重启虚拟机系统 Hadoop 2.7.2 in Ubuntu 14.04 LTS 配置开始Ubuntu开启root账户登录 vim 安装 可以用gedit代替 1sudo apt-get install vim Ubuntu14.04桌面环境目录 1sudo gedit /usr/share/lightdm/lightdm.conf.d/50-unity-greeter.conf 桌面环境设置如下 开启root账户 1234567[SeatDefaults]greeter-session=unity-greeteruser-session=ubuntugreeter-show-manual-login=trueallow-guest=false- 启用root账号sudo passwd root SSH实现无密码登录 ssh通讯安装 1sudo apt-get install ssh ssh启动 1/etc/init.d/ssh start ssh状态 1ps -e |grep ssh 生成公钥 私钥 1ssh-keygen -t rsa -P &quot;&quot; 公钥添加授权 1cat ~/.ssh/id_rsa.pub &gt;&gt; ~/.ssh/authorized_keys 登入 1ssh localhost 登出 1exit 更改hosts 与hostname 查看IP 1ifconfig 编辑hostname 123vim /etc/hostname # 用gedit也可i #更改为主机名SparkMaster SparkWorker1 SparkWorker2shift+zz 保存退出 更改hosts 123vim /etc/hostsi #更改IP及对应主机名字shift+zz 保存退出 公钥添加至授权 123456scp传输 方法失效，通过拷贝即可cd /root/.ssh/将slave的密钥传到Master上scp id_rsa.pub root@SparkMaster:/root/.ssh/id_rsa.pub.SparkWorker1 scp id_rsa.pub root@SparkMaster:/root/.ssh/id_rsa.pub.SparkWorker2cat ~/.ssh/id_rsa.pub.SparkWorker1 &gt;&gt; ~/.ssh/authorized_keys cat ~/.ssh/id_rsa.pub.SparkWorker2 &gt;&gt; ~/.ssh/authorized_keys 这样我们的authorized_keys就有了三台主机的密钥,将authorized_keys分别复制到另外两台电脑对应目录下 Java环境安装1.8.0 下载安装Java 123mkdir /usr/lib/javamv /root/.... /usr/lib/javatar -xvf jdk-.... 修改JAVA环境配置使生效1.8.0 1234567gedit ~/.bashrcexport JAVA_HOME=/usr/lib/java/jdk1.8.0_91export JRE_HOME=$&#123;JAVA_HOME&#125;/jreexport CLASS_PATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/libexport PATH=$&#123;JAVA_HOME&#125;/bin:$PATH- 使bashrc生效source ~/.bashrc Hadoop环境安装2.7.2 下载安装Hadoop 12mkdir /usr/lib/hadooptar -xvf hadoop-.... 修改Hadoop环境配置使生效2.7.2 1234567gedit ~/.bashrcexport JAVA_HOME=/usr/lib/java/jdk1.8.0_91export JRE_HOME=$&#123;JAVA_HOME&#125;/jreexport CLASS_PATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/libexport PATH=$&#123;JAVA_HOME&#125;/bin:/usr/lib/hadoop/hadoop-2.7.2/bin:$PATH - 使bashrc生效source ~/.bashrc hadoop 版本hadoop version 更改hadoop三个文件的java环境 1234567cd /usr/lib/hadoop/hadoop-2.7.2/etc/hadoopgedit hadoop-env.sh # 修改如下export JAVA_HOME=/usr/lib/java/jdk1.8.0_91 gedit yarn-env.sh # 修改如下export JAVA_HOME=/usr/lib/java/jdk1.8.0_91gedit mapred-env.sh # 修改如下export JAVA_HOME=/usr/lib/java/jdk1.8.0_91 更改slaves 为2个子节 1gedit slaves #SparkWorker1 Sparkworker2 更改三个xml文件 1cd /usr/lib/hadoop/hadoop-2.7.2/etc/hadoop 更改site.xml文件 123456789101112&lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://SparkMaster:9000/&lt;/value&gt; &lt;description&gt;The name of default file system&lt;/description&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/usr/lib/hadoop/hadoop-2.7.2/tmp&lt;/value&gt; &lt;description&gt;A base for other temporary directories&lt;/description&gt; &lt;/property&gt; &lt;/configuration&gt; 更改dfs.xml文件 1234567891011121314&lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;2&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;/usr/lib/hadoop/hadoop-2.7.2/dfs/name&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.datanode.name.dir&lt;/name&gt; &lt;value&gt;/usr/lib/hadoop/hadoop-2.7.2/dfs/data&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 更改mapred.xml文件 123456&lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 更改yarn.xml文件 12345678910&lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;SparkMaster&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; scp 传输环境到节点机器 1234scp -r hadoop/ root@SparkWorker1:/usr/lib/scp -r java/ root@SparkWorker1:/usr/lib/scp -r hadoop/ root@SparkWorker2:/usr/lib/scp -r java/ root@SparkWorker2:/usr/lib/ 编辑bashrc 1234567gedit ~/.bashrcexport JAVA_HOME=/usr/lib/java/jdk1.8.0_91export JRE_HOME=$&#123;JAVA_HOME&#125;/jreexport CLASS_PATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/libexport PATH=$&#123;JAVA_HOME&#125;/bin:/usr/lib/hadoop/hadoop-2.7.2/bin:$PATH - 使bashrc生效source ~/.bashrc 格式化hdfs系统 12cd /usr/lib/hadoop/hadoop-2.7.2/sbinhadoop namenode -format 启动hdfs系统 12./start-dfs.sh htttp://SparkMaster:50070 # HDFS集群 启动yarn集群 1234./start-yarn.shhttp://SparkMaster:8088 #ResourceManager状态http://SparkWorker1:8042 #NodeManager状态http://SparkWorker1:8042 #NodeManager状态 历史服务 123./mr-jobhistory-daemon.sh start historyserver #历史服务http://SparkMaster:19888 #ResourceManager状态./mr-jobhistory-daemon.sh stop historyserver #停止 slave无法启动nodemanager可以删除data文件夹 12usr/lib/hadoop/tmp/dfs/ -lsrm -r /data/ Hadoop实例测试 建立输入输出文件夹 12hadoop fs -mkdir -p /data/wordcounthadoop fs -mkdir -p /output/ 复制所需文件到输入文件夹 1hadoop fs -put ../etc/haddop/#.xml /data/wordcount/ 执行wordcount 的mapreduce命令 1hadoop jar ../share/hadoop//mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount /data/wordcount/hadoop /output/wordcount2 可以查看个文件夹及文件 1http://sparkmaster:50070/explorer.html#/ hadoop 配置完毕 运行实例成功 Spark 1.6.2 SCALA 2.10.6 配置开始 SPARK SCALA环境配置 Spark环境安装1.6.2 12mkdir /usr/lib/sparktar -xvf spark-.... Scala环境安装2.10.6 12mkdir /usr/lib/scalatar -xvf scala-.... Spark Scala配置 12345678910111213141516gedit ~/.bashrc# SCALA 配置export JAVA_HOME=/usr/lib/java/jdk1.8.0_91export JRE_HOME=$&#123;JAVA_HOME&#125;/jreexport SCALA_HOME=/usr/lib/scala/scala-2.10.6export CLASS_PATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/libexport PATH=$&#123;SCALA_HOME&#125;/bin:$&#123;JAVA_HOME&#125;/bin:/usr/lib/hadoop/hadoop-2.7.2/bin:$PATH# SPARK 配置export JAVA_HOME=/usr/lib/java/jdk1.8.0_91export JRE_HOME=$&#123;JAVA_HOME&#125;/jreexport SCALA_HOME=/usr/lib/scala/scala-2.10.6export SPARK_HOME=/usr/lib/spark/spark-1.6.2-bin-hadoop2.6export CLASS_PATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/libexport PATH=$&#123;SPARK_HOME&#125;/lib:$&#123;SCALA_HOME&#125;/bin:$&#123;JAVA_HOME&#125;/bin:/usr/lib/hadoop/hadoop-2.7.2/bin:$PATH- 使bashrc生效source ~/.bashrc Spark-env.sh slave 配置 1234cp spark-env.sh.template spark-env.shcp slave.template slavegedit spark-env.shgedit slave 追加spark-env.sh信息 12345export JAVA_HOME=/usr/lib/java/jdk1.8.0_91export SCALA_HOME=/usr/lib/scala/scala-2.10.6export SPARK_MASTER_IP=192.168.204.130export SPARK_WORKER_MEMORY=2gexport HADOOP_CONF_DIR=/usr/lib/hadoop/hadoop-2.7.2/conf 修改slave 123SparkMasterSparkWorker1SparkWorker2 传输 SCALA 和 SPARK 1234scp -r /usr/lib/spark/ root@SparkWorker1:/usr/lib/scp -r /usr/lib/spark/ root@SparkWorker2:/usr/lib/scp -r /usr/lib/scala/ root@SparkWorker1:/usr/lib/scp -r /usr/lib/scala/ root@SparkWorker2:/usr/lib/ 启动spark 12cd /usr/lib/spark/spark-1.6.2-bin-hadoop2.6/sbin# ./start-all.sh 观察Spark 1http://sparkmaster:8080/ 启动spark-shell 12cd /usr/lib/spark/spark-1.6.2-bin-hadoop2.6/bin# ./spark-shell 观察Spark-shell 1http://sparkmaster:4040/ SPARK测试 切换目录 1cd /usr/lib/spark/spark-1.6.2-bin-hadoop2.6 将README.md 上传至data 1hadoop fs -put README.md /data/ 启动Spark shell 时间要用12 Min 1MASTER=spark://SparkMaster:7077 ./spark-shell 读取README.md 做如下处理 123val file = sc.textFile(&quot;hdfs://SparkMaster:9000/data/README.md&quot;)val count = file.flatMap(line =&gt; line.split(&quot; &quot;)).map(word =&gt; (word, 1)).reduceByKey(_+_)count collect SPARK SCALA 配置完毕 运行实例成功 IDEA 安装测试 创建文件夹 1mkdir /usr/local/idea 拷贝至文件夹 1cp /root/ideaIC-2016.2.tar.gz /usr/local/idea/ 切换至目录并解压 12cd /usr/local/idea/tzr -xvf ideaIC-2016.2.tar.gz 为方便是用bin下命令,将其配置在~/.bashrc的PATH里.下面就是截止目前为止的所有环境配置. 12345678export JAVA_HOME=/usr/lib/java/jdk1.8.0_91export JRE_HOME=$&#123;JAVA_HOME&#125;/jreexport SCALA_HOME=/usr/lib/scala/scala-2.10.6export SPARK_HOME=/usr/lib/spark/spark-1.6.2-bin-hadoop2.6export CLASS_PATH=.:$&#123;JAVA_HOME&#125;/lib:$&#123;JRE_HOME&#125;/libexport PATH=/usr/local/idea/idea-IC-162.1121.32/bin:$&#123;SPARK_HOME&#125;/lib:$&#123;SCALA_HOME&#125;/bin:$&#123;JAVA_HOME&#125;/bin:/usr/lib/hadoop/hadoop-2.7.2/bin:$PATH- 使bashrc生效source ~/.bashrc 打开IDEA 12cd /usr/local/idea/idea-IC-162.1121.32/binidea.sh 安装SCALA插件plugins 在线安装欢迎界面-右下角configuration-左下角Install JetBrains-搜索scala-install即可 离线安装欢迎界面-右下角configuration-下方Install plugins from disk-选择安装 创建项目Create New Project-Scala-SBT-name-location-SDK(选择JAVA路径)-SBT-SCALA-Finash由于要自动完成SBT工具的安装,用时较长,本人用时30min以上. 资料提供链接: http://pan.baidu.com/s/1slQpli1密码: ####请打赏索要. 环境提供链接: http://pan.baidu.com/s/1bpcDkxL密码: ####请打赏索要. 友情提示,如有帮助,文章底下有打赏按键.]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Hadoop Spark</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Coding笔记系列2--两个简单展示]]></title>
    <url>%2F2016%2F07%2F14%2Fcode-cookbook-3%2F</url>
    <content type="text"><![CDATA[Coding笔记第三篇,有两个不成样子的东西,贴出来看看.做的实在是太low了,我都不想拿出来见人. 王小波-简介页面请点击王小波-简介页面 诗经-国风-展示页面请点击诗经-国风-展示页面在这里用css JS语法的时候,没有能够熟练的掌握,离开了IDE就不能写.也没能掌握Bootstrap这成熟的前端开发框架. 有两点需要注意和加强的地方: 语法规范 CSS这种简单的语法还是有一些生疏,不能很好的运用.以至于不停的去查用法.熟练度太欠缺 见识短浅 没有对整个设计有一个全面的理性的认识,导致自己在实践中,不停的改Idea,最终已经偏离初心甚远. 以后要多加注意]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Coding</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Coding笔记系列2--初涉前端略有趣]]></title>
    <url>%2F2016%2F06%2F22%2Fcode-cookbook-2%2F</url>
    <content type="text"><![CDATA[Coding笔记第二篇.这几天不想看paper,也不想写paper.可能这几天天气太热,心情浮躁,想换换心情. HTML5 and CSS这部分很简单,只要记住命令是自封闭还是配对封闭.也不清楚这么说对不对,一直看英文的.总结几点自己感觉值得记忆的地方: a标签对应链接href,p标签文字记录标签. img标签对已链接src. .classcss中对应class需要前加. #idcss中对应id需要加# h1css中对应标签直接规定 BootstrapBootstrap作为最通用的前端框架,用起来简直无脑. 自带css btn 以及 btn-default btn-primary … well 之前没注意这个样式,超好用 ul无序ol有序数字 input中单选radio多选checkbox jQueryjQ在这里学习太早了吧,所幸还是很简单. 直接给出涉及到的用法12345678910111213141516171819202122232425&lt;script&gt; $(document).ready(function() &#123; $(&quot;#target1&quot;).css(&quot;color&quot;, &quot;red&quot;); // css样式 $(&quot;#target1&quot;).prop(&quot;disabled&quot;, true); // disabled $(&quot;#target4&quot;).remove(); // 移除样式 $(&quot;#target2&quot;).appendTo(&quot;#right-well&quot;); // 添加 $(&quot;#target5&quot;).clone().appendTo(&quot;#left-well&quot;); // 克隆下添加 $(&quot;#target1&quot;).parent().css(&quot;background-color&quot;, &quot;red&quot;); // 父类 $(&quot;#right-well&quot;).children().css(&quot;color&quot;, &quot;orange&quot;); // 子类 $(&quot;#left-well&quot;).children().css(&quot;color&quot;, &quot;green&quot;); $(&quot;.target:nth-child(2)&quot;).addClass(&quot;animated bounce&quot;); // 层数 $(&quot;.target:even&quot;).addClass(&quot;animated shake&quot;); // 奇偶even odd $(&quot;body&quot;).addClass(&quot;animated hinge&quot;) // body操作 &#125;);&lt;/script&gt;]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Coding</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Coding笔记系列1--入门前端须知]]></title>
    <url>%2F2016%2F06%2F20%2Fcode-cookbook-1%2F</url>
    <content type="text"><![CDATA[这是Coding笔记的第一篇,写这系列文章主要是记录学习心得.2016-6-20这天开始,记录自己在Freecodecamp的学习历程.计划花费2个月在上面刷,不知道能学习到什么程度.这是系列笔记的开篇,就写下注意事项吧,也是FCC官方的一些观念. 每天的训练代码人,常说,代码是个体力活.要有量的积累,才能掌握这项体力活. 一读二搜三提问学习一门语言,首先就是阅读官方文档,使用方法都有说明,error的解决办法也能找到.第二,就是善用搜索引擎,你要相信这问题你不是第一次遇到,你也不是困扰的第一人.第三,就是Qustion环节,求助于一些有Coding经验的老手,是最快的解决办法.此类方法,不要常用.代码是孤独的旅行.其次,为什么要写这系列文章,为什么写博客,写这些到底有什么用,又是为了什么写?总是有人问这些问题,不是为什么,而是为了什么.人总是自私的,那就说句煽情的话吧. 为了遇见更好的自己]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>Coding</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用软件推荐与分享--Windows软件篇]]></title>
    <url>%2F2016%2F06%2F17%2Fsoftware-windows%2F</url>
    <content type="text"><![CDATA[首先,使用了这么多年的电脑,也积攒了一些微不足道的使用经验,一直想记录记录给自己个备忘,同时分享给别人作为参考.同时,本人由于是穷屌丝一个,目前的使用平台仅限于Windows,之前有过MacOS的使用经验,但对MacOS熟悉度还是不够,还远远没能达到可以写出的程度. 此文,是软件篇,硬件篇链接为PC硬件平台的推荐与分享—Windows硬件篇 当PC成为生活不可或缺的一部分时,优秀的软件给生活乃至人生都会带来优质的体验.结合本人多年的软件使用经验,整理出这些常用的软件,在此,分享给大家.闲话少说,进入正题啦. 系统篇Windows 10 不要担心10会稳定性很差 用户体验很好 有一定学习成本 Windows 7 稳定办公游戏首选仅推荐,原版下载安装.奉上下载地址MSDN,I tell you,MSDN里的软件都是巨硬家的原版镜像,下面涉及到巨硬家应用,都可以从这里找到,可以放心下载.至于巨硬家的产品激活,就需要大家各显神通了. 办公篇如果,读者你把你的PC当成生产力工具的话,也就是你工作必备品.那这些软件你可能会很喜欢. 办公软件OfficeMicrosoft Office 2016 体验超好,比13提升的不是一点半点 Office 365 推荐购买 Microsoft Office 2013 稳定办公首选对于巨硬家族的产品,如果有能力就支持正版购买.学校一般有免费正版可用.其他激活方式如KMS,自己可用动手操作,这里不再叙述. WPS 个人用户建议使用 功能个性化强 PDF文档处理福昕阅读器 国产良心 在巨无霸Adobe面前分下一大杯羹 据说当初公司看不起中国市场只做英文foxit 启动速度,处理速度远超Adobe官网地址这里哦福昕阅读器中文版 Adobe Acrobat 编辑PDF神器 邮件处理Foxmail 入职必备,第一首选 各种邮件收发顺利如Gmail官网地址哦Foxmail Outlook 工作时,见一些老板还是用这个 熟悉的话,也很好用 代码篇编辑器Sublime 代码界最性感的编辑器 收费编辑器 请支持正版,破解靠自己 VIM Vim大法 notepad++ Win平台 免费好用 工具F.lux 护眼首选 用了就离不开 Evething 本地搜索神器 Total Commander 文件管理神器 Clover 便签式资源管理器]]></content>
      <categories>
        <category>推荐分享</category>
      </categories>
      <tags>
        <tag>hardware</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安河桥]]></title>
    <url>%2F2016%2F06%2F05%2Ftime%2F</url>
    <content type="text"><![CDATA[岁月静好,现世安稳]]></content>
      <categories>
        <category>心情随笔</category>
      </categories>
      <tags>
        <tag>心情</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo-github部署指南]]></title>
    <url>%2F2016%2F06%2F02%2Fhexo-deploy%2F</url>
    <content type="text"><![CDATA[本博使用的是Hexo+github部署而成,并无花费,只需要一定的技术水平. 前期准备申请github账号github作为一个优秀的代码托管平台,如今的码农世界,第一要求不是你什么项目经验,工作经验,第一点就是你的github账号,对这个开源的代码世界有何贡献,是衡量一个成功代码者的重要标准. github官网 部署git环境git是一种代码管理方式,是一种免费、开源的分布式版本控制系统.git下载地址 部署Node.js环境Node.js是一个Javascript运行环境(runtime). Node.js优点 RESTful API 单线程Node.js可以在不新增额外线程的情况下，依然可以对任务进行并行处理 —— Node.js是单线程的。它通过事件轮询（event loop）来实现并行操作，对此，我们应该要充分利用这一点 —— 尽可能的避免阻塞操作，取而代之，多使用非阻塞操作。 非阻塞IO V8虚拟机 事件驱动node.js下载地址 部署Hexo环境初始化使用git在任意非中文路径空文件夹,使用命令1npm install hexo-cli -g 部署hexo-deployer-git1npm install hexo-deployer-git --save 生成目录1hexo init 静态化123hexo generateorhexo g 部署123hexo deployorhexo d 本地服务12345hexo serveror hexo server -p 5000 #端口号orhexo s 完整部署步骤123456npm install hexo-cli -gnpm install hexo-deployer-git --savehexo inithexo clean # 删除静态文件hexo ghexo d github仓库建立与用户名一致的Respository,例如用户名为xixici,则建立xixici.github.io config.yml配置修改修改Hexo站点主目录下config.yml文件中部署部分.如下:1234deploy: type: git repository: http://github.com/xixici/xixici.github.io.git branch: master 然后部署就需要上述命令12hexo ghexo d 文章发表1hexo new post &quot;markdown tips&quot; 本人环境12345678910111213$ hexo version # 命令语句hexo: 3.2.0hexo-cli: 1.0.1os: Windows_NT 10.0.10586 win32 x64http_parser: 2.5.2node: 4.4.4v8: 4.5.103.35uv: 1.8.0zlib: 1.2.8ares: 1.10.1-DEVicu: 56.1modules: 46openssl: 1.0.2h 参考 使用Hexo搭建个人博客(基于hexo3.0) http://baixin.io/2015/08/12/hexo/ 如何搭建一个独立博客——简明 Github Pages与 jekyll 教程]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>hexo github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PC硬件平台的推荐与分享--Windows硬件篇]]></title>
    <url>%2F2016%2F05%2F30%2Fhardware-windows%2F</url>
    <content type="text"><![CDATA[首先,使用了这么多年的电脑,也积攒了一些微不足道的使用经验,一直想记录记录给自己个备忘,同时分享给别人作为参考.同时,本人由于是穷屌丝一个,目前的使用平台仅限于Windows,之前有过MacOS的使用经验,但对MacOS熟悉度还是不够,还远远没能达到可以写出的程度. 此文,是硬件篇,软件篇链接为常用软件推荐与分享—Windows软件篇有一个优越的硬件环境,身心与工作都能受益匪浅.硬件的选购来说,线上与线下都会有很多坑等着去跳.总体来说,对于现如今的互联网时代而言,线上会是大多数首要选项.当然,如果线下有很好的选择,或许不必来线上这鱼龙混杂的世界. 配置个人建议(肺腑之言.因人而异) SSD(固态)硬盘 120GB以上,上不封顶,多多益善 RAM(内存) 8G起 CPU(中央处理器) 喜新厌旧,型号越新越优越 品牌推荐 Lenovo联想(美帝良心)对不追求性价比,不care钱这个问题,联想不失为你的第一备选.联想这种战五渣,接过IBM的Thinkpad,把笔电第一品牌给拉下马,我也不说什么了. Acer宏碁(踏实友商)对宏碁qi而言,我感觉就是一挺踏实的友商,身边的盆友们也有人用过. Hasee神舟(赶紧上船)神舟绝对是广大笔电爱好者的第一入选品牌.非小白,第一选,赶紧上船. HP惠普 Dell戴尔 Asus华硕 Samsung三星对于一生产力工具而言,首位的是提升生产力,第二位是个人喜好.如果顺序反之,我也没什么话说.经常有朋友说,我很喜欢某某型号的电脑,我只有一个字,买.开心就好,想太多,何必呢. 选购指南(线上)京东虽然一直被誉为二手东,但相对于假货横行的某猫来说,保障也不是高了一分两分.首推. 装机大师某猫也有很多良心卖家,某美要谨慎.在这里推荐两个好评很高的店 萌叔装机太多人安利这家 摩西电脑卡吧基佬推荐 台式机推荐款办公台机 Dell Vostro Dell Inspiron 游戏台机 不推荐品牌,组装为宜 笔电推荐款办公笔电 Thinkpad T450 游戏笔电 神舟 Z6 HP 暗影精灵 Lenovo 拯救者 高端玩家笔电 Alienware 外星人 Razer Blade 雷蛇灵刃 Terrans Force 未来人类 如果你心仪某一种,就出手吧.]]></content>
      <categories>
        <category>推荐分享</category>
      </categories>
      <tags>
        <tag>hardware</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[markdown学习笔记]]></title>
    <url>%2F2016%2F05%2F23%2Fmarkdown-tips%2F</url>
    <content type="text"><![CDATA[当你需要使用一种 高格调,又很 Geek范 的文字工具来记录自己,分享价值时,Markdwon就是你的首选.当你学习一项工具,并且使用它,或许你会花费很大的成本,但是如果你学会了,并使用,你会爱上他.MarkDown如是说. 工欲善其事必先利其器—MarkPad(WIN平台)MarkPad 是款开源的 Markdown 编辑, Window 8 和谐友好的风格界面。 Markdown实用语法 以下是常用用法,如 加粗, 斜体, 链接, 列表, 公式, 代码, 表格等等 加粗与斜体12**加粗的用法在这里***斜体的用法是这里* 加粗的用法在这里 斜体的用法是这里 标题的用法1234#标题1##标题1......######标题1 #的数量的多少与大小有关,类似的还有-,自己试验用法吧. 链接的写法1[XIXICI 主页](http:\\xixici.com\) XIXICI 主页 阅读更多1&lt;!--more--&gt; 引用12&gt;不能听命于自己者，就要受命于他人。——尼采《查特拉斯如是说》 不能听命于自己者，就要受命于他人。——尼采《查特拉斯如是说》 待办事宜12345- [ ] 支持以 PDF 格式导出文稿- [ ] 改进 Cmd 渲染算法，使用局部渲染技术提高渲染效率- [x] 新增 Todo 列表功能- [x] 修复 LaTex 公式渲染问题- [x] 新增 LaTex 公式编号功能 [ ] 支持以 PDF 格式导出文稿 [ ] 改进 Cmd 渲染算法，使用局部渲染技术提高渲染效率 [x] 新增 Todo 列表功能 [x] 修复 LaTex 公式渲染问题 [x] 新增 LaTex 公式编号功能 质能守恒公式1$$E=mc^2$$ E=mc^2高亮代码1234567@requires_authorizationclass SomeClass: passif __name__ == '__main__': # A comment print 'hello world' 在整段代码两端加三个`, 可以对整段代码加高亮.仅仅对一句代码高亮可以在句子两端加一个`即可. 绘制表格12345| 项目 | 价格 | 数量 || -------- | -----: | :----: || 计算机 | \$1600 | 5 || 手机 | \$12 | 12 || 管线 | \$1 | 234 | 项目 价格 数量 计算机 $1600 5 手机 $12 12 管线 $1 234 网易云音乐插入1&lt;iframe frameborder=&quot;no&quot; border=&quot;0&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; width=330 height=86 src=&quot;http://music.163.com/outchain/player?type=2&amp;id=32957377&amp;auto=1&amp;height=66&quot;&gt;&lt;/iframe&gt; 自动播放将auto=1即可. Geek的专注在本文表现的淋漓尽致.只用键盘就能写出来这么漂亮(排版而已)的文章. 参考 欢迎使用 Cmd Markdown 编辑阅读器 MarkPad下载地址]]></content>
      <categories>
        <category>学习笔记</category>
      </categories>
      <tags>
        <tag>markdown</tag>
      </tags>
  </entry>
</search>
